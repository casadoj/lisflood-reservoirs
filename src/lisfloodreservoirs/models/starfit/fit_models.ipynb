{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9308b28d-3d86-4b1f-b4cc-81ea425b4d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "from storage import fit_storage, create_storage_harmonic\n",
    "from release import fit_release, create_release_harmonic, create_release_linear\n",
    "from inputs import read_reservoir_attributes, read_reservoir_data#, rank_and_filter_data\n",
    "from functions import plot_nor, plot_release, epiweek_to_date\n",
    "\n",
    "from lisfloodreservoirs.utils.metrics import KGEmod\n",
    "from lisfloodreservoirs import Config, read_attributes, read_timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78b52d4-857e-4d5d-b831-49a68cbf0389",
   "metadata": {},
   "source": [
    "## Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa3ce018-b96d-495f-907d-5292aeee9197",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config('Z:/nahaUsers/casadje/datasets/reservoirs/ResOpsUS/results/starfit/config.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8007fea0-ccbe-4f1f-b8c2-cb4f6f065561",
   "metadata": {},
   "source": [
    "### Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "084f3aae-54bd-4874-942c-fae790f87cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logger\n",
    "logger = logging.getLogger('fit-starfit')\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False\n",
    "log_format = logging.Formatter('%(asctime)s | %(levelname)s | %(name)s | %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "# log on screen\n",
    "c_handler = logging.StreamHandler()\n",
    "c_handler.setFormatter(log_format)\n",
    "c_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(c_handler)\n",
    "# # log file\n",
    "# log_path = cfg.PATH_CALIB / 'logs'\n",
    "# log_path.mkdir(exist_ok=True)\n",
    "# log_file = log_path / '{0:%Y%m%d%H%M}_calibrate_{1}.log'.format(datetime.now(),\n",
    "#                                                                '_'.join(args.config_file.split('.')[0].split('_')[1:]))\n",
    "# f_handler = logging.FileHandler(log_file)\n",
    "# f_handler.setFormatter(log_format)\n",
    "# f_handler.setLevel(logging.INFO)\n",
    "# logger.addHandler(f_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1712436-e861-44d4-8afd-0d4abaf19ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 17:45:55 | INFO | fit-starfit | Storage fitted parameters will be saved in: Z:\\nahaUsers\\casadje\\datasets\\reservoirs\\ResOpsUS\\results\\starfit\\NOR\n",
      "2024-07-30 17:45:55 | INFO | fit-starfit | Release fitted parameters will be saved in: Z:\\nahaUsers\\casadje\\datasets\\reservoirs\\ResOpsUS\\results\\starfit\\release\n"
     ]
    }
   ],
   "source": [
    "PATH_STORAGE = cfg.PATH_DEF.parent / 'NOR'\n",
    "PATH_STORAGE.mkdir(parents=True, exist_ok=True)\n",
    "logger.info(f'Storage fitted parameters will be saved in: {PATH_STORAGE}')\n",
    "\n",
    "PATH_RELEASE = cfg.PATH_DEF.parent / 'release'\n",
    "PATH_RELEASE.mkdir(parents=True, exist_ok=True)\n",
    "logger.info(f'Release fitted parameters will be saved in: {PATH_RELEASE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72800cb4-d23d-49c4-9c97-9893e894de02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USRDATS_path = Path('Z:/nahaUsers/casadje/datasets/reservoirs/ResOpsUS/raw')\n",
    "# GRanD_path = Path('Z:/nahaUsers/casadje/datasets/reservoirs/GRanD/v1_3')\n",
    "\n",
    "# # grand_id = 753\n",
    "# cutoff_year = 1982"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e38b54d-043a-4ccb-ae40-65b51ccf5c1c",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0c6279-93e7-4861-aa62-733c04e54b9c",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b74504c2-3279-4834-853e-eaf9ef8738a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 17:45:55 | INFO | fit-starfit | 90 reservoirs in the attribute tables\n"
     ]
    }
   ],
   "source": [
    "# list of reservoirs to be trained\n",
    "try:\n",
    "    reservoirs = pd.read_csv(cfg.RESERVOIRS_FILE, header=None).squeeze().tolist()\n",
    "except IOError as e:\n",
    "    logger.error(f'Failed to open {cfg.RESERVOIRS_FILE}: {e}')\n",
    "    raise\n",
    "\n",
    "# import all tables of attributes\n",
    "try:\n",
    "    attributes = read_attributes(cfg.PATH_DATA / 'attributes', reservoirs)\n",
    "except IOError as e:\n",
    "    logger.error('Failed to read attribute tables from {0}: {1}'.format(cfg.PATH_DATA / 'attributes', e))\n",
    "    raise\n",
    "logger.info(f'{attributes.shape[0]} reservoirs in the attribute tables')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc48b17-3b9e-42c5-934e-38b3f7853934",
   "metadata": {},
   "source": [
    "### Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "201db074-7330-469f-82c4-010f75b6ba95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 17:45:59 | INFO | fit-starfit | 90 reservoirs with timeseries\n"
     ]
    }
   ],
   "source": [
    "# training periods\n",
    "try:\n",
    "    with open(cfg.PERIODS_FILE, 'rb') as file:\n",
    "        periods = pickle.load(file)\n",
    "except IOError as e:\n",
    "    logger.error(f'Failed to open {cfg.PERIODS_FILE}: {e}')\n",
    "    raise\n",
    "\n",
    "# read time series\n",
    "try:\n",
    "    timeseries = read_timeseries(cfg.PATH_DATA / 'time_series' / 'csv',\n",
    "                                 attributes.index,\n",
    "                                 periods)\n",
    "    for grand_id, obs in timeseries.items():\n",
    "        obs['s'] = obs.storage * 1e-6 # MCM\n",
    "        obs[['i', 'r']] = obs[['inflow', 'outflow']] * 1e-6 * 86400 # MCM/day\n",
    "except IOError as e:\n",
    "    logger.error('Failed to read time series from {0}: {1}'.format(cfg.PATH_DATA / 'time_series' / 'csv', e))\n",
    "    raise\n",
    "logger.info(f'{len(timeseries)} reservoirs with timeseries')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4b2a42-9688-4b13-b408-8456c6411fec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5034d4aa-bed1-4f10-9894-662c6da126de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read reservoir attributes and extract storage capacity\n",
    "# attributes = read_reservoir_attributes(GRanD_path, grand_id)\n",
    "# Vtot = attributes.loc[grand_id, 'CAP_MCM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d908647e-f408-4fb1-95df-a133c5e61d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read daily time series\n",
    "# daily = (\n",
    "#     read_reservoir_data(USRDATS_path, grand_id)\n",
    "#     .assign(\n",
    "#         i=lambda x: x['i_cumecs'] * 1e-6 * 86400,  # MCM/day\n",
    "#         r=lambda x: x['r_cumecs'] * 1e-6 * 86400,  # MCM/day\n",
    "#         year=lambda x: x.date.dt.year,\n",
    "#         epiweek=lambda x: x.date.dt.isocalendar().week\n",
    "#     )\n",
    "#     .rename(columns={'s_MCM': 's'})\n",
    "#     .loc[:, ['date', 's', 'i', 'r', 'year', 'epiweek']]\n",
    "#     .query('year >= @cutoff_year')\n",
    "#     .set_index('date')\n",
    "#     )\n",
    "# daily.epiweek = daily.epiweek.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c5348e-8ed1-4c51-994c-a4b3e0b5f574",
   "metadata": {},
   "source": [
    "## Fit reservoir\n",
    "\n",
    "### Storage functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "484e99ab-859d-4cfd-bce3-2112c01ebfe5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60fe51e63d994c42a03ebbc382496a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting targets for dam 41: Ross\n",
      "Dam 41 cutoff year set back to 1999\n",
      "Fitting targets for dam 63: Tieton\n",
      "Dam 63 cutoff year set back to 1982\n",
      "Fitting targets for dam 293: Fresno\n",
      "Dam 293 cutoff year set back to 1989\n",
      "Fitting targets for dam 300: Tiber Dike\n",
      "Dam 300 cutoff year set back to 2007\n",
      "Fitting targets for dam 307: Fort Peck Dam\n",
      "Dam 307 cutoff year set back to 1982\n",
      "Fitting targets for dam 319: Gibson\n",
      "Dam 319 cutoff year set back to 1994\n",
      "Fitting targets for dam 355: Yellowtail\n",
      "Dam 355 cutoff year set back to 1982\n",
      "Fitting targets for dam 362: Clark Canyon\n",
      "Dam 362 cutoff year set back to 1982\n",
      "Fitting targets for dam 364: Hebgen Dam\n",
      "Dam 364 cutoff year set back to 1995\n",
      "Fitting targets for dam 367: Mason\n",
      "Dam 367 cutoff year set back to 1997\n",
      "Fitting targets for dam 368: Lima\n",
      "Dam 368 cutoff year set back to 2007\n",
      "Fitting targets for dam 372: Unity\n",
      "Dam 372 cutoff year set back to 1994\n",
      "Fitting targets for dam 373: Buffalo Bill\n",
      "Dam 373 cutoff year set back to 1982\n",
      "Fitting targets for dam 384: Jackson Lake\n",
      "Dam 384 cutoff year set back to 1982\n",
      "Fitting targets for dam 391: Lucky Peak\n",
      "Dam 391 cutoff year set back to 2004\n",
      "Fitting targets for dam 393: Boysen\n",
      "Dam 393 cutoff year set back to 1982\n",
      "Fitting targets for dam 398: Bull Lake\n",
      "Dam 398 cutoff year set back to 1982\n",
      "Fitting targets for dam 416: Pathfinder Dike\n",
      "Dam 416 cutoff year set back to 1993\n",
      "Fitting targets for dam 419: Big Sandy Dike\n",
      "Dam 419 cutoff year set back to 2009\n",
      "Fitting targets for dam 421: Seminoe\n",
      "Dam 421 cutoff year set back to 1982\n",
      "Fitting targets for dam 423: Fontenelle\n",
      "Dam 423 cutoff year set back to 1988\n",
      "Fitting targets for dam 438: Pineview\n",
      "Dam 438 cutoff year set back to 2008\n",
      "Fitting targets for dam 442: Lost Creek\n",
      "Dam 442 cutoff year set back to 1998\n",
      "Fitting targets for dam 445: Meeks Cabin\n",
      "Dam 445 cutoff year set back to 2001\n",
      "Fitting targets for dam 449: Echo\n",
      "Dam 449 cutoff year set back to 1990\n",
      "Fitting targets for dam 451: Flaming Gorge\n",
      "Dam 451 cutoff year set back to 1982\n",
      "Fitting targets for dam 456: Wanship\n",
      "Dam 456 cutoff year set back to 1987\n",
      "Fitting targets for dam 467: Bor Jordanelle\n",
      "Dam 467 cutoff year set back to 1993\n",
      "Fitting targets for dam 471: Moon Lake\n",
      "Dam 471 cutoff year set back to 2007\n",
      "Fitting targets for dam 477: Deer Creek\n",
      "Dam 477 cutoff year set back to 1986\n",
      "Fitting targets for dam 488: Bor Starvation\n",
      "Dam 488 cutoff year set back to 1997\n",
      "Fitting targets for dam 497: Williams Fork\n",
      "Dam 497 cutoff year set back to 1982\n",
      "Fitting targets for dam 502: Green Mountain\n",
      "Dam 502 cutoff year set back to 1982\n",
      "Fitting targets for dam 511: Chatfield Dam\n",
      "Dam 511 cutoff year set back to 1982\n",
      "Fitting targets for dam 517: Ruedi\n",
      "Dam 517 cutoff year set back to 1982\n",
      "Fitting targets for dam 518: Joes Valley\n",
      "Dam 518 cutoff year set back to 2004\n",
      "Fitting targets for dam 522: Cheesman\n",
      "Dam 522 cutoff year set back to 1999\n",
      "Fitting targets for dam 530: Spinney Mountain\n",
      "Dam 530 cutoff year set back to 1990\n",
      "Fitting targets for dam 533: Eleven Mile Canyon\n",
      "Dam 533 cutoff year set back to 1997\n",
      "Fitting targets for dam 536: Taylor Park\n",
      "Dam 536 cutoff year set back to 1982\n",
      "Fitting targets for dam 541: Blue Mesa\n",
      "Dam 541 cutoff year set back to 1982\n",
      "Fitting targets for dam 575: Vallecito\n",
      "Dam 575 cutoff year set back to 1982\n",
      "Fitting targets for dam 595: Friant\n",
      "Dam 595 cutoff year set back to 2000\n",
      "Fitting targets for dam 597: Glen Canyon\n",
      "Dam 597 cutoff year set back to 1982\n",
      "Fitting targets for dam 601: Navajo\n",
      "Dam 601 cutoff year set back to 1982\n",
      "Fitting targets for dam 753: Garrison Dam\n",
      "Dam 753 cutoff year set back to 1982\n",
      "Fitting targets for dam 780: Jamestown\n",
      "Dam 780 cutoff year set back to 2006\n",
      "Fitting targets for dam 789: Sandy Lake Dam and Lock\n",
      "Dam 789 cutoff year set back to 1982\n",
      "Fitting targets for dam 870: Oahe Dam\n",
      "Dam 870 cutoff year set back to 2010\n",
      "Fitting targets for dam 882: Pactola\n",
      "Dam 882 cutoff year set back to 1982\n",
      "Fitting targets for dam 898: Glendo\n",
      "Dam 898 cutoff year set back to 1982\n",
      "Fitting targets for dam 952: Lovewell\n",
      "Dam 952 cutoff year set back to 2010\n",
      "Fitting targets for dam 957: Cherry Creek Dam\n",
      "Dam 957 cutoff year set back to 1984\n",
      "Fitting targets for dam 982: Melvern Dam\n",
      "Dam 982 cutoff year set back to 1982\n",
      "Fitting targets for dam 987: Pueblo\n",
      "Dam 987 cutoff year set back to 1984\n",
      "Fitting targets for dam 989: Harry S. Truman Dam\n",
      "Dam 989 cutoff year set back to 1982\n",
      "Fitting targets for dam 1006: Stockton Dam\n",
      "Dam 1006 cutoff year set back to 1982\n",
      "Fitting targets for dam 1023: Kaw Lake\n",
      "Dam 1023 cutoff year set back to 1991\n",
      "Fitting targets for dam 1026: Table Rock Dam\n",
      "Dam 1026 cutoff year set back to 1982\n",
      "Fitting targets for dam 1027: Fort Supply Lake\n",
      "Dam 1027 cutoff year set back to 1998\n",
      "Fitting targets for dam 1032: Oologah Lake\n",
      "Dam 1032 cutoff year set back to 1985\n",
      "Fitting targets for dam 1033: Beaver\n",
      "Dam 1033 cutoff year set back to 1982\n",
      "Fitting targets for dam 1036: Bull Shoals\n",
      "Dam 1036 cutoff year set back to 1982\n",
      "Fitting targets for dam 1042: Norfork\n",
      "Dam 1042 cutoff year set back to 1982\n",
      "Fitting targets for dam 1048: Keystone Lake\n",
      "Dam 1048 cutoff year set back to 1989\n",
      "Fitting targets for dam 1053: Fort Gibson Lake\n",
      "Dam 1053 cutoff year set back to 1982\n",
      "Fitting targets for dam 1067: Greers Ferry\n",
      "Dam 1067 cutoff year set back to 1982\n",
      "Fitting targets for dam 1070: Conchas Dam\n",
      "Dam 1070 cutoff year set back to 1991\n",
      "Fitting targets for dam 1086: Santa Rosa Dam\n",
      "Dam 1086 cutoff year set back to 1991\n",
      "Fitting targets for dam 1112: Blakely Mountain Dam\n",
      "Dam 1112 cutoff year set back to 1998\n",
      "Fitting targets for dam 1121: Degray Dam\n",
      "Dam 1121 cutoff year set back to 1988\n",
      "Fitting targets for dam 1124: Dierks\n",
      "Dam 1124 cutoff year set back to 2002\n",
      "Fitting targets for dam 1125: Narrows Dam\n",
      "Dam 1125 cutoff year set back to 1988\n",
      "Fitting targets for dam 1134: Pat Mayse Lake\n",
      "Dam 1134 cutoff year set back to 1982\n",
      "Fitting targets for dam 1207: Ross Barnett Reservoir\n",
      "Dam 1207 cutoff year set back to 1983\n",
      "Fitting targets for dam 1636: Senecaville Dam\n",
      "Dam 1636 cutoff year set back to 2001\n",
      "Fitting targets for dam 1723: Paintsville Dam\n",
      "Dam 1723 cutoff year set back to 1993\n",
      "Fitting targets for dam 1753: Kentucky\n",
      "Dam 1753 cutoff year set back to 1991\n",
      "Fitting targets for dam 1755: Barren River Lake Dam\n",
      "Dam 1755 cutoff year set back to 2001\n",
      "Fitting targets for dam 1756: Wolf Creek\n",
      "Dam 1756 cutoff year set back to 1982\n",
      "Fitting targets for dam 1761: John H. Kerr Dam\n",
      "Dam 1761 cutoff year set back to 1995\n",
      "Fitting targets for dam 1777: Center Hill Dam\n",
      "Dam 1777 cutoff year set back to 1995\n",
      "Fitting targets for dam 1796: B. Everett Jordan Dam\n",
      "Dam 1796 cutoff year set back to 2005\n",
      "Fitting targets for dam 1848: Sardis Dam\n",
      "Dam 1848 cutoff year set back to 1982\n",
      "Fitting targets for dam 1851: Hartwell Dam\n",
      "Dam 1851 cutoff year set back to 1982\n",
      "Fitting targets for dam 1864: Enid Dam\n",
      "Dam 1864 cutoff year set back to 1999\n",
      "Fitting targets for dam 1872: J. Strom Thurmond Dam\n",
      "Dam 1872 cutoff year set back to 1990\n",
      "Fitting targets for dam 1910: Walter F. George Lock and Dam\n",
      "Dam 1910 cutoff year set back to 1982\n",
      "Fitting targets for dam 7308: Richard B. Russell Dam\n",
      "Dam 7308 cutoff year set back to 1987\n",
      "Fitting targets for dam 7313: Canyon Ferry Dam\n",
      "Dam 7313 cutoff year set back to 1982\n"
     ]
    }
   ],
   "source": [
    "for grand_id, obs in tqdm(timeseries.items()):\n",
    "        \n",
    "    # update reservoir capacity, if maximum observeation exceeds GRanD\n",
    "    attributes.loc[grand_id, 'CAP_MCM'] = max(attributes.loc[grand_id, 'CAP_MCM'], obs.s.max())\n",
    "\n",
    "    # fit storage model\n",
    "    model_storage = fit_storage(grand_id, \n",
    "                                storage_daily=obs.s, \n",
    "                                attributes=attributes.loc[grand_id])\n",
    "\n",
    "    # export fitted parameters\n",
    "    pars_to_export = ['capacity (MCM)', 'NOR upper bound', 'NOR lower bound']\n",
    "    pars = {key: value for key, value in model_storage.items() if key in pars_to_export}\n",
    "    with open(PATH_STORAGE / f'{grand_id}.pkl', 'wb') as file:\n",
    "             pickle.dump(pars, file)\n",
    "    # pd.DataFrame({\n",
    "    #             'flood': model_storage[\"NOR upper bound\"],\n",
    "    #             'conservation': model_storage[\"NOR lower bound\"]\n",
    "    #         }).to_csv(PATH_STORAGE / f'{grand_id}.csv', index=False)\n",
    "    \n",
    "    # define normal operating range (NOR)\n",
    "    NORup = create_storage_harmonic(model_storage['NOR upper bound'], name='flood').set_index('epiweek')\n",
    "    NORdown = create_storage_harmonic(model_storage['NOR lower bound'], name='conservation').set_index('epiweek')\n",
    "    NOR = pd.concat((NORup, NORdown), axis=1)\n",
    "\n",
    "    # weekly time series of standardised storage combined with NOR\n",
    "    weekly_storage = model_storage['weekly storage']\n",
    "\n",
    "    # plot model\n",
    "    plot_nor(weekly_storage,\n",
    "             NOR,\n",
    "             title='{0} - {1}'.format(grand_id, attributes.loc[grand_id, 'DAM_NAME']),\n",
    "             save=PATH_STORAGE / f'{grand_id}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d49d9c-15e6-47b2-927f-7f59c4b201f4",
   "metadata": {},
   "source": [
    "### Release function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e186c9b-ad3c-49f4-bba9-8a70a0e892a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c845c13e8da4f9184a54d49b04b2a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting release function for dam 41: Ross\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 63: Tieton\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 293: Fresno\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 300: Tiber Dike\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 307: Fort Peck Dam\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 319: Gibson\n",
      "Fitting release function for dam 355: Yellowtail\n",
      "Fitting release function for dam 362: Clark Canyon\n",
      "Fitting release function for dam 364: Hebgen Dam\n",
      "Fitting release function for dam 367: Mason\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 368: Lima\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 372: Unity\n",
      "Fitting release function for dam 373: Buffalo Bill\n",
      "Fitting release function for dam 384: Jackson Lake\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 391: Lucky Peak\n",
      "Fitting release function for dam 393: Boysen\n",
      "Fitting release function for dam 398: Bull Lake\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 416: Pathfinder Dike\n",
      "Fitting release function for dam 419: Big Sandy Dike\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 421: Seminoe\n",
      "Fitting release function for dam 423: Fontenelle\n",
      "Fitting release function for dam 438: Pineview\n",
      "Fitting release function for dam 442: Lost Creek\n",
      "Fitting release function for dam 445: Meeks Cabin\n",
      "Fitting release function for dam 449: Echo\n",
      "Fitting release function for dam 451: Flaming Gorge\n",
      "Fitting release function for dam 456: Wanship\n",
      "Fitting release function for dam 467: Bor Jordanelle\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 471: Moon Lake\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 477: Deer Creek\n",
      "Fitting release function for dam 488: Bor Starvation\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 497: Williams Fork\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 502: Green Mountain\n",
      "Fitting release function for dam 511: Chatfield Dam\n",
      "Fitting release function for dam 517: Ruedi\n",
      "Fitting release function for dam 518: Joes Valley\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 522: Cheesman\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 530: Spinney Mountain\n",
      "Fitting release function for dam 533: Eleven Mile Canyon\n",
      "Fitting release function for dam 536: Taylor Park\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 541: Blue Mesa\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 575: Vallecito\n",
      "Fitting release function for dam 595: Friant\n",
      "Fitting release function for dam 597: Glen Canyon\n",
      "Fitting release function for dam 601: Navajo\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 753: Garrison Dam\n",
      "Fitting release function for dam 780: Jamestown\n",
      "Fitting release function for dam 789: Sandy Lake Dam and Lock\n",
      "Fitting release function for dam 870: Oahe Dam\n",
      "Fitting release function for dam 882: Pactola\n",
      "Fitting release function for dam 898: Glendo\n",
      "Fitting release function for dam 952: Lovewell\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 957: Cherry Creek Dam\n",
      "Fitting release function for dam 982: Melvern Dam\n",
      "Fitting release function for dam 987: Pueblo\n",
      "Fitting release function for dam 989: Harry S. Truman Dam\n",
      "Fitting release function for dam 1006: Stockton Dam\n",
      "Fitting release function for dam 1023: Kaw Lake\n",
      "Fitting release function for dam 1026: Table Rock Dam\n",
      "Fitting release function for dam 1027: Fort Supply Lake\n",
      "Fitting release function for dam 1032: Oologah Lake\n",
      "Fitting release function for dam 1033: Beaver\n",
      "Fitting release function for dam 1036: Bull Shoals\n",
      "Fitting release function for dam 1042: Norfork\n",
      "Fitting release function for dam 1048: Keystone Lake\n",
      "Fitting release function for dam 1053: Fort Gibson Lake\n",
      "Fitting release function for dam 1067: Greers Ferry\n",
      "Fitting release function for dam 1070: Conchas Dam\n",
      "Fitting release function for dam 1086: Santa Rosa Dam\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 1112: Blakely Mountain Dam\n",
      "Fitting release function for dam 1121: Degray Dam\n",
      "Fitting release function for dam 1124: Dierks\n",
      "Fitting release function for dam 1125: Narrows Dam\n",
      "Fitting release function for dam 1134: Pat Mayse Lake\n",
      "Fitting release function for dam 1207: Ross Barnett Reservoir\n",
      "Fitting release function for dam 1636: Senecaville Dam\n",
      "Release residual model will be discarded; (release will be based harmonic function only)\n",
      "Fitting release function for dam 1723: Paintsville Dam\n",
      "Fitting release function for dam 1753: Kentucky\n",
      "Fitting release function for dam 1755: Barren River Lake Dam\n",
      "Fitting release function for dam 1756: Wolf Creek\n",
      "Fitting release function for dam 1761: John H. Kerr Dam\n",
      "Fitting release function for dam 1777: Center Hill Dam\n",
      "Fitting release function for dam 1796: B. Everett Jordan Dam\n",
      "Fitting release function for dam 1848: Sardis Dam\n",
      "Fitting release function for dam 1851: Hartwell Dam\n",
      "Fitting release function for dam 1864: Enid Dam\n",
      "Fitting release function for dam 1872: J. Strom Thurmond Dam\n",
      "Fitting release function for dam 1910: Walter F. George Lock and Dam\n",
      "Fitting release function for dam 7308: Richard B. Russell Dam\n",
      "Fitting release function for dam 7313: Canyon Ferry Dam\n"
     ]
    }
   ],
   "source": [
    "for grand_id, obs in tqdm(timeseries.items()):\n",
    "    \n",
    "    # update reservoir capacity, if maximum observeation exceeds GRanD\n",
    "    attributes.loc[grand_id, 'CAP_MCM'] = max(attributes.loc[grand_id, 'CAP_MCM'], obs.s.max())\n",
    "\n",
    "    # fit release model\n",
    "    model_release = fit_release(grand_id,\n",
    "                                daily_ops=obs[['s', 'i', 'r']],\n",
    "                                attributes=attributes.loc[grand_id],\n",
    "                                NOR_path=PATH_STORAGE,\n",
    "                                cutoff_year=None)\n",
    "\n",
    "    # export fitted parameters\n",
    "    pars_to_export = ['mean inflow (MCM/wk)', 'harmonic parameters', 'residual parameters', 'constraints']\n",
    "    pars = {key: value for key, value in model_release.items() if key in pars_to_export}\n",
    "    with open(PATH_RELEASE / f'{grand_id}.pkl', 'wb') as file:\n",
    "             pickle.dump(pars, file)\n",
    "\n",
    "    # extract info from the fitted release: average inflow, harmonic release (standardised) and release contraints\n",
    "    avg_inflow = model_release['mean inflow (MCM/wk)']\n",
    "    release_harmonic = create_release_harmonic(model_release['harmonic parameters']).set_index('epiweek').squeeze()\n",
    "    release_linear = create_release_linear(model_release['residual parameters'])\n",
    "    Qmin, Qmax = model_release['constraints']\n",
    "    weekly_release = model_release['weekly release'].set_index('epiweek')\n",
    "\n",
    "    # plot model\n",
    "    title = '{0} - {1}'.format(grand_id, attributes.loc[grand_id, 'DAM_NAME'])\n",
    "    plot_release(weekly_release.r, avg_inflow, release_harmonic, release_linear, Qmin, Qmax, title=title,\n",
    "                 save=PATH_RELEASE / f'{grand_id}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc0234e-5cc2-46b0-81e0-cb13062cd461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
