{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6cab479-b290-4ab0-a8ff-30206ddaeb0a",
   "metadata": {},
   "source": [
    "# Lake tables - GloFAS5\n",
    "***\n",
    "\n",
    "**Author:** Chus Casado Rodríguez<br>\n",
    "**Date:** 03-12-2024<br>\n",
    "\n",
    "**Introduction:**<br>\n",
    "This notebook extracts the attributes required by LISFLOOD for the lakes selected to be modelled in GloFAS5:\n",
    "\n",
    "* Lake area\n",
    "* Outlet width\n",
    "* Average inflow\n",
    "\n",
    "**To do:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e639fc-a675-4798-ac48-80a60e1700e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "from tqdm.notebook import tqdm\n",
    "from shapely.geometry import Point\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from lisfloodreservoirs.utils.utils import outlet_width\n",
    "from lisfloodreservoirs.utils.plots import plot_reservoir_map, compare_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3569d4aa-ea68-4e3c-9240-1fa0dac22e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def width_from_area(area: float, c: float) -> float:\n",
    "    \"\"\"Estimation of the river width based on catchment area:\n",
    "            width = area**c\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    area: float\n",
    "        catchment area in km2\n",
    "    c: float\n",
    "        coefficient of the model\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    width: float\n",
    "        river width in meters\n",
    "    \"\"\"\n",
    "    return area**c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcc9ddb-75dd-4700-82cc-180c012df7d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afac568f-4e85-4c5a-905c-497fa465a128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "PATH_GLOFAS4 = Path('Z:/nahaUsers/casadje/EFASv5')\n",
    "PATH_GLOFAS5 = Path('Z:/nahaUsers/casadje/EFASv6')\n",
    "PATH_DATASETS = Path('Z:/nahaUsers/casadje/datasets/')\n",
    "PATH_GLWD = PATH_DATASETS / 'lakes' / 'GLWD'\n",
    "PATH_HYLAK = PATH_DATASETS / 'lakes' / 'HydroLAKES' / 'LakeATLAS_v10_shp'\n",
    "PATH_OUT = PATH_GLOFAS5 / 'lakes' / 'tables'\n",
    "PATH_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# # minimum storage capacity included in EFAS\n",
    "MIN_VOLUME = 10 # hm³\n",
    "MIN_AREA = 5 # km²\n",
    "MIN_CATCHMENT = 50 # km²\n",
    "# MIN_DOR = 30 # days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f577b3-e574-4b29-a3c8-81360db3a13b",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb358ff7-4258-4f59-986a-4706f83ba10b",
   "metadata": {},
   "source": [
    "### GLOFAS4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78cda95-42f3-4d89-8b39-f57331f2b3a8",
   "metadata": {},
   "source": [
    "#### Lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d85061-3e6f-453d-be2c-67efa9aa7508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load GLOFAS4 lakes\n",
    "glofas4 = gpd.read_file(PATH_GLOFAS4 / 'tables' / 'GLOFAS4_lakes.shp').set_index('LakID', drop=True)\n",
    "\n",
    "# add attributes from the tables\n",
    "if 'efas_attrs' in locals():\n",
    "    del efas_attrs\n",
    "prefix = 'lake'\n",
    "for file in (PATH_GLOFAS4 / 'tables').glob(f'{prefix}*.txt'):\n",
    "    var = file.stem.removeprefix(prefix)\n",
    "    try:\n",
    "        df = pd.read_csv(file, sep=' ', header=None)\n",
    "        df.dropna(axis=1, how='all', inplace=True)\n",
    "        df.columns = ['LakID', var]\n",
    "        df.set_index('LakID', inplace=True, drop=True)\n",
    "        glofas4[var] = df\n",
    "    except:\n",
    "        print(file)\n",
    "        continue\n",
    "# convert area to km2\n",
    "glofas4['area'] /= 1e6\n",
    "glofas4.rename(columns={'a': 'alpha'}, inplace=True)\n",
    "glofas4.drop(['AREA_KM2', 'LON_ORG', 'LAT_ORG', 'LISFLOODX', 'LISFLOODY'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6154883-7565-42f7-8cf3-d57070f7ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "glofas4.SOURCE.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d7abad-94a8-4b2b-9dd3-dd2fffe0c2e8",
   "metadata": {},
   "source": [
    "#### Static_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5b4096-08cc-45c6-821c-282423b73c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upstream area\n",
    "uparea = rxr.open_rasterio(PATH_GLOFAS4 / 'static_maps' / 'upArea_European_01min.nc').squeeze(dim='band')\n",
    "\n",
    "# channel width\n",
    "chanbw = rxr.open_rasterio(PATH_GLOFAS4 / 'static_maps' / 'chanbw_European_01min.nc').squeeze(dim='band')\n",
    "chanbw = chanbw.where(chanbw >= 0, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf9507b-9986-4cdc-84a4-bca2b4b23d1e",
   "metadata": {},
   "source": [
    "### GLOFAS5\n",
    "#### Lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2ca17d-a115-4a43-9314-be906411d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shapefile\n",
    "glofas5 = gpd.read_file(PATH_GLOFAS5 / 'lakes' / 'LakesEfasV6.shp')\n",
    "\n",
    "# keep only selected lakes\n",
    "glofas5 = glofas5[glofas5.checked != 3]\n",
    "\n",
    "# select columns\n",
    "id_cols = ['LakID', 'GLWD_ID', 'Hylak_id']\n",
    "glofas5 = glofas5[id_cols + ['geometry']]\n",
    "\n",
    "# remove IDs equal to 0\n",
    "for col in ['LakID', 'Hylak_id', 'GLWD_ID']:\n",
    "    glofas5[col] = glofas5[col].astype('Int64')\n",
    "    glofas5.loc[glofas5[col] == 0, col] = np.nan\n",
    "    \n",
    "# glofas5.columns = [col.upper() if col != 'geometry' else col for col in glofas5.columns]\n",
    "\n",
    "# correct HydroLakes IDs\n",
    "with open('lakes_GLOFAS4_HydroLakes.yaml', 'r') as file:\n",
    "    map_efas_hylak = yaml.safe_load(file)\n",
    "correct_hylak_ids = glofas5.LakID.map(map_efas_hylak).astype('Int64').dropna()\n",
    "glofas5.loc[correct_hylak_ids.index, 'Hylak_id'] = correct_hylak_ids.values\n",
    "\n",
    "# add GLWD IDs\n",
    "with open('lakes_GLOFAS4_GLWD.yaml', 'r') as file:\n",
    "    map_efas_glwd = yaml.safe_load(file)\n",
    "correct_glwd_ids = glofas5.LakID.map(map_efas_glwd).astype('Int64').dropna()\n",
    "glofas5.loc[correct_glwd_ids.index, 'GLWD_ID'] = correct_glwd_ids.values\n",
    "\n",
    "glofas5.sort_values(['Hylak_id'], ascending=True, inplace=True)\n",
    "glofas5.reset_index(drop=True, inplace=True)\n",
    "glofas5.index.name = 'FID'\n",
    "print('{0} lakes in GLOFAS5'.format(glofas5.shape[0]))\n",
    "print('\\t* {0} were in GLOFAS4'.format(glofas5.LakID.notnull().sum()))\n",
    "print('\\t* {0} are in HydroLakes'.format(glofas5.Hylak_id.notnull().sum()))\n",
    "print('\\t* {0} are in GLWD'.format(glofas5.GLWD_ID.notnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4986205c-6f10-4089-9eba-c80e23bdc218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = pd.concat((glofas5.geometry.x, glofas5.geometry.y), axis=1)\n",
    "# points.columns = ['lon', 'lat']\n",
    "# points.index.name = 'ID'\n",
    "\n",
    "# points.to_csv(PATH_GLOFAS5 / 'ncextract' / f'lakes_glofas5_{glofas5.shape[0]}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb7403-58fe-4bb5-81e2-c6759153c9e2",
   "metadata": {},
   "source": [
    "#### Reservoirs with low degree of regulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c55f7-ae31-4f3b-9ee6-0bb8c7d67fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoirs = pd.read_excel(\n",
    "    PATH_GLOFAS5 / 'reservoirs' / 'tables' / 'glofas5_reservoirs.xlsx',\n",
    "    sheet_name='as_lakes',\n",
    "    index_col='FID'\n",
    ")\n",
    "reservoirs[['ResID', 'GRanD_id', 'Hylak_id']] = reservoirs[['ResID', 'GRanD_id', 'Hylak_id']].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1408ab-3e10-47b9-964c-657bd66bd267",
   "metadata": {},
   "source": [
    "### GLWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe37a99-af06-4730-b086-0ae61eb0d824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# level 1\n",
    "glwd1 = gpd.read_file(PATH_GLWD / 'level1' / 'glwd_1.shp').set_index('GLWD_ID', drop=True)\n",
    "glwd1 = glwd1.loc[glwd1.index.intersection(glofas5.GLWD_ID)]\n",
    "\n",
    "# level 2\n",
    "glwd2 = gpd.read_file(PATH_GLWD / 'level2' / 'glwd_2.shp').set_index('GLWD_ID', drop=True)\n",
    "glwd2 = glwd2.loc[glwd2.index.intersection(glofas5.GLWD_ID)]\n",
    "\n",
    "# concatenate\n",
    "glwd = pd.concat((glwd1, glwd2), axis=0)\n",
    "\n",
    "if not glwd.shape[0] == glofas5.GLWD_ID.notnull().sum():\n",
    "    print('The number of lakes in \"glwd\" does not match the number of lakes in \"glofas5\" with assigned GLWD_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31a5598-26a7-4fda-a49b-30899b162ccb",
   "metadata": {},
   "source": [
    "### HydroLakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a67ee93-9fe2-4089-82a6-6fc950e6c612",
   "metadata": {},
   "outputs": [],
   "source": [
    "hylak = gpd.read_file(PATH_GLOFAS5 / 'lakes' / 'hydrolakes_domain.shp').set_index('Hylak_id', drop=True)\n",
    "hylak = hylak.loc[hylak.index.intersection(glofas5.Hylak_id)]\n",
    "hylak.Grand_id = hylak.Grand_id.replace(0, np.nan).astype('Int64')\n",
    "\n",
    "if not hylak.shape[0] == glofas5.Hylak_id.nunique():\n",
    "    print('The number of lakes in \"hylak\" ({0}) does not match the number of lakes in \"glofas5\" with assigned Hylak_id ({1})'.format(hylak.shape[0], glofas5.Hylak_id.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fee4b83-4159-4be3-99aa-30f5cb7a240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hylak.Lake_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2264c736-4a0e-4aa1-8c2b-ff927ed4c207",
   "metadata": {},
   "source": [
    "There are 4 lakes in the selection which are considered as controlled lakes by HydroLakes, therefore, they have a `GRAND_ID` that I will add to the `glofas5` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff08592-0379-480f-bbc7-eb2536b53c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add GRAND_ID to lakes in GLOFAS5\n",
    "glofas5['GRanD_id'] = glofas5.Hylak_id.map(hylak.Grand_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a28ed3d-845c-411a-a2ff-03572a4770c4",
   "metadata": {},
   "source": [
    "## Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871ac1c6-16b3-47f1-9809-53be1ff87491",
   "metadata": {},
   "source": [
    "### Catchment area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02db1f14-f03b-4ea7-93d4-193858dea403",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment = pd.DataFrame(index=glofas5.index, columns=['UPAREA', 'GLWD', 'HYLAK', 'GLOFAS5', 'SOURCE'], dtype=float)\n",
    "catchment.SOURCE = catchment.SOURCE.astype(str)\n",
    "\n",
    "# upstream area map\n",
    "for ID, point in glofas5.geometry.items():\n",
    "    catchment.loc[ID, 'UPAREA'] = uparea.sel(x=point.x, y=point.y, method='nearest').item() * 1e-6\n",
    "\n",
    "# GLWD\n",
    "idx = glofas5[glofas5.GLWD_ID.notnull()].GLWD_ID\n",
    "catchment.loc[idx.index, 'GLWD'] = glwd.loc[idx.values, 'CATCH_TSKM'].values * 1e3\n",
    "\n",
    "# HydroLakes\n",
    "idx = glofas5[glofas5.Hylak_id.isin(hylak.index)].Hylak_id\n",
    "catchment.loc[idx.index, 'HYLAK'] = hylak.loc[idx.values, 'Wshd_area'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc77a2a5-2f01-476c-ba86-94759f625b3d",
   "metadata": {},
   "source": [
    "#### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a11c96-dbb7-4a45-99b9-ef51fe43b0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_attributes(\n",
    "    catchment[['UPAREA', 'GLWD', 'HYLAK']],\n",
    "    thr=MIN_AREA,\n",
    "    vmin=1,\n",
    "    vmax=1e7,\n",
    "    title='catchment (km²)'\n",
    ")\n",
    "# plt.savefig(PATH_OUT / 'plots' / 'catchment_pairplot.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02689d5a-885e-438a-8a81-eb0c05964af4",
   "metadata": {},
   "source": [
    "#### Select values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6c244f-02b1-4cfa-abff-3d00214089b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select value from GRAND, GLOFAS4, HYLAK or ICOLD in that order\n",
    "for source in ['HYLAK', 'GLWD', 'UPAREA']:\n",
    "    missing = catchment.GLOFAS5.isnull()\n",
    "    mask = catchment[source].notnull()\n",
    "    catchment.loc[missing & mask, 'GLOFAS5'] = catchment.loc[missing & mask, source]\n",
    "    catchment.loc[missing & mask, 'SOURCE'] = source\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 5), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='face', facecolor='lightgray'), alpha=.5, zorder=0)\n",
    "sct = ax.scatter(\n",
    "    glofas5.geometry.x,\n",
    "    glofas5.geometry.y,\n",
    "    c=np.log10(catchment.GLOFAS5),\n",
    "    cmap='viridis_r',\n",
    "    s=5,\n",
    "    # vmin=0,\n",
    "    # vmax=2.5\n",
    ")\n",
    "cbar = plt.colorbar(sct, shrink=.5, label='catchment (km2)')\n",
    "ticks = [2, 3, 4, 5]\n",
    "cbar.set_ticks(ticks)\n",
    "cbar.set_ticklabels([10**x for x in ticks])\n",
    "plt.axis('off');\n",
    "plt.savefig(PATH_OUT / 'plots' / 'catchment_map.jpg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# add values to GLOFAS5\n",
    "glofas5.loc[catchment.index, ['CATCH_SKM', 'CATCH_SRC']] = catchment[['GLOFAS5', 'SOURCE']].values\n",
    "print('{0} reservoirs do not comply with the minimum catchment area of {1} km²'.format((glofas5.CATCH_SKM < MIN_AREA).sum(),\n",
    "                                                                                       MIN_CATCHMENT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a8da2-cc3f-4cba-adb5-778be7ef5c77",
   "metadata": {},
   "source": [
    "### Lake area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ad6216-d39b-4932-a370-ff23b58e8ced",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "area = pd.DataFrame(index=glofas5.index, columns=['GLOFAS4', 'GLWD', 'HYLAK', 'GLOFAS5', 'SOURCE'], dtype=float)\n",
    "area.SOURCE = area.SOURCE.astype(str)\n",
    "\n",
    "# GLOFAS4\n",
    "idx = glofas5[glofas5.LakID.notnull()].LakID\n",
    "area.loc[idx.index, 'GLOFAS4'] = glofas4.loc[idx.values, 'area'].values\n",
    "\n",
    "# GLWD\n",
    "idx = glofas5[glofas5.GLWD_ID.notnull()].GLWD_ID\n",
    "area.loc[idx.index, 'GLWD'] = glwd.loc[idx.values, 'AREA_SKM'].values\n",
    "\n",
    "# HydroLakes\n",
    "idx = glofas5[glofas5.Hylak_id.isin(hylak.index)].Hylak_id\n",
    "# idx = glofas5[glofas5.Hylak_id.notnull()].Hylak_id\n",
    "area.loc[idx.index, 'HYLAK'] = hylak.loc[idx.values, 'Lake_area'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c3ede-0b2b-4cfc-8312-7de5ebca15c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "area.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7b1fb-c8d9-42ed-9442-f7cf729ed557",
   "metadata": {},
   "source": [
    "#### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188996c5-3df8-4abb-ae12-a1c248effbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_attributes(\n",
    "    area[['GLOFAS4', 'GLWD', 'HYLAK']],\n",
    "    thr=MIN_AREA,\n",
    "    vmin=1e-1,\n",
    "    vmax=1e6,\n",
    "    title='area (km2)'\n",
    ")\n",
    "plt.savefig(PATH_OUT / 'plots' / 'area_pairplot.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c906c-2031-438d-8587-b0f3001fa758",
   "metadata": {},
   "source": [
    "#### Select values\n",
    "\n",
    "Some `Hylak_id` are repeated in GLOFAS5 because HydroLakes considers as a single lake cases where GLWD (and therefore GLOFAS4) considers several lakes. Therefore, using the HYLAK value will overestimate total area. I will use as main source GLWD, then GLOFAS4 and lastly HYLAK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a0997-8358-479f-8289-ae279ac5b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select value from GRAND, GLOFAS4, HYLAK or ICOLD in that order\n",
    "for source in ['GLWD', 'GLOFAS4', 'HYLAK']:\n",
    "    missing = area.GLOFAS5.isnull()\n",
    "    mask = area[source].notnull()\n",
    "    area.loc[missing & mask, 'GLOFAS5'] = area.loc[missing & mask, source]\n",
    "    area.loc[missing & mask, 'SOURCE'] = source\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 5), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='face', facecolor='lightgray'), alpha=.5, zorder=0)\n",
    "sct = ax.scatter(\n",
    "    glofas5.geometry.x,\n",
    "    glofas5.geometry.y,\n",
    "    c=np.log10(area.GLOFAS5),\n",
    "    cmap='viridis_r',\n",
    "    s=5,\n",
    "    # vmin=0,\n",
    "    # vmax=2.5\n",
    ")\n",
    "cbar = plt.colorbar(sct, shrink=.5, label='area (km2)')\n",
    "ticks = [2, 3, 4]\n",
    "cbar.set_ticks(ticks)\n",
    "cbar.set_ticklabels([10**x for x in ticks])\n",
    "plt.axis('off');\n",
    "plt.savefig(PATH_OUT / 'plots' / 'area_map.jpg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# add values to GLOFAS5\n",
    "glofas5.loc[area.index, ['AREA_SKM', 'AREA_SRC']] = area[['GLOFAS5', 'SOURCE']].values\n",
    "\n",
    "print('{0} lakes do not comply with the minimum lake area of {1} km2'.format((glofas5.AREA_SKM < MIN_AREA).sum(),\n",
    "                                                                             MIN_AREA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7395c3dc-ecc5-41ad-a903-6c224421273b",
   "metadata": {},
   "source": [
    "### $\\alpha$: width of the outlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a947746-f2bb-440f-9b0a-abdb76bff9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = pd.DataFrame(index=glofas5.index, columns=['GLOFAS4', 'BUREK', 'EXP', 'CHANBW', 'GLOFAS5', 'SOURCE'], dtype=float)\n",
    "alpha.SOURCE = alpha.SOURCE.astype(str)\n",
    "\n",
    "# GLOFAS4\n",
    "idx = glofas5[glofas5.LakID.notnull()].LakID\n",
    "alpha.loc[idx.index, 'GLOFAS4'] = glofas4.loc[idx.values, 'alpha'].values\n",
    "\n",
    "# using Burek's formula\n",
    "alpha['BUREK'] = catchment.UPAREA * 0.0032\n",
    "\n",
    "# fit a exponential function to the GLOFAS4 data\n",
    "aux = glofas4[glofas4.alpha != glofas4.alpha.min()]\n",
    "params, covariance = curve_fit(width_from_area, aux.CATCH_AREA, aux.alpha, p0=[.5])\n",
    "print('c = {0:.2f}'.format(params[0]))\n",
    "alpha['EXP'] = width_from_area(glofas5.CATCH_SKM, c=params[0])\n",
    "\n",
    "# channel width\n",
    "for ID, point in glofas5.geometry.items():\n",
    "    alpha.loc[ID, 'CHANBW'] = outlet_width(chanbw, uparea, point.x, point.y, n_points=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6536c2-811f-40e7-8bcb-65daa5dc3264",
   "metadata": {},
   "source": [
    "#### Comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddce1ed-5a06-44c2-b751-f9cb3f661d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(ncols=3, figsize=(10, 3), sharex=True, sharey=True)\n",
    "\n",
    "# vmin, vmax = .01, 1000\n",
    "# for ax, col in zip(axes, ['CHANBW', 'BUREK', 'EXP']):\n",
    "#     ax.scatter(alpha[col], alpha.GLOFAS4, s=8, alpha=.5)\n",
    "#     ax.plot([vmin, vmax], [vmin, vmax], 'k', lw=.5, zorder=0)\n",
    "#     ax.set(\n",
    "#         xlabel=col,\n",
    "#         xscale='log',\n",
    "#         yscale='log'\n",
    "#     )\n",
    "#     if ax == axes[0]:\n",
    "#         ax.set_ylabel('GLOFAS4')\n",
    "#         ax.set(\n",
    "#             xlim=(vmin, vmax),\n",
    "#             ylim=(vmin, vmax)\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a90f921-eb21-49c0-abd5-bfcc49f687fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_attributes(\n",
    "    alpha[['GLOFAS4', 'BUREK', 'EXP', 'CHANBW']],\n",
    "    thr=0,\n",
    "    vmin=.1,\n",
    "    vmax=2000,\n",
    "    title='outlet width (m)'\n",
    ")\n",
    "plt.savefig(PATH_OUT / 'plots' / 'outlet_width_pairplot.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151ac77a-a17e-4ec7-8207-3b4a30383d80",
   "metadata": {},
   "source": [
    "#### Select values\n",
    "I select GLOFAS4 values, if possible. If not, I will use the exponential function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12260f6b-6bdf-4fde-9682-b6d03d465950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select value from GRAND, GLOFAS4, HYLAK or ICOLD in that order\n",
    "for source in ['GLOFAS4', 'EXP']:\n",
    "    missing = alpha.GLOFAS5.isnull()\n",
    "    mask = alpha[source].notnull()\n",
    "    alpha.loc[missing & mask, 'GLOFAS5'] = alpha.loc[missing & mask, source]\n",
    "    alpha.loc[missing & mask, 'SOURCE'] = source\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 5), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='face', facecolor='lightgray'), alpha=.5, zorder=0)\n",
    "sct = ax.scatter(\n",
    "    glofas5.geometry.x,\n",
    "    glofas5.geometry.y,\n",
    "    c=alpha.GLOFAS5,\n",
    "    cmap='viridis_r',\n",
    "    s=5,\n",
    "    # vmin=0,\n",
    "    # vmax=2.5\n",
    ")\n",
    "cbar = plt.colorbar(sct, shrink=.5, label='outlet width (m)')\n",
    "plt.axis('off');\n",
    "# plt.savefig(PATH_OUT / 'plots' / 'outlet_width_map.jpg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# add values to GLOFAS5\n",
    "glofas5.loc[alpha.index, ['WIDTH_M', 'WIDTH_SRC']] = alpha[['GLOFAS5', 'SOURCE']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd2421d-2532-4ee0-814d-dfa48675830f",
   "metadata": {},
   "source": [
    "### Average inflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee38b3e4-5663-4a29-abe4-2fa2bc7431a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_avg = pd.DataFrame(index=glofas5.index, columns=['GLOFAS4', 'NAT_FLOW', 'GLWD', 'HYLAK', 'GLOFAS5', 'SOURCE'], dtype=float)\n",
    "dis_avg.SOURCE = alpha.SOURCE.astype(str)\n",
    "\n",
    "# GLOFAS4\n",
    "idx = glofas5[glofas5.LakID.notnull()].LakID\n",
    "dis_avg.loc[idx.index, 'GLOFAS4'] = glofas4.loc[idx.values, 'avinflow'].values\n",
    "\n",
    "# GLOFAS4 naturalised long-term run \n",
    "dis = xr.open_dataset(PATH_GLOFAS5 / 'lakes' / 'ncextract' / 'dis_215.nc')['dis']\n",
    "dis = dis.sel(time=slice('1993-01-02', None))\n",
    "dis.close()\n",
    "dis_avg['NAT_FLOW'] = dis.mean('time').to_pandas()\n",
    "\n",
    "# GLWD\n",
    "idx = glofas5[glofas5.GLWD_ID.notnull()].GLWD_ID\n",
    "dis_avg.loc[idx.index, 'GLWD'] = glwd.loc[idx.values, 'INFLOW_CMS'].values\n",
    "\n",
    "# HydroLakes\n",
    "idx = glofas5[glofas5.Hylak_id.isin(hylak.index)].Hylak_id\n",
    "dis_avg.loc[idx.index, 'HYLAK'] = hylak.loc[idx.values, 'Dis_avg'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe43d43-9b93-4b50-ab14-71ba1b5c90eb",
   "metadata": {},
   "source": [
    "#### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ebb35-b371-45bf-95e5-dbd918c052ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_attributes(\n",
    "    dis_avg[['GLOFAS4', 'NAT_FLOW', 'GLWD', 'HYLAK']],\n",
    "    thr=0,\n",
    "    vmin=0.01,\n",
    "    vmax=1000,\n",
    "    title='average inflow (m3/s)'\n",
    ")\n",
    "plt.savefig(PATH_OUT / 'plots' / 'dis_avg_pairplot.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792aeb1c-b671-4652-96e3-a952774ab00a",
   "metadata": {},
   "source": [
    "#### Select value\n",
    "\n",
    "I will select in all cases the value from the GLOFAS4 naturalised run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6804a2a-05d7-418e-be76-566dc46bfb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_avg.GLOFAS5 = dis_avg.NAT_FLOW\n",
    "dis_avg.SOURCE = 'GLOFAS4_natflow' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cbf29f-a48e-46e8-a8f8-8dccb7485eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 5), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='face', facecolor='lightgray'), alpha=.5, zorder=0)\n",
    "sct = ax.scatter(\n",
    "    glofas5.geometry.x,\n",
    "    glofas5.geometry.y,\n",
    "    c=dis_avg.GLOFAS5 / glofas5.CATCH_SKM * 3.6 * 24,\n",
    "    cmap='viridis_r',\n",
    "    s=5,\n",
    ")\n",
    "cbar = plt.colorbar(sct, shrink=.5, label='average discharge\\n(mm/day)')\n",
    "plt.axis('off');\n",
    "# plt.savefig(PATH_OUT / 'plots' / 'dis_avg_map.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91533c67-0d78-4b04-b33b-e89b6e2397c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add values to GLOFAS5\n",
    "glofas5.loc[alpha.index, ['DISAVG_CMS', 'DIS_SRC']] = dis_avg[['GLOFAS5', 'SOURCE']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81182569-f5c8-4a07-8cef-5a68d841fd1a",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9980a4fb-bc2a-40f5-a8cb-bab80b365285",
   "metadata": {},
   "outputs": [],
   "source": [
    "lakes = glofas5.copy()\n",
    "\n",
    "# add coordinates in the LISFLOOD grid\n",
    "lakes['LisfloodX'] = lakes.geometry.x\n",
    "lakes['LisfloodY'] = lakes.geometry.y\n",
    "\n",
    "# add info from HydroLakes\n",
    "hylak_ids = lakes.Hylak_id.dropna()\n",
    "hylak_cols = {'Lake_name': 'LAKE_NAME', \n",
    "              'Country': 'COUNTRY',\n",
    "              'Pour_long': 'LONG_DD',\n",
    "              'Pour_lat': 'LAT_DD'}\n",
    "lakes.loc[hylak_ids.index, hylak_cols.values()] = hylak.loc[hylak_ids.values, hylak_cols].rename(columns=hylak_cols).values\n",
    "\n",
    "# reorder columns\n",
    "cols = ['LakID', 'ResID', 'GLWD_ID', 'Hylak_id', 'GRanD_id', 'ICOLD_id',\n",
    "        'LAKE_NAME', 'COUNTRY', \n",
    "        'LONG_DD', 'LAT_DD', 'LisfloodX', 'LisfloodY', \n",
    "        'CATCH_SKM', 'CATCH_SRC', 'AREA_SKM', 'AREA_SRC', 'WIDTH_M', 'WIDTH_SRC', 'DISAVG_CMS', 'DIS_SRC']\n",
    "lakes = lakes[lakes.columns.intersection(cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db07298-3340-428b-b2fc-9b376e87345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute outlet widht of reservoirs\n",
    "reservoirs['WIDTH_M'] = width_from_area(reservoirs.CATCH_SKM, c=params[0])\n",
    "reservoirs['WIDTH_SRC'] = 'EXP'\n",
    "# rename and reorder columns\n",
    "reservoirs.rename(columns={'RES_NAME': 'LAKE_NAME'}, inplace=True, errors='ignore')\n",
    "reservoirs = reservoirs[reservoirs.columns.intersection(cols)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fe0c4a-3cae-48ee-9adc-cb3e18bb018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "lakes_reservoirs = pd.concat((lakes, reservoirs), axis=0)[cols]\n",
    "lakes_reservoirs.sort_values(['LakID', 'ResID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7c6118-07db-4fd6-aea1-0867ea131d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "# reservoirs['FID'] = np.arange(1, reservoirs.shape[0] + 1)\n",
    "# reservoirs.loc[reservoirs.ResID > 5000, 'FID'] = reservoirs.loc[reservoirs.ResID > 5000, 'ResID']\n",
    "idx = []\n",
    "i = 1000\n",
    "for lak_id in lakes_reservoirs.LakID.values:\n",
    "    if pd.isna(lak_id):\n",
    "        i += 1\n",
    "        idx.append(i)\n",
    "    else:\n",
    "        idx.append(lak_id)\n",
    "lakes_reservoirs['FID'] = idx\n",
    "lakes_reservoirs.set_index('FID', drop=True, inplace=True)\n",
    "lakes_reservoirs.sort_index(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbce7d8-7274-4056-867a-a21d83d19948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "lakes_reservoirs.to_excel(PATH_OUT / 'glofas5_lakes.xlsx', float_format='%.4f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
