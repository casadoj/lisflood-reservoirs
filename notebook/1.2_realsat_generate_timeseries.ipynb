{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JS_xWrkIlVK"
   },
   "source": [
    "# ReaLSAT: Reservoir and Lake Surface Area Timseries Dataset\n",
    "\n",
    "*   This notebook acommpanies the ReaLSAT dataset available at https://zenodo.org/record/5039223\n",
    "\n",
    "*   The notebook enables generation of surface area extents (and timeseries) of any ReaLSAT waterbody using GSW's global pixel maps[1] at monthly scale as input and the ORBIT framework[2].\n",
    "\n",
    "*   The notebook assumes Google Colab as the running environment. The users are encouraged to adapt the code by installing required packages locally in order to use the notebook outside Google Colab.\n",
    "\n",
    "*   The code requires authentication to use Google Earth Engine's API as well as Google Drive.\n",
    "\n",
    "*   The code also requires the base shapefile containing ReaLSAT waterbodies to be present in a Google Drive folder.\n",
    "\n",
    "\n",
    "\n",
    "####  \n",
    "\n",
    "##### 1. Pekel, J. F., Cottam, A., Gorelick, N., & Belward, A. S. (2016). High-resolution mapping of global surface water and its long-term changes. Nature, 540(7633), 418-422.\n",
    "\n",
    "##### 2.Khandelwal, A. (2019). ORBIT (Ordering Based Information Transfer): A Physics Guided Machine Learning Framework to Monitor the Dynamics of Water Bodies at a Global Scale (Doctoral dissertation, University of Minnesota)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNh-QBc36Mvk"
   },
   "source": [
    "### Import packages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65RChERMzQHZ"
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "from google.colab import drive\n",
    "!pip install geopandas\n",
    "import geopandas\n",
    "import json\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import gdal\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import skimage.measure\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-dN42MTzg-w"
   },
   "source": [
    "### Authenticate APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NMp9Ei9b0XXL"
   },
   "outputs": [],
   "source": [
    "# Trigger the authentication for Google Earth Engine API\n",
    "# The code will ask to paste the token in the input box\n",
    "ee.Authenticate()\n",
    "\n",
    "# Initialize the library.\n",
    "ee.Initialize()\n",
    "\n",
    "\n",
    "#mount google drive\n",
    "# The code will ask to paste the token in the input box \n",
    "drive.mount('/content/gdrive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bujZxOoSBtG8"
   },
   "source": [
    "### Load ReaLSAT waterbodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wky2ThAIBI1w"
   },
   "outputs": [],
   "source": [
    "google_drive_folder = 'ReaLSAT_ORBIT' # ensure that this folder exists in your google drive\n",
    "realsat_file_name = 'ReaLSAT' # name of the shapefile that contains the reference shape of all waterbodies. This shapefile should be the above google drive folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gIO08OHzjUcP"
   },
   "outputs": [],
   "source": [
    "### load ReaLSAT base shapefile\n",
    "realsat = geopandas.read_file('/content/gdrive/MyDrive/' + google_drive_folder + '/' + realsat_file_name + '.shp')\n",
    "realsat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjZtlCqxB2Fw"
   },
   "source": [
    "### extract GSW monthly maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEcZMy7vKfbf"
   },
   "outputs": [],
   "source": [
    "# use any geospatial analyis software (e.g. QGIS) to visualize waterbodies in realsat shapefile and select the ID to process.\n",
    "ID = 447286 # an agricultural reservoir in Uruguay.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7RFEyyvIh2fC"
   },
   "outputs": [],
   "source": [
    "# extract bounding box\n",
    "geom = realsat[realsat['ID']==ID].buffer(0.01).iloc[0]\n",
    "g = json.loads(realsat[realsat['ID']==ID].buffer(0.01).to_json())\n",
    "coords = np.array(g['features'][0]['geometry']['coordinates']).tolist()\n",
    "bbox = ee.Geometry.Polygon(coords)\n",
    "\n",
    "# load GSW monthly maps\n",
    "jrc_ee = ee.ImageCollection(\"JRC/GSW1_3/MonthlyHistory\").toBands().clip(bbox)\n",
    "\n",
    "# download the clipped monthly maps in the google drive folder\n",
    "task = ee.batch.Export.image.toDrive(image=jrc_ee,\n",
    "                                     description='montly maps',\n",
    "                                     scale=30,\n",
    "                                     region=bbox,\n",
    "                                     fileNamePrefix='ID_' + str(ID).zfill(6),\n",
    "                                     folder= google_drive_folder,\n",
    "                                     crs='EPSG:4326',\n",
    "                                     maxPixels= 1e13,\n",
    "                                     fileFormat='GeoTIFF')\n",
    "task.start()\n",
    "while(1):\n",
    "  print('task status: ' + task.status()['state'])\n",
    "  if task.status()['state']=='COMPLETED':\n",
    "    break\n",
    "  time.sleep(10)\n",
    "  clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72-mc9bgCBh2"
   },
   "source": [
    "#### Preprocess monthly maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpVUeZUIwCKz"
   },
   "outputs": [],
   "source": [
    "# utility function to convert a python n-d array to a geotiff file\n",
    "def create_geo_tiff(data,outfile,basefile,odtype):\n",
    "    rasterFormat = 'GTiff' # for now assuming output format is going to GTiff\n",
    "    rasterDriver = gdal.GetDriverByName(rasterFormat)\n",
    "    ds = gdal.Open(basefile)\n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    projection = ds.GetProjection()\n",
    "\n",
    "\n",
    "    band = ds.GetRasterBand(1)\n",
    "    full_xsize = band.XSize\n",
    "    full_ysize = band.YSize\n",
    "    ds = None\n",
    "    mds = rasterDriver.Create(outfile,full_xsize,full_ysize,data.shape[2],odtype)\n",
    "    mds.SetGeoTransform(geotransform)\n",
    "    mds.SetProjection(projection)\n",
    "    # initializing data array and putting zero filled bands in the prediction raster\n",
    "    for i in range(data.shape[2]):\n",
    "        mds.GetRasterBand(i+1).WriteArray(data[:,:,i])\n",
    "    # closing datasets\n",
    "    mds = None\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7pD6pDOAhOW"
   },
   "outputs": [],
   "source": [
    "# load monthly maps\n",
    "input_jrc = gdal.Open('/content/gdrive/MyDrive/' + google_drive_folder + '/ID_' + str(ID).zfill(6) + '.tif',0).ReadAsArray()\n",
    "T,row,col = input_jrc.shape\n",
    "\n",
    "# reshuffle pixel labels, before reshuffle land is 1, water is 2, and unknown is 0\n",
    "input_jrc[input_jrc==0] = 3\n",
    "input_jrc[input_jrc==1] = 0\n",
    "input_jrc[input_jrc==2] = 1\n",
    "input_jrc[input_jrc==3] = 2\n",
    "# after reshuffle, land is 0, water is 1, and unknown is 2\n",
    "\n",
    "# calculate % timesteps where a pixel is water\n",
    "occurrence = np.sum(input_jrc==1,axis=0)*1.0/np.sum(input_jrc<=1,axis=0)\n",
    "\n",
    "# prepare an empty tif file to map the selected waterbody's reference shape on pixels in the array\n",
    "base_data = np.expand_dims(input_jrc[0]*0.0,axis=2)\n",
    "create_geo_tiff(base_data,'/content/gdrive/MyDrive/' + google_drive_folder + '/ID_' + str(ID).zfill(6) + '_ref.tif','/content/gdrive/MyDrive/' + google_drive_folder + '/ID_' + str(ID).zfill(6) + '.tif',gdal.GDT_Int32)\n",
    "os.system('gdal_rasterize -a ID -l ' + realsat_file_name + ' ' + '/content/gdrive/MyDrive/' + google_drive_folder + '/' + realsat_file_name + '.shp ' + '/content/gdrive/MyDrive/' + google_drive_folder + '/ID_' + str(ID).zfill(6) + '_ref.tif')\n",
    "\n",
    "# load the reference shape mask\n",
    "mask = gdal.Open('/content/gdrive/MyDrive/' + google_drive_folder + '/ID_' + str(ID).zfill(6) + '_ref.tif',0).ReadAsArray()==ID\n",
    "\n",
    "# identify pixels that are not part of the selected lake\n",
    "# array to count number of timesteps a pixel is not a part of a connected component\n",
    "# that overlaps with the reference shape\n",
    "unconnected_count = np.zeros((row,col))\n",
    "# looping through each timestep\n",
    "for t in tqdm(range(T)):\n",
    "  cur_extent_map = input_jrc[t]\n",
    "  cur_conn_comps = skimage.measure.label(cur_extent_map==1)\n",
    "  ulabels = np.unique(cur_conn_comps)\n",
    "  # if the map is completely dry, skip\n",
    "  if len(ulabels)==1:\n",
    "    continue\n",
    "  ulabels = ulabels[1:] # remove background class (0)\n",
    "  for ulabel in ulabels:\n",
    "    cur_comp = cur_conn_comps==ulabel\n",
    "    if np.sum(cur_comp[mask])==0: # zero overlap with reference shape\n",
    "      unconnected_count[cur_comp] =  unconnected_count[cur_comp] + 1\n",
    "\n",
    "\n",
    "# remove pixels that are unconnected \n",
    "exclude_map = np.logical_or(np.isnan(occurrence),np.logical_and(occurrence>0,unconnected_count>5))\n",
    "\n",
    "# identify pixels that are always water or land to avoid unneccessary computations for ORBIT based label correction\n",
    "permanent_water = np.logical_and(occurrence>0.99,exclude_map==0)\n",
    "permanent_land = np.logical_and(occurrence<0.01,exclude_map==0)\n",
    "\n",
    "# identify dynamic pixel\n",
    "dynamic_pixels = np.logical_and(np.logical_and(exclude_map==0,permanent_water==0),permanent_land==0)\n",
    "dynamic_indices = np.where(dynamic_pixels.flatten()==1)[0]\n",
    "\n",
    "D  = np.sum(dynamic_pixels==1)\n",
    "\n",
    "# convert flatten each timestep to prepare array for ORBIT based correction workflow.\n",
    "input_stack = np.zeros((D,T))\n",
    "for t in tqdm(range(T)):\n",
    "  temp = input_jrc[t].flatten()\n",
    "  input_stack[:,t] = temp[dynamic_indices]\n",
    "\n",
    "\n",
    "# visualize different pixel categories\n",
    "f,ax = plt.subplots(1,6,figsize=(15,5))\n",
    "ax[0].imshow(occurrence)\n",
    "ax[0].set_title('Occurrence Map')\n",
    "ax[1].imshow(mask)\n",
    "ax[1].set_title('Reference Shape')\n",
    "ax[2].imshow(permanent_water)\n",
    "ax[2].set_title('Permanent Water')\n",
    "ax[3].imshow(permanent_land)\n",
    "ax[3].set_title('Permanent Land')\n",
    "ax[4].imshow(dynamic_pixels)\n",
    "ax[4].set_title('Dynamic Pixels')\n",
    "ax[5].imshow(exclude_map)\n",
    "ax[5].set_title('Excluded Pixels')\n",
    "plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNXcwKQkJ_V9"
   },
   "source": [
    "#### ORBIT based label correction and imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7n96WbyKA7-"
   },
   "outputs": [],
   "source": [
    "# Procedure to correct and impute labels to most likely labels.\n",
    "# Please see the following citations for more details: \n",
    "\n",
    "def ORBIT_S(data):\n",
    "  N,T = data.shape\n",
    "  cor_data = np.zeros((data.shape))\n",
    "  for t in range(T):\n",
    "    ord_labels = data[:,t]\n",
    "    ord_labels = np.append(0,ord_labels)\n",
    "    sum1 = np.cumsum(ord_labels)\n",
    "    sum2 = np.cumsum(1 - ord_labels)\n",
    "    score = sum1 + np.sum(sum2) - sum2\n",
    "    ind = np.argmin(score)\n",
    "\n",
    "    new_labels = ord_labels.copy()\n",
    "    new_labels[:] = 0\n",
    "    new_labels[0:ind] = 0\n",
    "    new_labels[ind:] = 1\n",
    "    new_labels = new_labels[1:]\n",
    "    cor_data[:,t] = new_labels\n",
    "  return cor_data\n",
    "    \n",
    "\n",
    "# learns a relative elevation ordering using multi-temporal extent maps\n",
    "def get_relative_elvation_ordering(data,max_iterations=10):\n",
    "  \n",
    "  data[data==2] = 0.5 # replace missing pixels with 0.5 to represent equal chance of being land or water\n",
    "  N,T = data.shape\n",
    "  dix = np.random.permutation(N) # initialize ordering\n",
    "  ord_data = data[dix,:]\n",
    "  wcount = np.sum(ord_data==1,axis=1)*1.0/np.sum(ord_data<=1,axis=1)\n",
    "  est_err = []\n",
    "  for inum in range(max_iterations):\n",
    "    cor_data = ORBIT_S(ord_data.copy()) # correct and impute pixels based on current ordering\n",
    "    \n",
    "    # calculate cost of current ordering. Low cost means less changes to input labels to achieve physical consistency\n",
    "    ers = np.sum(np.abs(cor_data-ord_data)) \n",
    "    est_err.append(ers)\n",
    "    print('Loss at iteration {}: {}'.format(inum,ers))\n",
    "    # stop at convergence\n",
    "    if len(est_err)>1 and est_err[-1]>=est_err[-2]:\n",
    "        break\n",
    "\n",
    "    #calculate new ordering \n",
    "    Mmat = np.zeros((N,))\n",
    "    for i in tqdm(range(N)):\n",
    "        cur_label = np.expand_dims(ord_data[i,:],axis=0)\n",
    "        cur_label = np.repeat(cur_label,N,axis=0)\n",
    "        diff_label = np.abs(cor_data-cur_label)\n",
    "        diff_count = np.sum(diff_label,axis=1)\n",
    "        min_inds = diff_count==np.min(diff_count)\n",
    "        \n",
    "        # breaking across-profile tie by picking the elevation profile with \n",
    "        # largest rank in the current iteration\n",
    "        last_ind = np.where(min_inds==1)[0][-1]\n",
    "\n",
    "        # breaking tie randomly\n",
    "        # last_ind = np.random.permutation(np.where(min_inds==1)[0])[0]\n",
    "        \n",
    "        Mmat[i] = last_ind\n",
    "    \n",
    "    tinfo = [(Mmat[i],wcount[i]) for i in range(N)]\n",
    "    tinfo = np.array(tinfo,dtype=np.dtype([('x', float), ('y', float)]))\n",
    "    fix = np.argsort(tinfo)\n",
    "    # print(fix.shape)\n",
    "    ord_data = ord_data[fix,:]\n",
    "    dix = dix[fix]\n",
    "    wcount = np.sum(ord_data==1,axis=1)*1.0/np.sum(ord_data<=1,axis=1)\n",
    "\n",
    "  return dix\n",
    "    \n",
    "\n",
    "# use dynamic programming to generate temporally smooth extent maps\n",
    "def ORBIT_T(local_score,cth):\n",
    "\n",
    "    row,col = local_score.shape\n",
    "    best_score = np.zeros((row,col))\n",
    "    best_score[:,0] = local_score[:,0]\n",
    "    best_index = np.zeros((row,col))\n",
    "    row_base = np.arange(row)\n",
    "    for j in tqdm(range(1,col)):\n",
    "        for i in range(row):\n",
    "            trn_cost = np.abs(i-row_base)*1.0*cth\n",
    "            lcl_cost = local_score[i,j]\n",
    "            prv_cost = best_score[:,j-1]\n",
    "            ttl_cost = trn_cost + lcl_cost + prv_cost\n",
    "            bst_cost = np.min(ttl_cost)\n",
    "            bst_indx = np.argmin(ttl_cost)\n",
    "            best_score[i,j] = bst_cost\n",
    "            best_index[i,j] = bst_indx\n",
    "\n",
    "    cuts = np.zeros((col,))\n",
    "    bst_cst = best_score[:,-1]\n",
    "    bst_ind = int(np.argmin(bst_cst))\n",
    "\n",
    "    for j in range(col-1,-1,-1):\n",
    "        cuts[j] = bst_ind\n",
    "        bst_ind = int(best_index[bst_ind,j])\n",
    "\n",
    "    return cuts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tdhr9OGuKHxW"
   },
   "outputs": [],
   "source": [
    "ix_orbit = get_relative_elvation_ordering(input_stack.copy(),max_iterations=10)\n",
    "\n",
    "ord_labels = np.zeros((D+1,T))\n",
    "ord_labels[1:,:] = input_stack[ix_orbit,:]\n",
    "weight = 3.0 # penality on changing water pixels compared to land pixels\n",
    "thr = 0.3 # smoothness parameter: higher value would lead to more smoothing\n",
    "sum1 = np.cumsum(ord_labels==1,axis=0)*weight\n",
    "sum2 = np.cumsum(ord_labels==0,axis=0)\n",
    "score = sum1 + np.sum(sum2) - sum2\n",
    "print('running ORBIT-T')\n",
    "cuts = ORBIT_T(score.copy(),thr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PdvW-h8YN26Q"
   },
   "outputs": [],
   "source": [
    "# array to store updated extent maps\n",
    "orbit_stack = np.zeros((row,col,T)).astype(np.uint8)\n",
    "\n",
    "jrc_timeseries = np.zeros((T,))\n",
    "orbit_timeseries = np.zeros((T,))\n",
    "for t in tqdm(range(T)):\n",
    "    cur_cut = int(cuts[t])\n",
    "    cur_map = np.zeros((D,))\n",
    "    cur_map[cur_cut:] = 1\n",
    "    cur_map_full = np.zeros((row*col,))\n",
    "    cur_map_full[dynamic_indices[ix_orbit]] = cur_map\n",
    "    cur_map_full = np.reshape(cur_map_full.copy(),(row,col))\n",
    "    cur_map_full[permanent_land] = 0\n",
    "    cur_map_full[permanent_water] = 1\n",
    "    orbit_stack[:,:,t] = cur_map_full\n",
    "    jrc_timeseries[t] = np.sum(input_jrc[t][exclude_map==0]==1)\n",
    "    orbit_timeseries[t]= np.sum(cur_map_full[exclude_map==0]==1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KquGVBDuT3z-"
   },
   "outputs": [],
   "source": [
    "# compare GSW based timeseries with ORBIT based timeseries\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(jrc_timeseries,'.-r',label='JRC Area')\n",
    "plt.plot(orbit_timeseries,'.-b',label='ORBIT Area')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m-U1g93uUvlI"
   },
   "outputs": [],
   "source": [
    "# extract date information\n",
    "date_list = []\n",
    "temp = jrc_ee.getInfo()\n",
    "for t in tqdm(range(T)):\n",
    "  date_list.append(temp['bands'][t]['id'][0:7])\n",
    "\n",
    "# visualize and compare surface extent maps\n",
    "for t in range(300,T):\n",
    "  print(t,date_list[t])\n",
    "  fig = plt.figure(figsize=(20, 5))\n",
    "  ax1= fig.add_subplot(1,4,1)\n",
    "  ax2= fig.add_subplot(1,4,2)\n",
    "  ax3= fig.add_subplot(1,2,2)\n",
    "\n",
    "  cur_jrc = input_jrc[t]\n",
    "  ax1.imshow(input_jrc[t],vmin=0,vmax=2)\n",
    "  ax2.imshow(orbit_stack[:,:,t],vmin=0,vmax=2)\n",
    "  ax1.set_title('JRC Map')\n",
    "  ax2.set_title('ORBIT Map')\n",
    "  ax3.plot(jrc_timeseries,'.-r',label='JRC Area')\n",
    "  ax3.plot(orbit_timeseries,'.-b',label='ORBIT Area')\n",
    "  ax3.plot([t,t],[0,np.max(orbit_timeseries)],'--k')\n",
    "  ax3.set_title(date_list[t])\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "  time.sleep(1)\n",
    "  clear_output(wait=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0FZE2Fp6RDRF"
   },
   "outputs": [],
   "source": [
    "#reshuffle pixel labels to match GSW categories\n",
    "orbit_stack[orbit_stack==0] = 3\n",
    "orbit_stack[orbit_stack==2] = 0\n",
    "orbit_stack[orbit_stack==1] = 2\n",
    "orbit_stack[orbit_stack==3] = 1\n",
    "\n",
    "# save updated labels\n",
    "create_geo_tiff(orbit_stack,'/content/gdrive/MyDrive/' + google_drive_folder + '/ID_' + str(ID).zfill(6) + '_orbit_updated.tif','/content/gdrive/MyDrive/' + google_drive_folder + '/ID_' + str(ID).zfill(6) + '.tif',gdal.GDT_Byte)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "generate_realsat_timeseries.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
