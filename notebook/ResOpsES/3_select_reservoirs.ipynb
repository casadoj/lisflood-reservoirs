{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7bfb620-0515-4bbe-adde-71b978d69700",
   "metadata": {},
   "source": [
    "# Select reservoirs\n",
    "***\n",
    "\n",
    "**_Autor:_** Chus Casado Rodríguez<br>\n",
    "**_Fecha:_** 01-08-2024<br>\n",
    "\n",
    "**Introduction:**<br>\n",
    "This code compares the available attributes for reservoirs in Spain from different sources: the Spanish Ministry, ICOLD, GRanD.\n",
    "\n",
    "**To be checked:**<br>\n",
    "* [ ] The field `cedex_dam.Qspill_EFL` is mostly empty.\n",
    "* [x] There's a erroneous reservoir in EFAS. \"El Alisillo\" (ResID=3247) does not refer to any real reservoir, but it's very closely located to the \"Montoro III\" reservoir. The attributes don't much, though, so it's not a matter of just renaming the reservoir. <font color='steelblue'>I have created a new reservoir to represent \"Montoro III\"</font>.\n",
    "* [ ] How to proceed when there are several reservoirs in a continuous chain. For instance, Torrejón-Tajo and Arrocampo, or Tanes and Rioseco. Should we simulate each of them, or simply simulate them as a single reservoir with the aggregated volume?\n",
    "* [x] Attributes from GRanD\n",
    "* [x] Compare attributes among data sources: reservoir volume, etc.\n",
    "* [x] Should I include in the tables of attributes only the reservoirs with time series, or all the reservoirs? <font color='steelblue'>I have included all the reservoirs, so they can be later on used for regionalization, i.e., to estimate their reservoir parameters based on the attributes even though there aren't records.\n",
    "* [ ] Filter reservoirs by the length of their observed time series (for instance, longer than 8 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a2b1a8-f344-4eb6-88fb-d716498dcd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "from pathlib import Path\n",
    "# import sys\n",
    "# sys.path.append('../../src/')\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import seaborn as sns\n",
    "sns.set_style('ticks')\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "581df1aa-482f-4a01-b0e8-5719eba0be37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lisfloodreservoirs.utils import DatasetConfig\n",
    "from lisfloodreservoirs.utils.SNCZI import reservoir_attributes, dam_attributes\n",
    "from lisfloodreservoirs.utils.names import remove_accents, correct_names\n",
    "from lisfloodreservoirs.utils.utils import filter_reservoirs, remove_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f067fcc-f130-499a-b7d4-a78af3eb919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f8d181-fc8f-4b5b-87dd-46f1b68d2830",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbb6d051-97ca-4f21-a6eb-8d3cfa545d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = DatasetConfig('config_dataset.yml')\n",
    "\n",
    "# path where plots will be saved\n",
    "PATH_PLOTS = cfg.PATH_ATTRS / 'plots'\n",
    "PATH_PLOTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# path of the Spanish Inventory of Dams and Reservoirs\n",
    "PATH_DATASETS = Path('Z:/nahaUsers/casadje/datasets')\n",
    "PATH_SNCZI = PATH_DATASETS / 'SNCZI' / 'reports' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7370645-04b8-4d5c-9a7c-110cbdc0330b",
   "metadata": {},
   "source": [
    "## CEDEX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011afccc-5c7d-44e1-9faa-f9e566aefb01",
   "metadata": {},
   "source": [
    "### Reservoir attributes\n",
    "\n",
    "There are several attributes of interest in this table:\n",
    "\n",
    "* Coordinates.\n",
    "* Reservoir volume: both total and live volume.\n",
    "* Reservoir area.\n",
    "* Design reservoir levels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abaab52-bc1f-4c5d-a02e-7092748668bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load reservoir attributes\n",
    "cedex_res = pd.read_csv(PATH_SNCZI / 'reservoirs' / 'attributes_reservoirs.csv', index_col='res_ID')\n",
    "cedex_res.inf_ID = cedex_res.inf_ID.astype('Int64')\n",
    "\n",
    "# rename columns\n",
    "rename_cols = {'Código del embalse': 'res_ID',\n",
    "               'Nombre del embalse': 'RES_NAME',\n",
    "               'Titular del embalse': 'owner',\n",
    "               'Coord. X ETRS89': 'LON', # longitude\n",
    "               'Coord. Y ETRS89': 'LAT', # latitud\n",
    "               'Coord. X UTM ETRS89 Huso 30': 'X',\n",
    "               'Coord. Y UTM ETRS89 Huso 30': 'Y',\n",
    "               'Coord. X Manual': 'X_manual',\n",
    "               'Coord. Y Manual': 'Y_manual',\n",
    "               'Volumen útil (m3)': 'V_live',\n",
    "               'Volumen total (m3)': 'CAP_MCM',\n",
    "               'Superficie del embalse (has)': 'AREA_SKM',\n",
    "               'Máximo nivel de avenida (m)': 'Z_EFL', # Extreme Flood Level\n",
    "               'Máximo nivel normal del embalse (m)': 'Z_MNL', # Maximum Normal Level\n",
    "               'Municipio': 'town', \n",
    "               'Id. Hoja 1:50.000': 'sheet_MTN50',\n",
    "               'Cauce': 'river', \n",
    "               'Código de infraestructura': 'inf_ID', \n",
    "               'Nombre de la presa': 'DAM_NAME'}\n",
    "cedex_res.rename(columns=rename_cols, inplace=True)\n",
    "\n",
    "# correct names\n",
    "for col in ['RES_NAME', 'DAM_NAME']:\n",
    "    cedex_res[col] = cedex_res[col].replace(np.nan, '')\n",
    "    cedex_res[col] = [remove_accents(name) for name in cedex_res[col]]\n",
    "\n",
    "# convert reservoir area to km2\n",
    "cedex_res.AREA_SKM /= 100\n",
    "\n",
    "# remove duplicated entries keeping the largest reservoir\n",
    "remove_duplicates(cedex_res, 'RES_NAME', 'CAP_MCM')\n",
    "        \n",
    "print('Imported from SNCZI {0} reservoirs and {1} attributes'.format(*cedex_res.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914e15f9-4b2f-4149-aada-d8db85dd52bc",
   "metadata": {},
   "source": [
    "### Dam attributes\n",
    "\n",
    "This dataset contains multiple attributes of interes:\n",
    "\n",
    "* Date of construction.\n",
    "* Coordinates.\n",
    "* Reservoir use.\n",
    "* Catchment area.\n",
    "* Reservoir level, surface and volume at the maximum normal level (MNL).\n",
    "* Elevation of river, foundation, crest.\n",
    "* Number of outlets (spillways and sluices) and their discharge capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6024113e-50db-4851-975d-89f67b7b789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dam attributes\n",
    "cedex_dam = pd.read_csv(PATH_SNCZI / 'dams' / 'attributes_dams.csv', index_col='inf_ID')\n",
    "\n",
    "# rename columns\n",
    "rename_cols = {'Nombre de la presa': 'DAM_NAME',\n",
    "               'Otro Nombre': 'other_name',\n",
    "               'Fase vida presa': 'phase',\n",
    "               'Titular de la presa': 'owner',\n",
    "               'Proyectista': 'designer',\n",
    "               'Categoría en función del riesgo potencial': 'category',\n",
    "               'Aprobación de las normas de explotación': 'date_exploitation_plan',\n",
    "               'Aprobación del plan de emergencia': 'date_emergency_plan',\n",
    "               'Fecha de finalización de las obras': 'date_construction',\n",
    "               'Río en el que se encuentra la presa': 'river', \n",
    "               'Municipio': 'town',\n",
    "               'Cuenca hidrográfica': 'basin', \n",
    "               'Provincia': 'province', \n",
    "               'X-UTM30ETRS89': 'X', \n",
    "               'Y-UTM30ETRS89': 'Y',\n",
    "               'Usuarios': 'users', \n",
    "               'Tipos': 'use', \n",
    "               'Superficie de la cuenca hidrográfica (km2)': 'CATCH_SKM',\n",
    "               'Aportación media anual (hm3)': 'INFLOW_MCM', \n",
    "               'Precipitación media anual (mm)': 'PREC_MM',\n",
    "               'Caudal punta avenida de proyecto (m3/s)': 'Q_design',\n",
    "               'Superficie del embalse a NMN (ha)': 'AREA_MNL', # Nivel Máximo Normal => Maximum Normal Level\n",
    "               'Capacidad a NMN (hm3)': 'VOL_MNL',\n",
    "               'Cota del NMN (m)': 'Z_MNL', \n",
    "               'Tipo de presa': 'type', \n",
    "               'Cota coronación (m)': 'ELEV_MASL',\n",
    "               'Altura desde cimientos (m)': 'DAM_HGT_M', \n",
    "               'Longitud de coronación (m)': 'len_crest',\n",
    "               'Cota cimentación (m)': 'Z_foundation', \n",
    "               'Cota del cauce en la presa (m)': 'Z_river',\n",
    "               'Volumen del cuerpo presa (1000 m3)': 'dam_vol',\n",
    "               'Número total de aliviaderos en la presa': 'no_spill', \n",
    "               'Regulación': 'regulation',\n",
    "               'Capacidad a NAE (m3/s)': 'Qspill_EFL', # Nivel de Avenida Extrema => Extreme Flood Level\n",
    "               'Número total de desagües en la presa': 'no_sluice',\n",
    "               'Capacidad (m3/s)': 'Qsluice'}\n",
    "cedex_dam.rename(columns=rename_cols, inplace=True)\n",
    "\n",
    "# correct names\n",
    "for col in ['DAM_NAME']:\n",
    "    cedex_dam[col] = cedex_dam[col].replace(np.nan, '')\n",
    "    cedex_dam[col] = [remove_accents(name) for name in cedex_dam[col]]\n",
    "    \n",
    "# convert to date\n",
    "for col in cedex_dam.columns[cedex_dam.columns.str.startswith('date')]:\n",
    "    cedex_dam[col] = pd.to_datetime(cedex_dam[col], format='%d-%m-%Y', errors='coerce')\n",
    "\n",
    "# convert reservoir area to km2\n",
    "cedex_dam.AREA_MNL /= 100\n",
    "\n",
    "# remove duplicate dams and keep the highest\n",
    "remove_duplicates(cedex_dam, 'DAM_NAME', 'DAM_HGT_M')\n",
    "\n",
    "print('{0} dams with {1} attributes imported from SNCZI'.format(*cedex_dam.shape))\n",
    "\n",
    "# assign reservoir ID to each dam\n",
    "res_ID = []\n",
    "for inf_ID in cedex_dam.index:\n",
    "    try:\n",
    "        res_id = cedex_res.loc[cedex_res.inf_ID == inf_ID].index[0]\n",
    "    except:\n",
    "        res_id = None\n",
    "    res_ID.append(res_id)\n",
    "cedex_dam['res_ID'] = res_ID\n",
    "cedex_dam.res_ID = cedex_dam.res_ID.astype('Int64')\n",
    "\n",
    "# convert into GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(cedex_dam.X, cedex_dam.Y)]\n",
    "cedex_dam = gpd.GeoDataFrame(cedex_dam, geometry=geometry, crs='epsg:25830')\n",
    "cedex_dam.to_crs(epsg=4326, inplace=True)\n",
    "cedex_dam['LON'] = cedex_dam.geometry.x\n",
    "cedex_dam['LAT'] = cedex_dam.geometry.y\n",
    "\n",
    "print('{0} out of {1} dams have an associated reservoir'.format((~cedex_dam.res_ID.isnull()).sum(), cedex_dam.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c309a3-f0e8-4b95-8c1d-4006e70a36b0",
   "metadata": {},
   "source": [
    "#### Reservoir use\n",
    "\n",
    "**Create individual colums for each use**\n",
    "\n",
    "I convert the `use` column into a one hot encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1d876-a62f-4f24-8eda-be888098cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse reservoir use:\n",
    "# 1. I will suppose that the the first use in the dataset is the `main_use`\n",
    "# 2. I create a `single_use` field to identify single-purpose and multipurpose reservoirs\n",
    "# 3. I create a one hot encoder class with all the possible reservoir uses\n",
    "\n",
    "cedex_dam.use = cedex_dam.use.replace(np.nan, '')\n",
    "rename_uses_cedex = {'': 'other',\n",
    "                     'Abastecimiento': 'supply',\n",
    "                     'Acuicultura': 'fish',\n",
    "                     'Adecuación ambiental': 'environment',\n",
    "                     'Defensa frente avenidas': 'flood',\n",
    "                     'Ganadero': 'livestock',\n",
    "                     'Hidroeléctrico': 'hydropower',\n",
    "                     'Industrial': 'industry',\n",
    "                     'Minería': 'mining',\n",
    "                     'Recreo': 'recreation',\n",
    "                     'Refrigeración': 'cooling',\n",
    "                     'Regulación': 'regulation',\n",
    "                     'Riego': 'irrigation',\n",
    "                     'Trasvase': 'diversion'}\n",
    "\n",
    "cedex_dam['main_use'] = ''\n",
    "cedex_dam['single_use'] = True\n",
    "cedex_uses = list(rename_uses_cedex.values())\n",
    "# cedex_uses.remove('')\n",
    "cedex_uses.sort()\n",
    "cedex_dam[cedex_uses] = False\n",
    "for ID in cedex_dam.index:\n",
    "    uses_i = cedex_dam.loc[ID, 'use'].split('. ')\n",
    "    # if '' in uses_i:\n",
    "    #     uses_i.remove('')\n",
    "    if len(uses_i) > 0:\n",
    "        for i, use in enumerate(uses_i):\n",
    "            use = rename_uses_cedex[use]\n",
    "            if i == 0:\n",
    "                cedex_dam.loc[ID, 'main_use'] = use\n",
    "            cedex_dam.loc[ID, use] = True\n",
    "\n",
    "# identify multi-purpose reservoirs\n",
    "mask_multiuse = cedex_dam[cedex_uses].sum(axis=1) > 1\n",
    "cedex_dam.loc[mask_multiuse, 'single_use'] = False\n",
    "\n",
    "# remove original 'use' field\n",
    "# cedex_dam.drop('use', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db8e823-94f3-40b4-a7b8-18622a0148f7",
   "metadata": {},
   "source": [
    "**Classify hydropower reservoirs**\n",
    "\n",
    "I will create a field called `HP_type` (hydropower type) to specify the importance of the hydropower use among all the uses of that reservoir. Codes:\n",
    "\n",
    "* 0: single purpose hydropower.\n",
    "* 1: multi-purpose in which hydropower is the main use.\n",
    "* 2: multi-purpose in which hydropower is the second use.\n",
    "* 3: multi-purpose in which hydropower is the third use.\n",
    "* N: multi-purpose in which hydropower is the Nth use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d672ba-be04-48b8-a8b4-e458e74c10f3",
   "metadata": {},
   "source": [
    "```Python\n",
    "cedex_dam['HP_type'] = np.nan\n",
    "\n",
    "cedex_dam.loc[cedex_dam.single_use & cedex_dam.hydropower, 'HP_type'] = 0\n",
    "\n",
    "for ID in cedex_dam.loc[cedex_dam.hydropower].index:\n",
    "    if cedex_dam.loc[ID, 'single_use']:\n",
    "        continue\n",
    "    uses = [rename_uses_cedex[use] for use in cedex_dam.loc[ID, 'use'].split('. ')]\n",
    "    if 'hydropower' in uses:\n",
    "        cedex_dam.loc[ID, 'HP_type'] = uses.index('hydropower') + 1\n",
    "\n",
    "cedex_dam.HP_type.value_counts()\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ac8f1-6b05-41d9-a0cd-77e0859dc752",
   "metadata": {},
   "source": [
    "**Total annual volume outflow (hm3)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a810dc3-a935-4882-82c4-95d89291bb24",
   "metadata": {},
   "source": [
    "```Python\n",
    "outflows = pd.DataFrame(dtype=float)\n",
    "for ID in tqdm(cedex_dam.loc[cedex_dam.hydropower].index):\n",
    "    \n",
    "    # load time series\n",
    "    df = pd.read_csv(path_cedex / 'timeseries' / f'{ID}.csv', index_col='date')\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    if 'outflow' not in df.columns:\n",
    "        continue\n",
    "    \n",
    "    # compute annual total flow\n",
    "    outflow_y = df.loc[datetime(2010, 1, 1): datetime(2019, 12, 31), 'outflow'].resample('y').mean() * 365 * 24 * 3600 / 1e6\n",
    "    outflow_y.index = [f'outflow_{idx.year}' for idx in outflow_y.index]\n",
    "    outflow_y = outflow_y.to_frame(ID)\n",
    "    \n",
    "    # concatenate\n",
    "    outflows = pd.concat((outflows, outflow_y), axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a78624-483e-4efd-a881-22b3088c7949",
   "metadata": {},
   "source": [
    "### Combine reservoir and dam attributes\n",
    "The connection is direct using the common `res_ID` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7887a1-79a7-4311-9f61-f6129bd00f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename index\n",
    "cedex_res.index.name = 'SNCZI'\n",
    "\n",
    "# set res_ID as index\n",
    "cedex_dam.reset_index(inplace=True)\n",
    "cedex_dam.set_index('res_ID', drop=True, inplace=True)\n",
    "cedex_dam.index.name = 'SNCZI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1d9e74-e9a4-4ffd-9d69-f17476131af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to be used from the inventory of dams in CEDEX\n",
    "cols_cedex_dam = ['DAM_NAME', 'LON', 'LAT', 'date_construction',\n",
    "                  # catchment hydrology\n",
    "                  'CATCH_SKM', 'INFLOW_MCM', 'PREC_MM', 'Q_design', \n",
    "                  # reservoir geometry\n",
    "                  'AREA_MNL', 'VOL_MNL', 'Z_MNL', 'ELEV_MASL', 'DAM_HGT_M', #'dam_vol', \n",
    "                  # reservoir regulation\n",
    "                  'no_spill', 'Qspill_EFL', 'regulation', 'no_sluice', 'Qsluice',\n",
    "                  # reservoir use\n",
    "                  'main_use', 'single_use', 'fish', 'diversion', 'environment', 'flood', 'hydropower', 'industry', 'irrigation', 'livestock',\n",
    "                  'mining', 'cooling', 'other', 'recreation', 'supply']\n",
    "\n",
    "# columns to be used from the inventory of reservoirs in CEDEX\n",
    "cols_cedex_res = ['RES_NAME', 'V_live', 'CAP_MCM', 'AREA_SKM', 'Z_EFL', 'Z_MNL']\n",
    "\n",
    "# combine attributes from CEDEX\n",
    "cedex = pd.concat((cedex_dam.loc[~cedex_dam.index.isnull(), cols_cedex_dam],\n",
    "                   cedex_res[cols_cedex_res]),\n",
    "                  axis=1,\n",
    "                  join='outer')\n",
    "cedex.index = cedex.index.astype(int)\n",
    "cedex.sort_index(inplace=True)\n",
    "cedex.DAM_NAME = cedex.DAM_NAME.replace(np.nan, '')\n",
    "\n",
    "# convert into GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(cedex.LON, cedex.LAT)]\n",
    "cedex = gpd.GeoDataFrame(cedex, geometry=geometry, crs='epsg:4326')\n",
    "\n",
    "# correct some names\n",
    "cedex.RES_NAME = cedex.RES_NAME.replace({'SANT PONC (SAN PONS)' : 'SAN PONS',\n",
    "                                         'CATLLAR': 'GAIA'})\n",
    "cedex.DAM_NAME = cedex.DAM_NAME.replace({'SANT PONC': 'SAN PONS',\n",
    "                                         'RIO JILOCA (REGULACION) (LECHAGO)': 'LECHAGO',\n",
    "                                         'CATLLAR': 'GAIA'})\n",
    "\n",
    "# remove zeros\n",
    "cedex[['CAP_MCM', 'CATCH_SKM']] = cedex[['CAP_MCM', 'CATCH_SKM']].replace(0, np.nan)\n",
    "\n",
    "# filter by catchment area and reservoir volume\n",
    "mask_cedex = filter_reservoirs(cedex.CATCH_SKM, cedex.CAP_MCM, MIN_CATCH, MIN_VOL)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='face', facecolor='lightgray'),\n",
    "               alpha=.5,\n",
    "               zorder=0)\n",
    "cedex.loc[~mask_cedex].plot(markersize=cedex.CAP_MCM**.5, c='indianred', alpha=.5, ax=ax, label='discarded')\n",
    "cedex.loc[mask_cedex].plot(markersize=cedex.CAP_MCM**.5, alpha=.5, ax=ax, label='selected')\n",
    "ax.set_extent([-10, 4.5, 35.5, 44])\n",
    "fig.legend(frameon=False, bbox_to_anchor=[1.0, .4, .1, .2])\n",
    "ax.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0397d688-61b3-4812-a297-b996225b8bdb",
   "metadata": {},
   "source": [
    "**Main use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dd3d2c-b1e9-42d8-a46c-1eeba25f1dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mainuse_singlepurpose = cedex.loc[mask_cedex & cedex.single_use, 'main_use'].value_counts()\n",
    "mainuse_multipurpose = cedex.loc[mask_cedex, 'main_use'].value_counts()\n",
    "mainuse_summary_cedex = pd.concat((mainuse_singlepurpose, mainuse_multipurpose), axis=1)\n",
    "mainuse_summary_cedex.columns = ['singlepurpose', 'multipurpose']\n",
    "mainuse_summary_cedex.sort_values('multipurpose', ascending=False, inplace=True)\n",
    "del mainuse_singlepurpose, mainuse_multipurpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41af2815-9322-47da-aa3f-a2d0ed787912",
   "metadata": {},
   "source": [
    "**All uses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee00ce5-f9fa-410e-a2e5-bef2b623818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alluses_singlepurpose = cedex.loc[mask_cedex & cedex.single_use, cedex_uses].sum()\n",
    "alluses_multipurpose = cedex.loc[mask_cedex, cedex_uses].sum()\n",
    "alluses_summary_cedex = pd.concat((alluses_singlepurpose, alluses_multipurpose), axis=1)\n",
    "alluses_summary_cedex.columns = ['singlepurpose', 'multipurpose']\n",
    "alluses_summary_cedex.sort_values('multipurpose', ascending=False, inplace=True)\n",
    "alluses_summary_cedex.dropna(axis=0, how='all', inplace=True)\n",
    "alluses_summary_cedex = alluses_summary_cedex[~(alluses_summary_cedex == 0).all(axis=1)]\n",
    "del alluses_singlepurpose, alluses_multipurpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd6730f-2f31-4c9b-afcd-eb11fb3f2132",
   "metadata": {},
   "source": [
    "## EFAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c39665-9399-4520-8f08-91d4b8ba124d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load EFAS reservoirs\n",
    "efas = gpd.read_file(PATH_EFAS / 'reservoirs' / 'reservoirs_EFAS5.shp')\n",
    "efas.ResID = efas.ResID.astype(pd.Int64Dtype())\n",
    "efas.set_index('ResID', inplace=True)\n",
    "\n",
    "# filter reservoir in Spain\n",
    "efas = efas.loc[efas.COUNTRY == 'Spain']\n",
    "\n",
    "# correct dam names\n",
    "efas.DAM_NAME.replace(np.nan, '', inplace=True)\n",
    "names = []\n",
    "for name in efas.DAM_NAME.str.upper():\n",
    "    split = name.split('_')\n",
    "    if len(split) == 2:\n",
    "        names.append(split[0])\n",
    "    elif len(split) > 2:\n",
    "        names.append(' '.join(split[:-1]))\n",
    "    else:\n",
    "        names.append(name)\n",
    "efas.DAM_NAME = names\n",
    "\n",
    "# correct coordinates of Cenza reservoir\n",
    "# efas.loc[3132, ['LON_ORG', 'LAT_ORG']] = [-7.1442, 42.1141]\n",
    "\n",
    "# remove old reservoir \"El Alisillo\" (ResID = 3247)\n",
    "efas.drop([3247], axis=0, inplace=True)\n",
    "\n",
    "# convert coordinates into the original\n",
    "efas = pd.DataFrame(efas)\n",
    "efas[['LON_ORG', 'LAT_ORG']] = efas[['LON_ORG', 'LAT_ORG']].astype(float)\n",
    "geometry = [Point(xy) for xy in zip(efas.LON_ORG, efas.LAT_ORG)]\n",
    "efas = gpd.GeoDataFrame(efas, geometry=geometry, crs='epsg:4326')\n",
    "efas.rename(columns={'LON_ORG': 'LON', 'LAT_ORG': 'LAT'}, inplace=True)\n",
    "\n",
    "# add EFAS reservoir parameters\n",
    "EFAS_vars = {'rclim': 'Vc',\n",
    "             'rflim': 'Vf',\n",
    "             'rminq': 'Qmin',\n",
    "             'rndq': 'Qnd',\n",
    "             'rnlim': 'Vn',\n",
    "             'rnormq': 'Qn',\n",
    "             'rtstor': 'CAP_MCM'}\n",
    "\n",
    "for file in (PATH_EFAS / 'reservoirs').glob('r*.txt'):\n",
    "    var = EFAS_vars[file.stem]\n",
    "    serie = pd.read_csv(file, header=None, index_col=0, sep=' ').squeeze()\n",
    "    efas[var] = serie.loc[efas.index]\n",
    "# convert volumes to hm3\n",
    "efas['CAP_MCM'] /= 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bec9fe-21e0-47a3-978d-5cb08894bfdf",
   "metadata": {},
   "source": [
    "I load the static map `res.nc` to extract from it the coordinates of the reservoirs in EFAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e1499b-52cc-4e19-92bc-7c9b4fad46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load static map of reservoirs\n",
    "efas_raster = xr.open_mfdataset(f'{PATH_EFAS}/iberia/res*.nc')['res'].compute()\n",
    "\n",
    "# extract an array of reservoir ID\n",
    "# ids = np.unique(glofas_raster.where(~glofas_raster.isnull(), drop=True))\n",
    "# ids = ids[~np.isnan(ids) & (ids != -9999)]\n",
    "# ids = ids.astype(int)\n",
    "ids = efas.index.sort_values().tolist()\n",
    "\n",
    "# xr.DataArrays of reservoir longitudes and latitudes\n",
    "lon = xr.DataArray(np.nan, dims=['ResID'], coords={'ResID': ids})\n",
    "lat = xr.DataArray(np.nan, dims=['ResID'], coords={'ResID': ids})\n",
    "for id in tqdm(ids):\n",
    "    try:\n",
    "        cell = efas_raster.where(efas_raster == id, drop=True)\n",
    "        lon.loc[dict(ResID=id)] = cell.lon.data[0]\n",
    "        lat.loc[dict(ResID=id)] = cell.lat.data[0]\n",
    "    except:\n",
    "        lon = lon.where(lon.ResID != id, drop=True)\n",
    "        lat = lat.where(lat.ResID != id, drop=True)\n",
    "coords = xr.Dataset({'lon': lon, 'lat': lat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658f0eb2-3246-4454-8dd0-a98d4d7c7995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract catchment area from the \"upArea\" static map\n",
    "upArea = xr.open_mfdataset(f'{PATH_EFAS}/iberia/upArea*.nc')['Band1'].compute()\n",
    "upArea.name = 'upstream_area'\n",
    "efas['CATCH_SKM'] = np.nan\n",
    "for ID in tqdm(efas.index):\n",
    "    try:\n",
    "        lon, lat = coords.sel(ResID=ID)['lon'].data, coords.sel(ResID=ID)['lat'].data\n",
    "        efas.loc[ID, 'CATCH_SKM'] = upArea.sel(lon=lon, lat=lat, method='nearest').drop(['lon', 'lat']).data\n",
    "    except:\n",
    "        print(f'The catchment area could not be extracted for ResID {ID}')\n",
    "efas.CATCH_SKM /= 1e6 # convert into km2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8241d0-d11c-4305-9042-77fe7ad59e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  select reservoirs based on catchment area and reservoir volume\n",
    "mask_efas = filter_reservoirs(efas.CATCH_SKM, efas.CAP_MCM, MIN_CATCH, MIN_VOL)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='face', facecolor='lightgray'),\n",
    "               alpha=.5,\n",
    "               zorder=0)\n",
    "efas.loc[~mask_efas].plot(markersize=efas.CAP_MCM**.5, c='indianred', alpha=.5, ax=ax, label='discarded')\n",
    "efas.loc[mask_efas].plot(markersize=efas.CAP_MCM**.5, alpha=.5, ax=ax, label='selected')\n",
    "# ax.set_extent([-10, 4.5, 35.5, 44])\n",
    "fig.legend(frameon=False, bbox_to_anchor=[1.0, .4, .1, .2])\n",
    "ax.axis('off');\n",
    "\n",
    "# apply the selection\n",
    "efas = efas.loc[mask_efas]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fce4b6-edbc-40d3-948f-6db0862fd140",
   "metadata": {},
   "source": [
    "There's a reservoir missing in the EFAS raster (`ResID=3132`, Cenza). Apart from that, the reservoir Montoro III that I have created to replace \"El Alisillo\" is also missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ff44f1-12a3-4a34-a451-4c94dd3d1f56",
   "metadata": {},
   "source": [
    "### Connect EFAS and CEDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8239f260-20b5-48fa-8e4b-328060b1b0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fields for the ID and name in HDCC\n",
    "efas[['SNCZI', 'SNCZI_Name']] = np.nan\n",
    "\n",
    "# find matches based on the name\n",
    "mask_name = cedex.RES_NAME.isin(efas.DAM_NAME)\n",
    "for ID, name in cedex.loc[mask_name, 'RES_NAME'].items():\n",
    "    efas.loc[efas.DAM_NAME == name, ['SNCZI', 'SNCZI_Name']] = ID, name\n",
    "\n",
    "# check missing values\n",
    "missing = efas.SNCZI.isnull().sum()\n",
    "if missing > 0:\n",
    "    print(f'{missing} reservoir are missing the SNCZI connection')\n",
    "    efas.SNCZI = efas.SNCZI.astype('Int64')\n",
    "else:\n",
    "    efas.SNCZI = efas.SNCZI.astype(int)\n",
    "    \n",
    "# reindex\n",
    "efas.reset_index(inplace=True)\n",
    "efas.set_index('SNCZI', drop=True, inplace=True)\n",
    "efas.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c7e7c8-5d9a-4d71-9f3c-2b0c49936b3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hydropower Data Base (HPDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c185824-131a-4457-ab5e-a10188dfad86",
   "metadata": {},
   "source": [
    "```Python\n",
    "hpdb = pd.read_excel(PATH_DATASETS / 'reservoirs' / 'HPDB' / 'HPDB_Spain.xlsx', index_col='HPDB_id')\n",
    "hpdb.Name = hpdb.Name.str.upper()\n",
    "# # correct coordinates of \"La Muela\"\n",
    "# hpdb.loc['H4', ['Longitude', 'Latitude']] = [-0.92821, 39.23821]\n",
    "\n",
    "# rename columns\n",
    "rename_cols = {#'Name',\n",
    "               # 'country',\n",
    "               'Longitude': 'lon',\n",
    "               'Latitude': 'lat',\n",
    "               'HPDB_installed_capacity_MW': 'instal_cap',\n",
    "               'HPDB_pumping  capacity if it is a HPHS_MW': 'pump_cap',\n",
    "               'HPDB_type': 'type',\n",
    "               'HPDB_head_m': 'head_HPDB',\n",
    "               'head': 'head_src2',\n",
    "               'dam height (match from ICOLD o Vattenfal for Sweden)': 'DAM_HGT_M',\n",
    "               'head (final)': 'head',\n",
    "               'HPDB_volume_Mm3': 'vol_HPDB',\n",
    "               'HPDB_volume_from ICOLD_Mm3': 'vol_ICOLD',\n",
    "               'HPDB_volume of reservoir_final_Mm3': 'volume',\n",
    "               'final energy generation GWh': 'energy',\n",
    "               'Annual volume discharged (a bit underestimated, because the used head is the maximum one) Mm3': 'vol_turb'\n",
    "              }\n",
    "hpdb.rename(columns=rename_cols, inplace=True)\n",
    "\n",
    "# filter dam hydropower plants\n",
    "hpdb = hpdb.loc[hpdb.type == 'HDAM']\n",
    "\n",
    "# convert into GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(hpdb.lon, hpdb.lat)]\n",
    "hpdb = gpd.GeoDataFrame(hpdb, geometry=geometry, crs='epsg:4326')\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='face', facecolor='lightgray'),\n",
    "               alpha=.5,\n",
    "               zorder=0)\n",
    "hpdb.plot(markersize=5, ax=ax)\n",
    "ax.set_title(f'Hydropower Batabase\\n{hpdb.shape[0]} reservoirs')\n",
    "ax.set_extent([-10, 4.5, 35.5, 44])\n",
    "ax.axis('off');\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61744b30-2240-41bb-969a-10367d412e4f",
   "metadata": {},
   "source": [
    "**Connect HPDB with HDCC**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459cacc7-bec2-41d4-bb6d-3ef081eb40de",
   "metadata": {
    "tags": []
   },
   "source": [
    "```Python\n",
    "# nearest neighbour in ICOLD for each point in HDCC\n",
    "idx_hpdb, idx_hdcc = hdcc.sindex.nearest(hpdb.geometry, max_distance=.1)\n",
    "\n",
    "# add ICOLD name and ID to the HDCC table\n",
    "hpdb.drop(['HDCC_ID', 'HDCC_Name'], axis=1, inplace=True, errors='ignore')\n",
    "idx_hpdb = hpdb.index[idx_hpdb]\n",
    "hpdb.loc[idx_hpdb, 'HDCC_ID'] = hdcc.iloc[idx_hdcc].index.values\n",
    "hpdb.loc[idx_hpdb, 'HDCC_Name'] = hdcc.iloc[idx_hdcc]['Name'].values\n",
    "\n",
    "(hpdb.Name == hpdb.HDCC_Name).sum()\n",
    "\n",
    "mask_name = hpdb.Name != hpdb.HDCC_Name\n",
    "hpdb.loc[mask_name, ['Name', 'HDCC_Name']].sort_values('Name').head(30)\n",
    "\n",
    "for col in hpdb.columns:\n",
    "    if len(col) > 10:\n",
    "        print(col)\n",
    "\n",
    "hpdb.to_file(PATH_DATASETS / 'reservoirs' / 'HPDB' / 'HPDB_Spain.shp')\n",
    "\n",
    "for ID in cedex_dam.index:\n",
    "    name = cedex_dam.loc[ID, 'DAM_NAME']\n",
    "    if 'MUELA' in name:\n",
    "        print(ID, name)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ac3645-089d-45ac-84f8-040048fe6a03",
   "metadata": {},
   "source": [
    "## ICOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17acb0d-e430-4583-873e-e7978f17fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shapefile\n",
    "path_icold = PATH_DATASETS / 'reservoirs' / 'ICOLD' / '2023'\n",
    "icold = gpd.read_file(path_icold / 'ICOLD_ES.shp')\n",
    "icold.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# remove duplicated entries keeping the heighest dam associated to each reservoir\n",
    "for name, count in icold.Res_Name.value_counts().items():\n",
    "    if count > 1:\n",
    "        remove_idx = icold.loc[icold.Res_Name == name].sort_values('Height', ascending=False).index[1:]\n",
    "        icold.drop(remove_idx, axis=0, inplace=True)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "# remove entries without geometry\n",
    "icold.drop([idx for idx, geo in icold.geometry.items() if geo is None], axis=0, inplace=True)\n",
    "        \n",
    "# convert reservoir volume MCM (hm3)\n",
    "icold.Res_Vol /= 1000\n",
    "\n",
    "# convert reservoir area to km2\n",
    "icold.Res_Area /= 1000\n",
    "\n",
    "# rename columns\n",
    "icold.rename(columns={'Catch_Area': 'CATCH_SKM',\n",
    "                      'Res_Vol': 'CAP_MCM',\n",
    "                      'Res_Area': 'AREA_SKM',\n",
    "                      'Res_Name': 'RES_NAME',\n",
    "                      'Res_Leng': 'RES_LEN_KM',\n",
    "                      'Dam_Name': 'DAM_NAME',\n",
    "                      'Latitude': 'LAT',\n",
    "                      'Longitude': 'LON',\n",
    "                      'Height': 'DAM_HGT_M',\n",
    "                      'Altitude': 'ELEV_MASL',\n",
    "                      'Crest_Leng': 'DAM_LEN_M'},\n",
    "             inplace=True)\n",
    "\n",
    "# correct names\n",
    "icold = correct_names(icold, col_pattern='name', split_pattern=', ')\n",
    "\n",
    "# select reservoirs based on catchment area and reservoir volume\n",
    "mask_icold = filter_reservoirs(icold.CATCH_SKM, icold.CAP_MCM, MIN_CATCH, MIN_VOL)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='face', facecolor='lightgray'),\n",
    "               alpha=.5,\n",
    "               zorder=0)\n",
    "icold.loc[~mask_icold].plot(markersize=icold.CAP_MCM**.5, c='indianred', alpha=.5, ax=ax, label='discarded')\n",
    "icold.loc[mask_icold].plot(markersize=icold.CAP_MCM**.5, alpha=.5, ax=ax, label='selected')\n",
    "# ax.set_extent([-10, 4.5, 35.5, 44])\n",
    "ax.legend(frameon=False)\n",
    "ax.axis('off');\n",
    "\n",
    "# apply the selection\n",
    "icold = icold.loc[mask_icold]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cade4cb-b4f0-448f-ac95-4a67ae65a5f5",
   "metadata": {},
   "source": [
    "### Connect CEDEX and ICOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f410c432-c60c-458c-a42e-9ab0ecc6ecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fields for the ID and name in HDCC\n",
    "icold[['SNCZI', 'SNCZI_Name']] = np.nan\n",
    "\n",
    "# find matches based on the reservoir name\n",
    "mask_name = cedex.RES_NAME.isin(icold.RES_NAME)\n",
    "for ID, name in cedex.loc[mask_name, 'RES_NAME'].items():\n",
    "    icold.loc[icold.RES_NAME == name, ['SNCZI', 'SNCZI_Name']] = ID, name\n",
    "\n",
    "# find matches based on the dam name\n",
    "mask_snczi = icold.SNCZI.isnull()\n",
    "mask_name = cedex.RES_NAME.isin(icold.loc[mask_snczi, 'DAM_NAME'])\n",
    "for ID, name in cedex.loc[mask_name, 'RES_NAME'].items():\n",
    "    icold.loc[icold.DAM_NAME == name, ['SNCZI', 'SNCZI_Name']] = ID, name\n",
    "    \n",
    "# find matches based on the dam name\n",
    "mask_snczi = icold.SNCZI.isnull()\n",
    "mask_name = cedex.DAM_NAME.isin(icold.loc[mask_snczi, 'DAM_NAME'])\n",
    "for ID, name in cedex.loc[mask_name, 'DAM_NAME'].items():\n",
    "    icold.loc[icold.DAM_NAME == name, ['SNCZI', 'SNCZI_Name']] = ID, name\n",
    "    \n",
    "# check missing values\n",
    "missing = icold.SNCZI.isnull().sum()\n",
    "if missing > 0:\n",
    "    print(f'{missing} reservoir are missing the SNCZI connection')\n",
    "    icold.SNCZI = icold.SNCZI.astype('Int64')\n",
    "else:\n",
    "    icold.SNCZI = icold.SNCZI.astype(int)\n",
    "    \n",
    "# reindex\n",
    "#icold.reset_index(inplace=True)\n",
    "#icold.set_index('SNCZI', drop=True, inplace=True)\n",
    "#icold.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718c55fc-0d4f-4b46-8d8b-bb7b485c09e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "```Python\n",
    "icold[['SNCZI', 'CEDEX_name']] = np.nan\n",
    "for snczi, name in tqdm(hdcc.name.items()):\n",
    "    \n",
    "    one = process.extractOne(name, icold.Res_Name, score_cutoff=90)\n",
    "\n",
    "    if one is None:\n",
    "        continue\n",
    "\n",
    "    # compute distance\n",
    "    point1 = hdcc.loc[hdcc.name == name].geometry.iloc[0]\n",
    "    point2 = icold.loc[icold.Res_Name == one[0]].geometry.iloc[0]\n",
    "    dist = geodesic((point1.y, point1.x), (point2.y, point2.x)).meters\n",
    "    if dist < 1e4:\n",
    "        icold.loc[icold.Res_Name == one[0], ['SNCZI', 'CEDEX_name']] = snczi, name\n",
    "        \n",
    "print('{0} matches found'.format((~icold.SNCZI.isnull()).sum()))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d741637-8d5f-4531-b961-d3dc3c90128d",
   "metadata": {},
   "source": [
    "### Reservoir use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3fe6c5-727c-4651-ad55-3ae08945a913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # count uses\n",
    "# uses = []\n",
    "# for ID in icold.index:\n",
    "#     try:\n",
    "#         uses = uses + list(icold.loc[ID, 'Purposes'])\n",
    "#     except:\n",
    "#         continue\n",
    "\n",
    "# np.unique(uses, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d163b0-90ef-43bd-9544-6d67e3bb5150",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_uses_icold = {'C': 'flood',\n",
    "               'I': 'irrigation',\n",
    "               'H': 'hydropower',\n",
    "               'F': 'fish',\n",
    "               'N': 'navigation',\n",
    "               'R': 'recreation',\n",
    "               'S': 'supply',\n",
    "               'X': 'other',\n",
    "               'T': 'tailings'}\n",
    "\n",
    "icold['main_use'] = ''\n",
    "icold['single_use'] = True\n",
    "\n",
    "icold_uses = list(rename_uses_icold.values())\n",
    "icold_uses.sort()\n",
    "icold[icold_uses] = False\n",
    "\n",
    "for ID in icold.index:\n",
    "    try:\n",
    "        for i, key in enumerate(icold.loc[ID, 'Purposes']):\n",
    "            use = rename_uses_icold[key]\n",
    "            if i == 0:\n",
    "                icold.loc[ID, 'main_use'] = use\n",
    "            icold.loc[ID, use] = True\n",
    "    except Exception as e:\n",
    "        print(f'Uses could not be renamed in reservoir {ID}: {e}')\n",
    "        continue\n",
    "\n",
    "# identify multi-purpose reservoirs\n",
    "mask_multipurpose = icold[icold_uses].sum(axis=1) > 1\n",
    "icold.loc[mask_multipurpose, 'single_use'] = False\n",
    "\n",
    "# # remove original 'Purposes' field\n",
    "# icold.drop('Purposes', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d0e01c-a0cb-46af-8d76-2a3f6d227aa3",
   "metadata": {},
   "source": [
    "**Main use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191275c0-1d37-4591-80c4-b6c1a500fbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_singleuse = icold.single_use\n",
    "mask_hdcc = ~icold.SNCZI.isnull()\n",
    "mainuse_singlepurpose = icold.loc[mask_hdcc & mask_singleuse, 'main_use'].value_counts()\n",
    "mainuse_multipurpose = icold.loc[mask_hdcc, 'main_use'].value_counts()\n",
    "mainuse_summary_icold = pd.concat((mainuse_singlepurpose, mainuse_multipurpose), axis=1)\n",
    "mainuse_summary_icold.columns = ['singlepurpose', 'multipurpose']\n",
    "mainuse_summary_icold.sort_values('multipurpose', ascending=False, inplace=True)\n",
    "del mainuse_multipurpose, mainuse_singlepurpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43edee3e-cbfc-4e18-940d-4558fbc2f1c0",
   "metadata": {},
   "source": [
    "**All uses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f309ed-e1de-4549-b95c-aae42c83c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "alluses_singlepurpose = icold.loc[mask_hdcc & mask_singleuse, icold_uses].sum()\n",
    "alluses_multipurpose = icold.loc[mask_hdcc, icold_uses].sum()\n",
    "alluses_summary_icold = pd.concat((alluses_singlepurpose, alluses_multipurpose), axis=1)\n",
    "alluses_summary_icold.columns = ['singlepurpose', 'multipurpose']\n",
    "alluses_summary_icold.sort_values('multipurpose', ascending=False, inplace=True)\n",
    "alluses_summary_icold.dropna(axis=0, how='all', inplace=True)\n",
    "alluses_summary_icold = alluses_summary_icold[~(alluses_summary_icold == 0).all(axis=1)]\n",
    "del alluses_singlepurpose, alluses_multipurpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb3c32b-f0f9-41c3-bced-19b7fae85ca4",
   "metadata": {},
   "source": [
    "## GRanD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303bd23e-bf68-4e25-8c7a-5971ab23629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load shapefile of dams\n",
    "path_grand = PATH_DATASETS / 'reservoirs' / 'GRanD' / 'v1_3'\n",
    "grand = gpd.read_file(path_grand / 'GRanD_dams_v1_3.shp')\n",
    "grand.set_index('GRAND_ID', drop=False, inplace=True)\n",
    "\n",
    "# filter dams in Spain\n",
    "grand = grand.loc[grand.COUNTRY == 'Spain']\n",
    "\n",
    "# correct names\n",
    "grand.DAM_NAME = grand.DAM_NAME.str.upper()\n",
    "grand.RES_NAME = grand.RES_NAME.str.upper()\n",
    "\n",
    "# rename columns\n",
    "grand['LON'] = grand.geometry.x\n",
    "grand['LAT'] = grand.geometry.y\n",
    "\n",
    "print('No. reservoirs:\\t{0}\\nNo. attributes:\\t{1}\\n'.format(*grand.shape))\n",
    "\n",
    "# select reservoirs based on catchment area and reservoir volume\n",
    "mask_grand = filter_reservoirs(grand.CATCH_SKM, grand.CAP_MCM, MIN_CATCH, MIN_VOL)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='face', facecolor='lightgray'),\n",
    "               alpha=.5,\n",
    "               zorder=0)\n",
    "grand.loc[~mask_grand].plot(markersize=grand.CAP_MCM**.5, c='indianred', alpha=.5, ax=ax, label='discarded')\n",
    "grand.loc[mask_grand].plot(markersize=grand.CAP_MCM**.5, alpha=.5, ax=ax, label='selected')\n",
    "# ax.set_extent([-10, 4.5, 35.5, 44])\n",
    "fig.legend(frameon=False, bbox_to_anchor=[1, .4, .1, .2])\n",
    "ax.axis('off');\n",
    "\n",
    "# apply the selection\n",
    "grand = grand.loc[mask_grand]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537c3ddf-0447-4326-8f22-faeff76212be",
   "metadata": {},
   "source": [
    "### Connect CEDEX and GRanD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b73ef1e-c683-4672-9b32-fc29dc83bd11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create fields for the ID and name in HDCC\n",
    "grand[['SNCZI', 'SNCZI_Name']] = np.nan\n",
    "\n",
    "# find matches based on the reservoir name\n",
    "mask_name = cedex.RES_NAME.isin(grand.RES_NAME)\n",
    "for ID, name in cedex.loc[mask_name, 'RES_NAME'].items():\n",
    "    grand.loc[grand.RES_NAME == name, ['SNCZI', 'SNCZI_Name']] = ID, name\n",
    "\n",
    "# find matches based on the dam name\n",
    "mask_snczi = grand.SNCZI.isnull()\n",
    "mask_name = cedex.DAM_NAME.isin(grand.loc[mask_snczi, 'DAM_NAME'])\n",
    "for ID, name in cedex.loc[mask_name, 'DAM_NAME'].items():\n",
    "    grand.loc[grand.DAM_NAME == name, ['SNCZI', 'SNCZI_Name']] = ID, name  \n",
    "\n",
    "# find matches based on the dam name\n",
    "mask_snczi = grand.SNCZI.isnull()\n",
    "mask_name = cedex.RES_NAME.isin(grand.loc[mask_snczi, 'DAM_NAME'])\n",
    "for ID, name in cedex.loc[mask_name, 'RES_NAME'].items():\n",
    "    grand.loc[grand.DAM_NAME == name, ['SNCZI', 'SNCZI_Name']] = ID, name\n",
    "    \n",
    "\n",
    "# check missing values\n",
    "missing = grand.SNCZI.isnull().sum()\n",
    "if missing > 0:\n",
    "    print(f'{missing} reservoir are missing the SNCZI connection')\n",
    "    grand.SNCZI = grand.SNCZI.astype('Int64')\n",
    "else:\n",
    "    grand.SNCZI = grand.SNCZI.astype(int)\n",
    "    \n",
    "# reindex\n",
    "grand.set_index('SNCZI', drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecab471-e6ce-4057-b00c-90f7808ba872",
   "metadata": {},
   "source": [
    "```Python\n",
    "grand[['SNCZI', 'SNCZI_name']] = np.nan\n",
    "for snczi, name in tqdm(cedex.RES_NAME.items()):\n",
    "    \n",
    "    one = process.extractOne(name, grand.DAM_NAME, score_cutoff=80)\n",
    "\n",
    "    if one is None:\n",
    "        continue\n",
    "\n",
    "    # compute distance\n",
    "    point1 = cedex.loc[cedex.RES_NAME == name].geometry.iloc[0]\n",
    "    point2 = grand.loc[grand.DAM_NAME == one[0]].geometry.iloc[0]\n",
    "    dist = geodesic((point1.y, point1.x), (point2.y, point2.x)).meters\n",
    "    if dist < 1e4:\n",
    "        grand.loc[grand.DAM_NAME == one[0], ['SNCZI', 'SNCZI_name']] = snczi, name\n",
    "        \n",
    "print('{0} matches found'.format((~grand.SNCZI.isnull()).sum()))\n",
    "\n",
    "\n",
    "grand[['SNCZI', 'SNCZI_name']] = np.nan\n",
    "for snczi, name in tqdm(cedex.DAM_NAME.items()):\n",
    "    \n",
    "    one = process.extractOne(name, grand.DAM_NAME, score_cutoff=80)\n",
    "\n",
    "    if one is None:\n",
    "        continue\n",
    "\n",
    "    # compute distance\n",
    "    point1 = cedex.loc[cedex.DAM_NAME == name].geometry.iloc[0]\n",
    "    point2 = grand.loc[grand.DAM_NAME == one[0]].geometry.iloc[0]\n",
    "    dist = geodesic((point1.y, point1.x), (point2.y, point2.x)).meters\n",
    "    if dist < 1e4:\n",
    "        grand.loc[grand.DAM_NAME == one[0], ['SNCZI', 'SNCZI_name']] = snczi, name\n",
    "        \n",
    "print('{0} matches found'.format((~grand.SNCZI.isnull()).sum()))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5331905e-d72c-41b7-a413-791a42912486",
   "metadata": {},
   "source": [
    "### Reservoir use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7025b062-4d2d-4fca-878d-b9785e12f731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "rename_uses_grand = {'USE_IRRI': 'irrigation',\n",
    "                  'USE_ELEC': 'hydropower',\n",
    "                     'USE_SUPP': 'supply',\n",
    "                     'USE_FCON': 'flood',\n",
    "                     'USE_RECR': 'recreation',\n",
    "                     'USE_NAVI': 'navigation',\n",
    "                     'USE_FISH': 'fish',\n",
    "                     'USE_PCON': 'pollution',\n",
    "                     'USE_LIVE': 'livestock',\n",
    "                     'USE_OTHR': 'other'}\n",
    "grand.rename(columns=rename_uses_grand, inplace=True)\n",
    "\n",
    "# replace values in 'MAIN_USE' to be consistent with the columns\n",
    "grand.MAIN_USE.replace({'Irrigation': 'irrigation',\n",
    "                        'Hydroelectricity': 'hydropower',\n",
    "                        'Water supply': 'supply',\n",
    "                        'Other': 'other',\n",
    "                        'Recreation': 'recreation',\n",
    "                        'Flood control': 'flood'},\n",
    "                       inplace=True)\n",
    "\n",
    "# convert to boolean\n",
    "grand_uses = list(rename_uses_grand.values())\n",
    "grand[grand_uses] = grand[grand_uses].replace({'Main': True, 'Major': True, 'Sec': True, None: False})\n",
    "\n",
    "# identify single purpose reservoirs\n",
    "grand['SINGLE_USE'] = False\n",
    "mask_singleuse = grand[grand_uses].sum(axis=1) == 1\n",
    "grand.loc[mask_singleuse, 'SINGLE_USE'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bab59a-b8db-4fd7-a372-faab06313ae4",
   "metadata": {},
   "source": [
    "**Main use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1fd93-92ae-4eae-adf6-f8c555b149b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_singleuse = grand.SINGLE_USE\n",
    "mask_hdcc = ~grand.index.isnull()\n",
    "\n",
    "mainuse_singlepurpose = grand.loc[mask_hdcc & mask_singleuse, 'MAIN_USE'].value_counts()\n",
    "mainuse_multipurpose = grand.loc[mask_hdcc, 'MAIN_USE'].value_counts()\n",
    "mainuse_summary_grand = pd.concat((mainuse_singlepurpose, mainuse_multipurpose), axis=1)\n",
    "mainuse_summary_grand.columns = ['singlepurpose', 'multipurpose']\n",
    "mainuse_summary_grand.sort_values('multipurpose', ascending=False, inplace=True)\n",
    "del mainuse_singlepurpose, mainuse_multipurpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a54f0ac-09fa-4cda-b6fc-67c757daf2dd",
   "metadata": {},
   "source": [
    "**All uses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545c1ac6-365e-42f9-828e-0ae12e1996ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "alluses_singlepurpose = grand.loc[mask_hdcc & mask_singleuse, grand_uses].sum()\n",
    "alluses_multipurpose = grand.loc[mask_hdcc, grand_uses].sum()\n",
    "alluses_summary_grand = pd.concat((alluses_singlepurpose, alluses_multipurpose), axis=1)\n",
    "alluses_summary_grand.columns = ['singlepurpose', 'multipurpose']\n",
    "alluses_summary_grand.sort_values('multipurpose', ascending=False, inplace=True)\n",
    "alluses_summary_grand.dropna(axis=0, how='all', inplace=True)\n",
    "alluses_summary_grand = alluses_summary_grand[~(alluses_summary_grand == 0).all(axis=1)]\n",
    "del alluses_singlepurpose, alluses_multipurpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535b31db-8025-41af-92c5-0e10c6572934",
   "metadata": {},
   "source": [
    "## Comparison of data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db85c7cb-067f-49b8-98ac-8e8fee352bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit `cedex` to the reservoirs that fulfil the conditions\n",
    "cedex = cedex.loc[mask_cedex]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041d91a4-d55b-4943-9945-757331bb819c",
   "metadata": {},
   "source": [
    "### Reservoir volume\n",
    "\n",
    "* CEDEX dams: `'V_MNL'`. This value does not represent total capacity, but the capacity at a normal level. Therefore, the actual reservoir capacity should always be larger than this value.\n",
    "* CEDEX reservoirs: `'V_total'`, `'V_live'`\n",
    "* ICOLD: `'Res_Vol'`\n",
    "* EFAS: `'Vtotal'`\n",
    "* GRanD: `'CAP_MCM'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d84ad2b-7676-414c-9492-236cd60653b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'CAP_MCM'\n",
    "\n",
    "# combine all volume data in a single table\n",
    "volume = pd.concat((cedex[[variable, 'VOL_MNL']],\n",
    "                    efas[variable],\n",
    "                    icold[variable],\n",
    "                    grand[variable], \n",
    "                   ), axis=1)\n",
    "volume.columns = ['CEDEX', 'CEDEX_MNL', 'EFAS', 'ICOLD', 'GRanD']\n",
    "\n",
    "print('Number of reservoirs:\\t{0}\\nNumber of data sets:\\t{1}'.format(*volume.shape))\n",
    "\n",
    "# summarize\n",
    "volume_summary = pd.concat(((~volume.isnull()).sum(), volume.sum()), axis=1)\n",
    "volume_summary.columns = ['no_reservoirs', 'total_volume']\n",
    "volume_summary.sort_values('no_reservoirs', ascending=False, inplace=True)\n",
    "\n",
    "# plot summary\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(8.5, 4), sharey=True)\n",
    "for ax, col in zip(axes, volume_summary):\n",
    "    ax.barh(volume_summary.index, volume_summary[col], color='lightsteelblue')\n",
    "    ax.spines[['top', 'left', 'right', 'bottom']].set_visible(False)\n",
    "    ax.tick_params(axis='y', length=0)\n",
    "    if ax == axes[0]:\n",
    "        ax.set(xlabel='no. reservoirs')\n",
    "    elif ax == axes[1]:\n",
    "        ax.set(xlabel='total volume (hm3)')\n",
    "        \n",
    "plt.savefig(PATH_PLOTS / 'reservoir_volume_barplot.jpg', dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19d374d-85e8-4a48-9e03-65928fb407d8",
   "metadata": {},
   "source": [
    "The data in the plots above only represents the reservoirs in the datasets (EFAS, GRanD, ICOLD) that I could match with reservoirs in the HDCC database. The datasets on their own may contain more reservoirs; for instance, ICOLD includes 1066 reservoirs in Spain, but \"only\" 374 could be matched with the 394 reservoirs in HDCC.\n",
    "\n",
    "EFAS and GRanD are the two data sets with fewer number of reservoirs. However, the total volume that those reservoirs represent is very close to more comprehensive data sets as ICOLD or CEDEX. Interestingly, the total volume in ICOLD slightly exceeds that in CEDEX. This could be caused by the fact that CEDEX volume does not represent total capacity, but the storage at the normal reservoir level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dcbebf-92cd-4722-bcdf-e955333eff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair plot\n",
    "pair_plot = sns.pairplot(volume, corner=True, plot_kws={'alpha': .5})\n",
    "\n",
    "# reference 1:1 line\n",
    "nrow, ncol = pair_plot.axes.shape\n",
    "vmin, vmax = volume.min().min(), volume.max().max()\n",
    "for i in range(nrow):\n",
    "    for j in range(ncol):\n",
    "        if i > j:\n",
    "            pair_plot.axes[i, j].plot([vmin, vmax], [vmin, vmax],\n",
    "                                      c='k', lw=1, ls=':', zorder=0)\n",
    "pair_plot.fig.suptitle('Reservoir volume (hm3)')\n",
    "\n",
    "plt.savefig(PATH_PLOTS / 'reservoir_volume_pairplot.jpg', dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87beca08-9a5a-4541-8798-04b6a6d76dd5",
   "metadata": {},
   "source": [
    "I assume that CEDEX `CEDEX` is the reference data set, as it is the local data set that probably was used by GRanD and ICOLD to develop their global data sets.\n",
    "\n",
    "Overall, there's a good agreement between all data sets:\n",
    " * ICOLD has a few reservoirs whose storage clearly exceeds the values reported by CEDEX.\n",
    " * GRanD reservoir storage shows more deviations compared with CEDEX. This deviations are small in most cases, and both overestimate or underestimate storage.\n",
    " * As the majority of reservoirs in EFAS come from GRanD, the analysis is similar to that of GRanD.\n",
    " * The live volume in CEDEX reservoirs is obviously smaller than the normal storage in most of the cases. However, there are a couple of errors in which the live volume exceeds the normal volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e68d303-dfd5-422e-b216-edf803c649f4",
   "metadata": {},
   "source": [
    "### Reservoir surface area\n",
    "\n",
    "All reservoir area values are in km2:\n",
    "\n",
    "* CEDEX dams: `'A_MNL'` in ha. This value does not represent the maximum area, but the surface at a normal level.\n",
    "* CEDEX reservoirs: `'AREA'`\n",
    "* ICOLD: `'Res_Area'`\n",
    "* EFAS: none\n",
    "* GRanD: `'AREA_SKM'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b60666-95b9-4e3b-b569-74e49023a456",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'AREA_SKM'\n",
    "\n",
    "# combine all volume data in a single table\n",
    "area = pd.concat((cedex[[variable, 'AREA_MNL']],\n",
    "                  icold[variable],\n",
    "                  #efas[variable],\n",
    "                  grand[variable], \n",
    "                 ), axis=1)\n",
    "area.columns = ['CEDEX', 'CEDEX_MNL', 'ICOLD', 'GRanD']\n",
    "\n",
    "print('Number of reservoirs:\\t{0}\\nNumber of data sets:\\t{1}'.format(*area.shape))\n",
    "\n",
    "# summarize\n",
    "area_summary = pd.concat(((~area.isnull()).sum(), area.sum()), axis=1)\n",
    "area_summary.columns = ['no_reservoirs', 'total_area']\n",
    "area_summary.sort_values('no_reservoirs', ascending=False, inplace=True)\n",
    "\n",
    "# plot summary\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(8.5, 4), sharey=True)\n",
    "for ax, col in zip(axes, area_summary):\n",
    "    ax.barh(area_summary.index, area_summary[col], color='lightsteelblue')\n",
    "    ax.spines[['top', 'left', 'right', 'bottom']].set_visible(False)\n",
    "    ax.tick_params(axis='y', length=0)\n",
    "    if ax == axes[0]:\n",
    "        ax.set(xlabel='no. reservoirs')\n",
    "    elif ax == axes[1]:\n",
    "        ax.set(xlabel='total area (km²)')\n",
    "        \n",
    "plt.savefig(PATH_PLOTS / 'reservoir_area_barplot.jpg', dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef680d2f-3f10-449b-8c98-4d0d9c934577",
   "metadata": {},
   "source": [
    "The values for ICOD and CEDEX are very similar, both in terms of number of reservoirs and the total reservoir area. As seen for volume, ICOLD has a slightly smaller set of reservoirs than CEDEX, but the total aggregation slightly exceeds CEDEX. Again, this could be caused by CEDEX reporting area/volume at normal reservoir level, not at its maximum level.\n",
    "\n",
    "GRanD reports reservoir area in approximately half of the reservoirs. The total reservoir area seems to be in a similar proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca26967-9a1a-4a04-84fe-8d0ad4932220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair plot\n",
    "pair_plot = sns.pairplot(area, corner=True, plot_kws={'alpha': .5})\n",
    "\n",
    "# reference 1:1 line\n",
    "nrow, ncol = pair_plot.axes.shape\n",
    "amin, amax = area.min().min(), area.max().max()\n",
    "for i in range(nrow):\n",
    "    for j in range(ncol):\n",
    "        if i > j:\n",
    "            pair_plot.axes[i, j].plot([amin, amax], [amin, amax],\n",
    "                                      c='k', lw=1, ls=':', zorder=0)\n",
    "pair_plot.fig.suptitle('Reservoir surface (km²)')\n",
    "\n",
    "plt.savefig(PATH_PLOTS / 'reservoir_area_pairplot.jpg', dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2397f787-863a-44c1-a362-02b92db1f125",
   "metadata": {},
   "source": [
    "The pair plots above show that GRanD underestimates reservoir area., and there seems to be a clear trend (even though the spread increases with increasing reservoir size).\n",
    "\n",
    "ICOLD data agrees appropriately with CEDEX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2226df9-3b55-4978-96ce-48c08e72cee9",
   "metadata": {},
   "source": [
    "### Catchment area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafcb0cf-abec-4407-9177-60bac46a01ce",
   "metadata": {},
   "source": [
    "All catchment area values are in km2?\n",
    "\n",
    "* CEDEX dams: `'catch_area'` in ha. This value does not represent the maximum area, but the surface at a normal level.\n",
    "* ICOLD: `'Catch_Area'`\n",
    "* EFAS: none\n",
    "* GRanD: `'CATCH_SKM'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5afb2f-c05b-49dc-a6c7-d50d4fc1087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable = 'CATCH_SKM'\n",
    "\n",
    "# combine all volume data in a single table\n",
    "catchment = pd.concat((cedex[variable],\n",
    "                       efas[variable],\n",
    "                       icold[variable],\n",
    "                       grand[variable], \n",
    "                      ), axis=1)\n",
    "catchment.columns = ['CEDEX', 'EFAS', 'ICOLD', 'GRanD']\n",
    "\n",
    "print('Number of reservoirs:\\t{0}\\nNumber of data sets:\\t{1}'.format(*catchment.shape))\n",
    "\n",
    "# summarize\n",
    "catchment_summary = pd.concat(((~catchment.isnull()).sum(), catchment.sum()), axis=1)\n",
    "catchment_summary.columns = ['no_reservoirs', 'total_area']\n",
    "catchment_summary.sort_values('no_reservoirs', ascending=False, inplace=True)\n",
    "\n",
    "# plot summary\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(8.5, 4), sharey=True)\n",
    "for ax, col in zip(axes, catchment_summary):\n",
    "    ax.barh(catchment_summary.index, catchment_summary[col], color='lightsteelblue')\n",
    "    ax.spines[['top', 'left', 'right', 'bottom']].set_visible(False)\n",
    "    ax.tick_params(axis='y', length=0)\n",
    "    if ax == axes[0]:\n",
    "        ax.set(xlabel='no. reservoirs')\n",
    "    elif ax == axes[1]:\n",
    "        ax.set(xlabel='total catchment area (km²)')\n",
    "        \n",
    "plt.savefig(PATH_PLOTS / 'reservoir_catchment_barplot.jpg', dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc406fa-7805-4f20-9804-d62f9e80c594",
   "metadata": {},
   "source": [
    "The catchment area value is missing from several reservoirs in CEDEX, which causes that ICOLD is the most comprehensive data set. Even though the number of reservoirs in GRanD that report catchment area is notably smaller, the total catchment area is close to other data sets, meaning that GRanD includes the reservoirs with larger contributing area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e25e0c8-4f82-425b-ba37-b6e6c6b12c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair plot\n",
    "pair_plot = sns.pairplot(catchment, corner=True, plot_kws={'alpha': .5})\n",
    "\n",
    "# reference 1:1 line\n",
    "nrow, ncol = pair_plot.axes.shape\n",
    "amin, amax = catchment.min().min(), catchment.max().max()\n",
    "for i in range(nrow):\n",
    "    for j in range(ncol):\n",
    "        if i > j:\n",
    "            pair_plot.axes[i, j].plot([amin, amax], [amin, amax],\n",
    "                                      c='k', lw=1, ls=':', zorder=0)\n",
    "pair_plot.fig.suptitle('Catchment area (km²)')\n",
    "            \n",
    "plt.savefig(PATH_PLOTS / 'reservoir_catchment_pairplot.jpg', dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e698ab-b54f-4f09-b36f-08cf4a81969a",
   "metadata": {},
   "source": [
    "There is a considerable scatter in the areas among the smallest catchments. Specifically, GRanD has some rerservoirs which overestimate catchment area compared both with CEDEX and ICOLD. ICOLD, instead, includes catchment areas that differ in both ways (over or underestimate) the area of small catchments compared with CEDEX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabfec54-5917-403a-a9c4-992547e45e03",
   "metadata": {},
   "source": [
    "**Test GIS and `cutmaps` catchments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf82fc8a-c475-4ca9-9e78-80518600f2fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate the upstream area for each reservoir catchment\n",
    "filename = 'upArea_01min.nc'\n",
    "path_cutmaps = PATH_RESOPSES / 'ancillary' / 'cutmaps'\n",
    "cutmaps = pd.Series(index=points.id, dtype=float, name='CATCH_SKM')\n",
    "cutmaps.index.name = 'SNCZI'\n",
    "for ID in tqdm(cutmaps.index):\n",
    "    # load map cut\n",
    "    data = xr.open_dataset(path_cutmaps / ID / filename)['Band1']\n",
    "    # calculate catchment area in km²\n",
    "    cutmaps.loc[ID] = data.max().values / 1e6\n",
    "\n",
    "# assign values to the \"catchment\" DataFrame\n",
    "cutmaps.index = cutmaps.index.astype(int)\n",
    "catchment.loc[cutmaps.index, 'cutmaps'] = cutmaps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977a2af-264b-4876-b789-79d20fccc618",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import watershed polygons derived in GIS\n",
    "gis = gpd.read_file(PATH_RESOPSES / 'GIS' / 'Layers' / 'watershed_305.shp')\n",
    "gis.Name = gis.Name.astype('Int64')\n",
    "gis.rename(columns={'Name': 'SNCZI', 'Shape_Leng': 'LENG_KM', 'Shape_Area': 'CATCH_SKM'}, inplace=True)\n",
    "gis.set_index('SNCZI', inplace=True)\n",
    "gis.drop(['OID_', 'HydroID'], axis=1, inplace=True)\n",
    "\n",
    "# assign values to the \"catchment\" DataFrame\n",
    "catchment.loc[gis.index, 'GIS'] = gis.CATCH_SKM.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a8f477-101c-41ce-8e02-d44343e5350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(catchment, corner=True, plot_kws={'alpha': .5});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b8c71-ad1e-49db-a52e-d38f3ba94ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "catchment.loc[[616, 1038, 1290, 1342, 1643, 1840, 1953, 2050]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96a6d4d-bf1a-48ce-a504-7c9bdd3ca663",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = reservoirs.loc[reservoirs.TS == 1].index.difference(watershed.index).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d95bf6-e92a-4c63-9777-fac54e1dee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoirs.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea611bdd-4f66-4556-a5fc-ee2f76df4316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "watershed.boundary.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45687633-cab5-4c11-a3b7-a0a2d4aceecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to the comparative table the area of the polygons derived in GIS\n",
    "catchment.loc[watershed.index, 'GIS'] = watershed['CATCH_SKM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2294d5a1-1d2a-4428-be5d-e78160300efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a field reporting the most reliable value of the catchment area\n",
    "# catchment['CATCH_SKM'] = catchment[['CEDEX', 'ICOLD']].max(axis=1)\n",
    "# mask = catchment.CATCH_SKM.isnull()\n",
    "# catchment.loc[mask, 'CATCH_SKM'] = catchment.loc[mask, 'GRanD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2cd5d5-22b0-4def-9fac-419891c0fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a field reporting the most reliable value of the catchment area\n",
    "catchment['CATCH_SKM'] = catchment.GRanD\n",
    "mask = catchment.CATCH_SKM.isnull()\n",
    "catchment.loc[mask, 'CATCH_SKM'] = catchment.loc[mask, ['CEDEX', 'ICOLD']].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b0e842-09d7-4625-893e-2488d4458b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = (catchment.GIS - catchment.CATCH_SKM) / catchment.CATCH_SKM * 100\n",
    "catchment.loc[error.abs() > 50].sort_index().round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb77720-848e-4999-96a2-098b3963f576",
   "metadata": {},
   "source": [
    "It seems like GRanD is a more reliable source in terms of catchment area, so, when available, I compare against this data set. If not avaible, I compare agains the minimum between CEDEX and ICOLD.\n",
    "\n",
    "* __Correct in GIS__: 52, 173, 317, 400, 442, 620, 916, 993, 1019, 1062, 1075, 1125, 1285, 1565, 1657, 2083, 2101, 2175, 2261, 2469?, 2561\n",
    "* __Wrong in GIS__: 616, 1038, 1290, 1342, 1643, 1840, 1953, 2050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4279ef89-05c6-47e5-86f4-e4a5f9ce899d",
   "metadata": {},
   "source": [
    "Incongruences between CEDEX and ICOLD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7f8fb4-6ca4-44cb-be42-c5225ae52455",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{catchment.CEDEX.isnull().sum()} reservoir miss the catchment area in CEDEX')\n",
    "print(f'{catchment.ICOLD.isnull().sum()} reservoir miss the catchment area in ICOLD')\n",
    "print(f'{catchment.GRanD.isnull().sum()} reservoir miss the catchment area in GRanD')\n",
    "print(f'{catchment.GIS.isnull().sum()} reservoir miss the catchment area in GIS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c92fa1f-a904-49e1-a9b5-f4967fc4bee0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Reservoir use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a154cdc-23c3-4a0d-a120-f61dba50761e",
   "metadata": {},
   "source": [
    "**Main use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1db75b-576a-4ccd-b294-0ccf33f03f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_use = {'CEDEX': mainuse_summary_cedex,\n",
    "            'ICOLD': mainuse_summary_icold,\n",
    "            'GRanD': mainuse_summary_grand}\n",
    "\n",
    "fig, axes = plt.subplots(ncols=len(main_use), figsize=(len(main_use) * 4, 4), sharex=True, tight_layout=True)\n",
    "for ax, (label, df) in zip(axes, main_use.items()):\n",
    "    ax.barh(df.index, df.multipurpose, color='steelblue', label='multi-purpose')\n",
    "    ax.barh(df.index, df.singlepurpose, color='lightsteelblue', label='single purpose')\n",
    "    ax.set(title=label,\n",
    "           xlabel='no. reservoirs')\n",
    "    ax.tick_params(axis='y', length=0)\n",
    "    ax.spines[['top', 'left', 'right', 'bottom']].set_visible(False);\n",
    "fig.suptitle('Main reservoir use')\n",
    "fig.legend(*ax.get_legend_handles_labels(), loc=5, frameon=False, bbox_to_anchor=[1.02, .4, .1, .2]);\n",
    "\n",
    "plt.savefig(PATH_PLOTS / 'reservoir_main_use.jpg', dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfa0bb9-eef9-4d61-a2d7-63dd85c39982",
   "metadata": {},
   "source": [
    "The definition of the main use of a reservoir is ambiguous. Is it the use that requires larger water volume? Is it a design decision? \n",
    "\n",
    "The ambiguity is clear in the plot above. Even though the two most common main uses (supply and hydropower) coincide in CEDEX and ICOLD, the figures differ notably. These two data sets assign different importance to flood and irrigation. On the contrary, GRanD identifies irrigation as the main reservoir use in Spain, followed by hydropower and supply; flood control has no importance in this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27de15f-40c2-4e1c-863a-65cbdcb40d4e",
   "metadata": {},
   "source": [
    "**All uses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fd3481-b0f1-4815-ab10-e94778766b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_uses = {'CEDEX': alluses_summary_cedex,\n",
    "            'ICOLD': alluses_summary_icold,\n",
    "            'GRanD': alluses_summary_grand}\n",
    "\n",
    "fig, axes = plt.subplots(ncols=len(all_uses), figsize=(len(all_uses) * 4, 4), sharex=True, tight_layout=True)\n",
    "for ax, (label, df) in zip(axes, all_uses.items()):\n",
    "    ax.barh(df.index, df.multipurpose, color='steelblue', label='multi-purpose')\n",
    "    ax.barh(df.index, df.singlepurpose, color='lightsteelblue', label='single purpose')\n",
    "    ax.set(title=label,\n",
    "           xlabel='no. reservoirs')\n",
    "    ax.tick_params(axis='y', length=0)\n",
    "    ax.spines[['top', 'left', 'right', 'bottom']].set_visible(False);\n",
    "fig.suptitle('All reservoir uses')\n",
    "fig.legend(*ax.get_legend_handles_labels(), loc=5, frameon=False, bbox_to_anchor=[1.02, .4, .1, .2]);\n",
    "\n",
    "plt.savefig(PATH_PLOTS / 'reservoir_all_uses.jpg', dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dce7120-e483-406d-8cff-e71b8f367bb6",
   "metadata": {},
   "source": [
    "The difference between the three data sets remains when looking at all the reservoir uses. ICOLD and GRanD identify hydropower and irrigation as the two most common uses, even though the order differs between them two. CEDEX, instead, considers water supply as the main use (3rd in ICOLD and GRanD), and limits hydropower and irrigation to the 3rd and 4th rank. It's remarkable that flood control is the second most common use in CEDEX, but it has a residual value in both ICOLD and GRanD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a47590e-2159-4fbb-998a-9f9db57fe180",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c44ec3-1509-47bd-8eb6-0bd9600cf13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_snczi_grand = grand.GRAND_ID.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d403d6-ce1e-4492-b2c7-0af050627773",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(map_snczi_grand), cedex.shape[0], grand.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92acf83-8d85-4fd2-b0f0-aaa136b1e2e1",
   "metadata": {},
   "source": [
    "### CEDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f8958-81fc-4bd1-8163-53270143ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set GRAND_ID as index\n",
    "cedex.reset_index(inplace=True)\n",
    "cedex['GRAND_ID'] = cedex.SNCZI.map(map_snczi_grand)\n",
    "cedex = cedex[cedex.GRAND_ID.notnull()]\n",
    "cedex.GRAND_ID = cedex.GRAND_ID.astype(int)\n",
    "cedex.set_index('GRAND_ID', inplace=True)\n",
    "print(f'{len(cedex)} CEDEX reservoirs have a GRAND_ID')\n",
    "\n",
    "# convert boolean fields to 0-1\n",
    "bool_cols = list(rename_uses_cedex.values()) + ['single_use']\n",
    "cedex[bool_cols] = cedex[bool_cols].astype(bool).astype(int)\n",
    "\n",
    "# reorder columns\n",
    "cols_cedex = cedex.columns.tolist()\n",
    "cols_cedex.remove('RES_NAME')\n",
    "cols_cedex = ['RES_NAME'] + cols_cedex\n",
    "cedex = cedex[cols_cedex]\n",
    "\n",
    "# export\n",
    "cedex.drop(columns=['geometry']).to_csv(cfg.PATH_ATTRS / 'cedex.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a77859b-3a5f-4056-ab99-d9e2b43a9873",
   "metadata": {},
   "source": [
    "### EFAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ee8f4-b0ac-4837-800f-b4818a94c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set GRAND_ID as index\n",
    "efas.reset_index(inplace=True)\n",
    "efas['GRAND_ID'] = efas.SNCZI.map(map_snczi_grand)\n",
    "efas = efas[efas.GRAND_ID.notnull()]\n",
    "efas.GRAND_ID = efas.GRAND_ID.astype(int)\n",
    "efas.set_index('GRAND_ID', inplace=True)\n",
    "print(f'{len(efas)} EFAS reservoirs have a GRAND_ID')\n",
    "\n",
    "# rename columns\n",
    "efas.rename(columns={'ACTIVE_FRO': 'YEAR'}, inplace=True)\n",
    "\n",
    "# attributes to be included from EFAS\n",
    "cols_efas = ['SNCZI', 'DAM_NAME', 'YEAR',\n",
    "             # coordinates\n",
    "             'LON', 'LAT', 'LisfloodX', 'LisfloodY',\n",
    "             # LISFLOOD limits\n",
    "             'Vc', 'Vf', 'Qmin', 'Qnd', 'Vn', 'Qn', 'CAP_MCM',\n",
    "             # catchment area\n",
    "            'CATCH_SKM']\n",
    "\n",
    "# export as CSV\n",
    "efas[cols_efas].to_csv(cfg.PATH_ATTRS / 'efas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee9696a-cd36-4ed1-afd2-f39da44d90e3",
   "metadata": {},
   "source": [
    "### ICOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1273c9da-f5ba-458a-85f4-d990c23f4126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set GRAND_ID as index\n",
    "icold.reset_index(inplace=True)\n",
    "icold['GRAND_ID'] = icold.SNCZI.map(map_snczi_grand)\n",
    "icold = icold[icold.GRAND_ID.notnull()]\n",
    "icold.GRAND_ID = icold.GRAND_ID.astype(int)\n",
    "icold.set_index('GRAND_ID', inplace=True)\n",
    "print(f'{len(icold)} ICOLD reservoirs have a GRAND_ID')\n",
    "\n",
    "# convert 'SNCZI' to integer\n",
    "# icold.SNCZI = icold.SNCZI.astype('Int64')\n",
    "# icold.set_index('SNCZI', inplace=True)\n",
    "\n",
    "# convert boolean fields to 0-1\n",
    "bool_cols = list(rename_uses_icold.values()) + ['single_use']\n",
    "icold[bool_cols] = icold[bool_cols].astype(bool).astype(int)\n",
    "\n",
    "# attributes to be included from ICOLD\n",
    "cols_icold = ['SNCZI', 'RES_NAME', 'DAM_NAME', 'ELEV_MASL', 'CATCH_SKM', 'DAM_LEN_M', \n",
    "              'Elec_Capac', 'Ene_Annual',\n",
    "              'Foundation', 'DAM_HGT_M',\n",
    "              'Irr_Area', \n",
    "              'LON', 'LAT',\n",
    "              'AREA_SKM', 'RES_LEN_KM', 'CAP_MCM', 'Resettled',\n",
    "              'Spill_Cap', 'Spill_Type', 'Vol_flood', 'Year',\n",
    "              'main_use', 'single_use', 'fish', 'flood', 'hydropower', 'irrigation', 'navigation', 'other', 'recreation', 'supply', 'tailings']\n",
    "\n",
    "# export attribute table\n",
    "icold[cols_icold].to_csv(cfg.PATH_ATTRS / 'icold.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f801af35-1c41-4570-8288-9d97ecc6f29f",
   "metadata": {},
   "source": [
    "### GRanD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07aca37-56af-4bc6-82e0-4b3abdca8a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set GRAND_ID as index\n",
    "grand.reset_index(inplace=True)\n",
    "grand.set_index('GRAND_ID', inplace=True)\n",
    "print(f'{len(grand)} reservoirs in GRanD')\n",
    "\n",
    "# convert boolean fields to 0-1\n",
    "bool_cols = list(rename_uses_grand.values()) + ['SINGLE_USE']\n",
    "grand[bool_cols] = grand[bool_cols].astype(bool).astype(int)\n",
    "\n",
    "# attributes to be included from EFAS\n",
    "cols_grand = ['SNCZI', 'RES_NAME', 'DAM_NAME', 'YEAR', 'REM_YEAR', 'LON', 'LAT',\n",
    "              'DAM_HGT_M', 'DAM_LEN_M', 'AREA_SKM', 'CAP_MCM', 'DEPTH_M', 'DIS_AVG_LS', 'DOR_PC', 'ELEV_MASL', 'CATCH_SKM',\n",
    "              'irrigation', 'hydropower', 'supply', 'flood', 'recreation', 'navigation', 'fish', 'pollution', 'livestock', 'other', 'MAIN_USE', 'SINGLE_USE','LAKE_CTRL']\n",
    "\n",
    "# export as CSV\n",
    "grand[cols_grand].to_csv(cfg.PATH_ATTRS / 'grand.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a69598e-147e-441b-b870-30a17a7e7129",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "ICOLD seems to be the best data set to extract the reservoir static attributes. In the specific case of Spain, the Spanish National Inventory of Reservoirs and Dams (CEDEX) is more comprehensive, both in terms of number of reservoirs and the number of attributes. However, since this is only an exercise that must be extrapolated continentally/globally, we need to use a global data set like ICOLD or GRanD. The comparison of these two global data sets against CEDEX shows that the figures in ICOLD are closer to the reference. On top of that, I could match 374 reservoirs between the observed time series and ICOLD, and only 225 with GRanD, so using ICOLD increases notably the sample of reservoirs.\n",
    "\n",
    "The drawback of using ICOLD is that the data can not be open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7ceb30-4100-485d-859d-cf882b595d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export shapefile of reservoirs\n",
    "hdcc['lon_orig'] = hdcc.geometry.x\n",
    "hdcc['lat_orig'] = hdcc.geometry.y\n",
    "hdcc[['lon_lisf', 'lat_lisf']] = np.nan\n",
    "\n",
    "# hdcc.to_file(PATH_RESOPSES / 'GIS' / 'reservoirs_ResOpsES.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd555531-7479-47be-8da7-69b89bc182c8",
   "metadata": {},
   "source": [
    "### Reservoirs with time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c531fa-9508-47b3-be55-6fccc1482440",
   "metadata": {},
   "source": [
    "**Anuario de Aforos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc3ba33-683f-477f-a034-c08f02b406b4",
   "metadata": {},
   "source": [
    "Import shapefile of reservoirs in the Hydrological Data Colection Center (HDCC) database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477bb7cc-d50d-49ab-ad07-0329602faa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_cedex = PATH_DATASETS / 'CEDEX' / 'processed' / 'reservoirs'\n",
    "reservoirs_AA = gpd.read_file(path_cedex / 'attributes' / 'GIS' / 'reservoirs.shp')\n",
    "reservoirs_AA.ref_ceh = reservoirs_AA.ref_ceh.astype('Int64')\n",
    "reservoirs_AA['source'] = 'CEDEX'\n",
    "reservoirs_AA.rename(columns={'nombre': 'name', 'ref_ceh': 'ID'}, inplace=True)\n",
    "reservoirs_AA['SNCZI'] = reservoirs_AA['SNCZI'].replace(0, np.nan).astype('Int64')\n",
    "reservoirs_AA.set_index('SNCZI', drop=True, inplace=True)\n",
    "reservoirs_AA.sort_index(axis=0, inplace=True)\n",
    "\n",
    "print('Anuario de Aforos contains {0} reservoirs'.format(reservoirs_AA.shape[0]))\n",
    "print('{0} reservoirs are not connected to the SNCZI database'.format((reservoirs_AA.index.isnull()).sum()))\n",
    "# reservoirs_AA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482e3f1f-3b2c-4dea-baa0-4e6dd6c341dc",
   "metadata": {},
   "source": [
    "**Agència Catalana de l'Aigua**\n",
    "\n",
    "I have downloaded reservoir records from the ACA website, but these reservoirs are not yet in HDCC. I will upload here the shapefile of the ACA reservoirs and concatenate it to HDCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c003556-c6c7-4826-8efb-0c61643e16be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load shapefile and treat the data\n",
    "reservoirs_aca = gpd.read_file(PATH_DATASETS / 'ACA' / 'processed' / 'reservoirs' / 'attributes' / 'GIS' / 'reservoirs_ACA.shp')\n",
    "reservoirs_aca['source'] = 'ACA'\n",
    "reservoirs_aca.set_index('SNCZI', inplace=True, drop=True)\n",
    "reservoirs_aca.rename(columns={'ID_ACA': 'ID'}, inplace=True)\n",
    "\n",
    "print('ACA contains {0} reservoirs'.format(reservoirs_aca.shape[0]))\n",
    "print('{0} reservoirs are not connected to the SNCZI database'.format((reservoirs_aca.index.isnull()).sum()))\n",
    "# reservoirs_aca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bddecc-16e3-474c-96ad-c4eacf95b2a9",
   "metadata": {},
   "source": [
    "**Hidrosur**\n",
    "\n",
    "I have requested reservoir data from Hidrosur. This data is not yet in HDCC, so I will load it here and combine it with the reservoirs in HDCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab930bfc-3d93-4566-94c8-f100efba1dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load shapefile and treat the data\n",
    "reservoirs_sur = gpd.read_file(PATH_DATASETS / 'Hidrosur' / 'processed' / 'reservoirs' / 'attributes' / 'GIS' / 'reservoirs_hidrosur.shp')\n",
    "reservoirs_sur['source'] = 'Hidrosur'\n",
    "reservoirs_sur['SNCZI'] = reservoirs_sur['SNCZI'].astype('Int64')\n",
    "reservoirs_sur.set_index('SNCZI', drop=True, inplace=True)\n",
    "\n",
    "print('Hidrosur contains {0} reservoirs'.format(reservoirs_sur.shape[0]))\n",
    "print('{0} reservoirs are not connected to the SNCZI database'.format((reservoirs_sur.index.isnull()).sum()))\n",
    "# reservoirs_sur.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bddf17-e2f1-49b0-afb3-e7dbc53ed330",
   "metadata": {},
   "source": [
    "**Merge all**\n",
    "\n",
    "<font color='indianred'>I remove the reservoirs without SNCZI code.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79145027-62a2-4cbc-8af1-e4e7d3499fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['ID', 'name', 'source', 'geometry']\n",
    "hdcc = pd.concat((reservoirs_AA[cols], reservoirs_aca[cols], reservoirs_sur[cols]), axis=0)\n",
    "hdcc.index = hdcc.index.astype('Int64')\n",
    "# remove one of the instances of the Siurana reservoir (included both in Anuario and ACA)\n",
    "# I remove the instance in the ACA (`ID == 'E18')\n",
    "hdcc = hdcc.loc[hdcc.ID != 'E18']\n",
    "hdcc.name = hdcc.name.str.replace(r'(.+), (.+)', r'\\2 \\1', regex=True)\n",
    "# hdcc.name = hdcc.name.apply(unidecode.unidecode)\n",
    "hdcc.name = [remove_accents(name) for name in hdcc.name]\n",
    "\n",
    "print('Anuario + ACA + Hidrosur:\\t{0} reservoirs'.format(hdcc.shape[0]))\n",
    "print('{0} reservoirs are not connected to the SNCZI database'.format((hdcc.index.isnull()).sum()))\n",
    "\n",
    "hdcc = hdcc.loc[~(hdcc.index.isnull())]\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='face', facecolor='lightgray'),\n",
    "               alpha=.5,\n",
    "               zorder=0)\n",
    "hdcc.plot(markersize=5, ax=ax)\n",
    "ax.set_title(f'Hydro DB\\n{hdcc.shape[0]} reservoirs')\n",
    "ax.set_extent([-10, 4.5, 35.5, 44])\n",
    "ax.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db2b1dd-9674-4ebd-805a-c39fc046d0fd",
   "metadata": {},
   "source": [
    "### Select reservoirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a89e7f-43d2-4de7-9eed-e541b48dab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = {'CEDEX': mask_cedex,\n",
    "         'EFAS': mask_efas,\n",
    "         'ICOLD': mask_icold,\n",
    "         'GRanD': mask_grand}\n",
    "\n",
    "attributes = {'CEDEX': cedex,\n",
    "              'EFAS': efas,\n",
    "              'ICOLD': icold,\n",
    "              'GRanD': grand}\n",
    "\n",
    "summary = pd.DataFrame(index=attributes.keys(), columns=['initially', 'selected', 'timeseries'])\n",
    "for label, df in attributes.items():\n",
    "    summary.loc[label, 'initially'] = masks[label].shape[0]\n",
    "    summary.loc[label, 'selected'] = df.shape[0]\n",
    "    summary.loc[label, 'timeseries'] = len(df.index.intersection(hdcc.index))\n",
    "    \n",
    "total_IDs = []\n",
    "for label, serie in masks.items():\n",
    "    total_IDs += serie.index.tolist()\n",
    "total_IDs = set(total_IDs)\n",
    "summary.loc['total', 'initially'] = len(total_IDs)\n",
    "    \n",
    "selected_IDs = []\n",
    "for label, df in attributes.items():\n",
    "    selected_IDs += df.index.tolist()\n",
    "selected_IDs = set(selected_IDs)\n",
    "summary.loc['total', 'selected'] = len(selected_IDs)\n",
    "summary.loc['total', 'timeseries'] = len(selected_IDs.intersection(hdcc.index))\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c0ed2-1fbb-4b42-9f12-7eee2f7386e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoirs = pd.DataFrame(columns=['RES_NAME', 'DAM_NAME', 'LON', 'LAT', 'CAP_MCM', 'AREA_SKM', 'CATCH_SKM'])\n",
    "reservoirs.index.name = 'SNCZI'\n",
    "\n",
    "# add reservoirs from CEDEX\n",
    "reservoirs = pd.concat((reservoirs, cedex[reservoirs.columns]))\n",
    "\n",
    "# add reservoirs from ICOLD\n",
    "sel = icold.index.difference(reservoirs.index)\n",
    "reservoirs = pd.concat((reservoirs, icold.loc[sel, reservoirs.columns]))\n",
    "\n",
    "# add reservoirs from GRanD\n",
    "sel = grand.index.difference(reservoirs.index)\n",
    "reservoirs = pd.concat((reservoirs, grand.loc[sel, reservoirs.columns]))\n",
    "\n",
    "# add reservoirs from EFAS\n",
    "sel = efas.index.difference(reservoirs.index)\n",
    "reservoirs = pd.concat((reservoirs, efas.loc[sel, ['DAM_NAME', 'LON', 'LAT', 'CAP_MCM', 'CATCH_SKM']]))\n",
    "\n",
    "# time series available?\n",
    "# reservoirs['TS'] = 0\n",
    "idx_ts = reservoirs.index.intersection(hdcc.index)\n",
    "# reservoirs.loc[idx_ts, 'TS'] = 1\n",
    "reservoirs.loc[idx_ts, ['SOURCE_TS', 'ID_TS']] = hdcc.loc[idx_ts, ['source', 'ID']].values\n",
    "\n",
    "# convert into GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(reservoirs.LON, reservoirs.LAT)]\n",
    "reservoirs = gpd.GeoDataFrame(reservoirs, geometry=geometry, crs='epsg:4326')\n",
    "\n",
    "# export point shapefile\n",
    "reservoirs.loc[reservoirs.ID_TS.notnull()].to_file(PATH_RESOPSES / 'GIS' / 'reservoirs_ResOpsES.shp')\n",
    "\n",
    "reservoirs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ffdee0-e8d5-4184-a1d4-302cd6d85485",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152951ce-3811-4a1e-af96-56c27c8e6d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TXT file to apply CUTMAPS\n",
    "path_cutmaps = PATH_RESOPSES / 'ancillary' / 'cutmaps' / 'input'\n",
    "points = gpd.read_file(path_cutmaps / 'reservoirs.shp')\n",
    "points = points[['LON', 'LAT', 'SNCZI']]\n",
    "points[['LON', 'LAT']] = points[['LON', 'LAT']].astype(float).round(4)\n",
    "points['SNCZI'] = [f'{ID:04}' for ID in points.SNCZI]\n",
    "\n",
    "points.to_csv(path_cutmaps / 'reservoirs.txt',\n",
    "              sep='\\t',\n",
    "              header=False,\n",
    "              index=False,\n",
    "              float_format='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8ec080-46f9-4d9e-aba1-f552c3babbe5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693182f6-4a59-40e5-a7e4-879a43cf7b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create CSV file to apply NCEXTRACT\n",
    "path_ncextract = PATH_RESOPSES / 'ancillary' / 'ncextract'\n",
    "points = gpd.read_file(path_ncextract / 'reservoirs.shp')\n",
    "points = points[['LON', 'LAT', 'SNCZI']]\n",
    "points[['LON', 'LAT']] = points[['LON', 'LAT']].astype(float).round(4)\n",
    "points['SNCZI'] = [f'{ID:04}' for ID in points.SNCZI]\n",
    "points.rename(columns={'SNCZI': 'id', 'LAT': 'lat', 'LON': 'lon'}, inplace=True)\n",
    "\n",
    "points[['id', 'lat', 'lon']].to_csv(path_ncextract / 'reservoirs.csv',\n",
    "                                    header=True,\n",
    "                                    index=False,\n",
    "                                    float_format='%.4f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ea858f-426c-48b1-b755-1d3b19a83121",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
