{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea5bd7d-c20e-4161-8483-6de3327e14ef",
   "metadata": {},
   "source": [
    "# Spanish Inventory of Dams and Reservoirs\n",
    "***\n",
    "\n",
    "**_Author:_** Chus Casado Rodríguez<br>\n",
    "**_Date:_** 10-04-2024<br>\n",
    "\n",
    "**Introduction:**<br>\n",
    "This notebook downloads the reports from the Spanish Inventory of Dams and Reservoirs (_Inventario de Presas y Embalses de España_, IPEE), and them loads the reports, treats them and export them as CSV files. The process is repeated for reservoirs and dams, as they have different reports in the inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fb9455a-c6b8-42f3-a31b-10abb4bc5f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append('../../src/')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from lisfloodreservoirs.utils.SNCZI import reservoir_attributes, dam_attributes\n",
    "from lisfloodreservoirs.utils.names import correct_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "1942e1f5-67d7-460d-afc0-6d736634524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_accents(string: str) -> str:\n",
    "    \n",
    "#     string = re.sub(r'[ÁáÀà]', 'A', string)\n",
    "#     string = re.sub(r'[Éé]', 'E', string)\n",
    "#     string = re.sub(r'[Íí]', 'I', string)\n",
    "#     string = re.sub(r'[Óó]', 'O', string)\n",
    "#     string = re.sub(r'[Úú]', 'U', string)\n",
    "\n",
    "#     return string\n",
    "\n",
    "# def swap_words(string: str, split_pattern: str = '. ') -> str:\n",
    "    \n",
    "#     words = string.split(split_pattern)\n",
    "#     if len(words) == 2:\n",
    "#         return ' '.join([word.strip() for word in words[::-1]])\n",
    "#     else:\n",
    "#         return string\n",
    "\n",
    "# def arabic_to_roman(match):\n",
    "#     arabic = int(match.group(0))\n",
    "#     roman_numerals = {\n",
    "#         1: 'I', 4: 'IV', 5: 'V', 9: 'IX', 10: 'X', 40: 'XL',\n",
    "#         50: 'L', 90: 'XC', 100: 'C', 400: 'CD', 500: 'D', 900: 'CM', 1000: 'M'\n",
    "#     }\n",
    "#     result = ''\n",
    "#     for value, numeral in sorted(roman_numerals.items(), key=lambda x: -x[0]):\n",
    "#         while arabic >= value:\n",
    "#             result += numeral\n",
    "#             arabic -= value\n",
    "#     return result\n",
    "\n",
    "# def correct_names(df: pd.DataFrame, col_pattern: str = 'nombre', split_pattern: str = ', ') -> pd.DataFrame:\n",
    "    \n",
    "#     col_names = [col for col in df if col_pattern in col.lower()]\n",
    "#     for col in col_names:\n",
    "#         # replace missing values\n",
    "#         df[col] = df[col].replace(np.nan, '')\n",
    "#         # remove accents\n",
    "#         df[col] = df[col].apply(remove_accents)\n",
    "#         # swap articles\n",
    "#         df[col] = df[col].apply(swap_words, split_pattern=split_pattern)\n",
    "#         # convert arabic numbers to roman numbers\n",
    "#         df[col] = df[col].apply(lambda x: re.sub(r'\\b\\d+\\b', arabic_to_roman, x))\n",
    "        \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b251c7-a5cf-425d-b964-afa417d07858",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1327761-7034-42ea-bfce-33231b1509fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where the data is stored\n",
    "PATH_DATASETS = Path('Z:/nahaUsers/casadje/datasets/')\n",
    "PATH_CEDEX = PATH_DATASETS / 'CEDEX' / 'processed' / 'reservoirs' / 'attributes' / 'GIS'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedbbed7-f697-4163-a6fe-9c4891924549",
   "metadata": {},
   "source": [
    "## Reservoir attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65d1118-811d-4320-ac63-8b40b56b1cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNCZI contains 3170 reservoirs and 18 attributes\n"
     ]
    }
   ],
   "source": [
    "# shapefile of reservoirs in the Spanish inventory\n",
    "reservoirs_SNCZI = gpd.read_file(PATH_CEDEX / 'egis_embalse_geoetrs89.shp')\n",
    "reservoirs_SNCZI['ID_EMBALSE'] = reservoirs_SNCZI['ID_EMBALSE'].astype(int)\n",
    "reservoirs_SNCZI.set_index('ID_EMBALSE', drop=True, inplace=True)\n",
    "reservoirs_SNCZI.sort_index(axis=0, inplace=True)\n",
    "reservoirs_SNCZI.to_crs(epsg=25830, inplace=True)\n",
    "\n",
    "print('SNCZI contains {0} reservoirs and {1} attributes'.format(*reservoirs_SNCZI.shape))\n",
    "# reservoirs_SNCZI.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b36724-2400-4186-8ad4-447e04912184",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Download reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af068b96-6f3b-4d04-9307-2ce7d0d80b79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a9951edbb24d8dbfbcbe19e0ecaf8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_reports_res = PATH_DATASETS / 'SNCZI' / 'reports' / 'reservoirs'\n",
    "path_reports_res.mkdir(parents=True, exist_ok=True)\n",
    "for ID in tqdm(reservoirs_SNCZI.index):\n",
    "\n",
    "    # output XML file\n",
    "    filename = f'{path_reports_res}/{ID:04}.xml'\n",
    "    if os.path.isfile(filename):\n",
    "        continue\n",
    "    \n",
    "    # extract data from URL\n",
    "    url = f'https://sig.mapama.gob.es/WebServices/clientews/snczi/Default.aspx?nombre=EGISPE_EMBALSE&claves=ID_EMBALSE&valores={ID}&op=ExpMultiple'\n",
    "    \n",
    "    with requests.get(url) as response:\n",
    "        lines = [line.decode('utf-8') for line in response.iter_lines()]\n",
    "    \n",
    "    # export XML file\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.writelines(line + '\\n' for line in lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12374fee-f997-4d23-8090-9f8545b25f05",
   "metadata": {},
   "source": [
    "### Read reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fddc52a-7777-472a-b0fa-ee41b164cc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5df5a80ffb47c2bec098a167a428a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load individal XML for each reservoir\n",
    "cedex_res = pd.DataFrame(dtype='object')\n",
    "for file in tqdm(list(path_reports_res.glob('*.xml'))):\n",
    "    ID = int(file.stem)\n",
    "    try:\n",
    "        cedex_res = pd.concat((cedex_res, reservoir_attributes(str(file), name=ID)), axis=1)\n",
    "    except:\n",
    "        print(f'File {file} could not be read')\n",
    "cedex_res = cedex_res.transpose()\n",
    "cedex_res.index.name = 'res_ID'\n",
    "\n",
    "# rename field 'inf_ID' (infrastructure ID)\n",
    "# this field is the connection between the reservoir and dam attributes\n",
    "# each reservoir references its main dam using the 'inf_ID' field\n",
    "cedex_res.rename(columns={'Código de infraestructura': 'inf_ID'}, inplace=True)\n",
    "cedex_res.inf_ID = cedex_res.inf_ID.astype('Int64')\n",
    "cedex_res.drop('Código del embalse', axis=1, inplace=True)\n",
    "\n",
    "# correct names\n",
    "cedex_res = correct_names(cedex_res, col_pattern='nombre', split_pattern= '. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03e2b04-5ebd-4b79-ab1d-abc1d3bc02c5",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f758efd-86a8-45f5-a6e9-0762d84d70b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns\n",
    "cols = cedex_res.columns.tolist()\n",
    "cols.remove('inf_ID')\n",
    "cols = ['inf_ID'] + cols\n",
    "cedex_res = cedex_res[cols]\n",
    "\n",
    "# export\n",
    "cedex_res.to_csv(path_reports_res / 'attributes_reservoirs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450121f7-8601-4ce4-b5ce-33c9f90a8984",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dam attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cbce758-a43d-4d76-ad8d-2b87badf5b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNCZI contains 3208 dams and 23 attributes\n"
     ]
    }
   ],
   "source": [
    "# shapefile of dams in the Spanish inventory\n",
    "dams_SNCZI = gpd.read_file(PATH_CEDEX / 'egis_presa_geoetrs89.shp')\n",
    "cols_int = ['ID_INFRAES', 'CODIGO']\n",
    "dams_SNCZI[cols_int] = dams_SNCZI[cols_int].astype(int)\n",
    "dams_SNCZI.set_index('ID_INFRAES', drop=True, inplace=True)\n",
    "dams_SNCZI.sort_index(inplace=True)\n",
    "dams_SNCZI.to_crs(epsg=25830, inplace=True)\n",
    "\n",
    "print('SNCZI contains {0} dams and {1} attributes'.format(*dams_SNCZI.shape))\n",
    "# dams_SNCZI.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b520994-ea55-4786-af67-a57b8a46d0d2",
   "metadata": {},
   "source": [
    "### Download reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd9833c9-2adf-42e8-99d3-1721cc8cab8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f1e33ddab554fbfb1206bfa08b5de8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_reports_dam = PATH_DATASETS / 'SNCZI' / 'reports' / 'dams'\n",
    "path_reports_dam.mkdir(parents=True, exist_ok=True)\n",
    "for id_infr in tqdm(dams_SNCZI.index):\n",
    "\n",
    "    # output XML file\n",
    "    code = dams_SNCZI.loc[id_infr, 'CODIGO']\n",
    "    filename = f'{path_reports_dam}/{code:07}.xml'\n",
    "    if os.path.isfile(filename):\n",
    "        continue\n",
    "    \n",
    "    # extract data from URL\n",
    "    url = f'https://sig.mapama.gob.es/WebServices/clientews/snczi/Default.aspx?nombre=EGISPE_PRESA&claves=ID_INFRAESTRUCTURA&valores={id_infr}&op=Exportar'\n",
    "    \n",
    "    with requests.get(url) as response:\n",
    "        lines = [line.decode('utf-8') for line in response.iter_lines()]\n",
    "    \n",
    "    # export XML file\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.writelines(line + '\\n' for line in lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d042f640-5c89-4cab-be5c-510dd0342e66",
   "metadata": {},
   "source": [
    "### Read reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b6af990-2206-4cb7-838b-1da4b976d796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad7572878b447da97ff8ee9f80fc345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3229 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Z:\\nahaUsers\\casadje\\datasets\\SNCZI\\reports\\dams\\1330033.xml could not be read\n",
      "File Z:\\nahaUsers\\casadje\\datasets\\SNCZI\\reports\\dams\\1390018.xml could not be read\n",
      "File Z:\\nahaUsers\\casadje\\datasets\\SNCZI\\reports\\dams\\2090035.xml could not be read\n",
      "File Z:\\nahaUsers\\casadje\\datasets\\SNCZI\\reports\\dams\\2240051.xml could not be read\n",
      "File Z:\\nahaUsers\\casadje\\datasets\\SNCZI\\reports\\dams\\2340021.xml could not be read\n",
      "File Z:\\nahaUsers\\casadje\\datasets\\SNCZI\\reports\\dams\\2340022.xml could not be read\n",
      "File Z:\\nahaUsers\\casadje\\datasets\\SNCZI\\reports\\dams\\2420011.xml could not be read\n",
      "File Z:\\nahaUsers\\casadje\\datasets\\SNCZI\\reports\\dams\\2490027.xml could not be read\n",
      "File Z:\\nahaUsers\\casadje\\datasets\\SNCZI\\reports\\dams\\4450005.xml could not be read\n",
      "File Z:\\nahaUsers\\casadje\\datasets\\SNCZI\\reports\\dams\\5140029.xml could not be read\n",
      "File Z:\\nahaUsers\\casadje\\datasets\\SNCZI\\reports\\dams\\5230010.xml could not be read\n",
      "File Z:\\nahaUsers\\casadje\\datasets\\SNCZI\\reports\\dams\\8460057.xml could not be read\n"
     ]
    }
   ],
   "source": [
    "# load individal XML for each dam\n",
    "cedex_dam = pd.DataFrame(dtype='object')\n",
    "for file in tqdm(list(path_reports_dam.glob('*.xml'))):\n",
    "    inf_ID = int(file.stem)\n",
    "    try:\n",
    "        cedex_dam = pd.concat((cedex_dam, dam_attributes(str(file), name=inf_ID)), axis=1)\n",
    "    except:\n",
    "        print(f'File {file} could not be read')\n",
    "cedex_dam = cedex_dam.transpose()\n",
    "cedex_dam.index.name = 'inf_ID'\n",
    "\n",
    "# correct names\n",
    "cedex_dam = correct_names(cedex_dam, col_pattern='nombre', split_pattern='. ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349d1fc8-6326-43e8-900a-9e8bffe44e6e",
   "metadata": {},
   "source": [
    "Some dams have more than one type of spillway, so the fields related to the spillway have several values separated by semicolon. Here I will identify these dams, separate the values and value representative of all the types of reservoir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea4e6269-3f4a-43c6-8ae0-ca4f54e1d4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regulation = []\n",
    "# for value in cedex_dam.Regulación.astype(str):\n",
    "#     regulation += [x.strip() for x in value.split(';')]\n",
    "# set(regulation)\n",
    "\n",
    "map_regulation = {'': np.nan,\n",
    "                  'Compuerta Taintor': 1,\n",
    "                  'Compuerta de sector': 1,\n",
    "                  'Compuerta de segmento': 1,\n",
    "                  'Compuerta vertical': 1,\n",
    "                  'Compuertas': 1,\n",
    "                  'Compuertas clapetas': 1,\n",
    "                  'No. labio fijo': 0,\n",
    "                 }\n",
    "\n",
    "# correct values in dams with more than one type of spillway\n",
    "cols = ['Número total de aliviaderos en la presa', 'Regulación', 'Capacidad a NAE (m3/s)']\n",
    "idx = cedex_dam[cols[0]].astype(str).str.contains(';')\n",
    "for ID, row in cedex_dam.loc[idx, cols].iterrows():\n",
    "    \n",
    "    # split spillway attributes\n",
    "    row = row.str.replace('---', '')\n",
    "    row = row.str.split(';')\n",
    "    \n",
    "    # correct number and capacity of the spillways\n",
    "    number = np.array([int(n) for n in row.iloc[0]])\n",
    "    capacity = np.array([np.nan if n in [' ', ''] else float(n) for n in row.iloc[2]])\n",
    "    cedex_dam.loc[ID, cols[0]] = np.nansum(number)\n",
    "    cedex_dam.loc[ID, cols[2]] = np.nansum(number * capacity)\n",
    "    \n",
    "    # correct regulation\n",
    "    cedex_dam.loc[ID, cols[1]] = np.nanmax([map_regulation[x.strip()] for x in row.iloc[1]])\n",
    "\n",
    "# correct regulation\n",
    "cedex_dam.replace(map_regulation, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a834691e-c333-40d5-91c7-c06167694215",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "724b3a7f-f36d-4147-b297-5546bf2478c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "cedex_dam.to_csv(path_reports_dam / 'attributes_dams.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
