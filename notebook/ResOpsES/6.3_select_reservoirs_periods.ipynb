{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "631e1812-9c8c-4f8e-ad1b-41578130117b",
   "metadata": {},
   "source": [
    "# Select reservoirs and study period\n",
    "***\n",
    "\n",
    "**Author:** Chus Casado Rodríguez<br>\n",
    "**Date:** 02-08-2024<br>\n",
    "\n",
    "**Introduction:**<br>\n",
    "This notebook reads all the attributes and time series in the dataset and selects the reservoirs appropriate for testing the different reservoir routines. Several conditions need to be met for a reservoir to be selected:\n",
    "\n",
    "1. It must contain observed time series of the variables `inflow`, `storage` and `outflow`. <font color='red'>NOT IN RESOPSES!!!</font>\n",
    "2. The longest period without gaps in those three time series needs to be longer than 8 years.\n",
    "3. The bias between the observed inflow and outflow timeseries needs to be between 0.7 and 1.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1940f88-25de-47e5-88ec-2ba55e079da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pickle\n",
    "\n",
    "from lisfloodreservoirs import read_attributes, read_timeseries\n",
    "from lisfloodreservoirs.utils import DatasetConfig\n",
    "from lisfloodreservoirs.utils.timeseries import define_period #,create_demand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d503d3-dd70-4b64-b148-ff7f86e0b789",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c696d1-6723-4c46-b84b-94e978d70e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected reservoirs and periods will be saved in:\n",
      "\tZ:\\nahaUsers\\casadje\\datasets\\reservoirs\\ResOpsES\\v3.0\\selection\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = DatasetConfig('config_dataset.yml')\n",
    "\n",
    "PATH_OUT = cfg.PATH_RESOPS / cfg.VERSION / 'selection'\n",
    "PATH_OUT.mkdir(parents=True, exist_ok=True)\n",
    "print(f'Selected reservoirs and periods will be saved in:\\n\\t{PATH_OUT}\\n')\n",
    "\n",
    "inflow_var = 'inflow_efas5_bc'\n",
    "variables = [inflow_var, 'storage', 'outflow']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da057a63-1f1b-412b-9188-3b984c86a637",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ab25ee-79ef-423a-aaf5-eb3c10fc6d6a",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0f3767b-5d97-442c-ac6c-d52ebd123d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206 reservoirs in the attribute tables\n",
      "206 reservoirs comply with the minimum catchment area: 25 km²\n",
      "206 reservoirs comply with the minimum storage capacity: 10 hm3\n",
      "177 reservoirs comply with the minimum degree of regulation: 0.08\n",
      "144 reservoirs comply with the minimum degree of disruptivity: 0.06 m\n"
     ]
    }
   ],
   "source": [
    "# import all tables of attributes\n",
    "attributes = pd.read_csv(cfg.PATH_ATTRS / 'combined.csv', index_col='GRAND_ID') #read_attributes(PATH_DATA / 'attributes', reservoirs=None)\n",
    "print(f'{attributes.shape[0]} reservoirs in the attribute tables')\n",
    "\n",
    "# # keep only reservoirs with all observed variables\n",
    "# mask = pd.concat([attributes[var.upper()] == 1 for var in variables], axis=1).all(axis=1)\n",
    "# attributes = attributes[mask]\n",
    "# attributes.sort_index(axis=0, inplace=True)\n",
    "# print('{0} reservoirs include observed time series for all variables: {1}'.format(attributes.shape[0],\n",
    "#                                                                                 ', '.join(variables)))\n",
    "\n",
    "# keep reservoirs that comply with the catchment area and total storage conditions\n",
    "if cfg.MIN_AREA is not None:\n",
    "    mask_area = attributes.CATCH_SKM >= cfg.MIN_AREA\n",
    "    attributes = attributes[mask_area]\n",
    "    print('{0} reservoirs comply with the minimum catchment area: {1} km²'.format(attributes.shape[0],\n",
    "                                                                                  cfg.MIN_AREA))\n",
    "if cfg.MIN_VOL is not None:\n",
    "    mask_volume = attributes.CAP_MCM >= cfg.MIN_VOL\n",
    "    attributes = attributes[mask_volume]\n",
    "    print('{0} reservoirs comply with the minimum storage capacity: {1} hm3'.format(attributes.shape[0],\n",
    "                                                                                    cfg.MIN_VOL))\n",
    "\n",
    "if cfg.MIN_DOR is not None:\n",
    "    mask_dor = attributes.DOR >= cfg.MIN_DOR\n",
    "    attributes = attributes[mask_dor]\n",
    "    print('{0} reservoirs comply with the minimum degree of regulation: {1}'.format(attributes.shape[0],\n",
    "                                                                                    cfg.MIN_DOR))\n",
    "\n",
    "if cfg.MIN_DOD is not None:\n",
    "    mask_dod = attributes.DOD_M >= cfg.MIN_DOD\n",
    "    attributes = attributes[mask_dod]\n",
    "    print('{0} reservoirs comply with the minimum degree of disruptivity: {1} m'.format(attributes.shape[0],\n",
    "                                                                                        cfg.MIN_DOD))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a07a7af-b676-4a54-b2f9-d7f62acf74ae",
   "metadata": {},
   "source": [
    "#### Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f3ce9d6-350a-41ad-8345-1097aed7f18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 reservoirs with timeseries\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read time series\n",
    "timeseries = read_timeseries(cfg.PATH_TS / 'csv',\n",
    "                             attributes.index)\n",
    "print(f'{len(timeseries)} reservoirs with timeseries\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d691a230-50d0-42e8-b1c9-a3fb6bef772f",
   "metadata": {},
   "source": [
    "## Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f53d31c9-1d85-47d9-8dfa-fadefe9ff162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f470d73328284264be6bd14fd4d7d8b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "select reservoirs:   0%|          | 0/144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2656 discarded for lack of records:\t1915 days\n",
      "2661 discarded for lack of records:\t839 days\n",
      "2664 discarded for lack of records:\t2098 days\n",
      "2667 discarded for lack of records:\t2098 days\n",
      "2677 discarded for lack of records:\t2901 days\n",
      "2699 discarded for excesive bias:\t0.64\n",
      "2812 discarded for excesive bias:\t1.50\n",
      "2821 discarded for lack of records:\t1460 days\n",
      "2824 discarded for excesive bias:\t0.66\n",
      "2833 discarded for excesive bias:\t0.61\n",
      "2839 discarded for excesive bias:\t0.69\n",
      "2855 discarded for excesive bias:\t1.30\n",
      "2866 discarded for excesive bias:\t0.62\n",
      "2878 discarded for excesive bias:\t0.69\n",
      "2880 discarded for excesive bias:\t0.68\n",
      "2895 discarded for lack of records:\t2098 days\n",
      "3479 discarded for lack of records:\t2098 days\n",
      "3485 discarded for lack of records:\t2561 days\n",
      "3492 discarded for lack of records:\t2098 days\n",
      "3504 discarded for lack of records:\t2545 days\n",
      "6829 discarded for lack of records:\t2190 days\n",
      "7052 discarded for excesive bias:\t0.27\n",
      "7056 discarded for lack of records:\t2678 days\n",
      "\n",
      "121 reservoirs selected\n"
     ]
    }
   ],
   "source": [
    "bias = {}\n",
    "periods = {}\n",
    "for grand_id, ts in tqdm(timeseries.items(), desc='select reservoirs', total=len(timeseries)):\n",
    "    \n",
    "    # select study period\n",
    "    start, end = define_period(ts[variables])\n",
    "    if np.isnan(start) or np.isnan(end):\n",
    "        print(f'{grand_id:>4} discarded for lack of records')\n",
    "        continue\n",
    "    duration = (end - start) / np.timedelta64(1, 'D')\n",
    "    if duration >= cfg.MIN_YEARS * 365:\n",
    "        ts = ts.loc[start:end]\n",
    "    else:\n",
    "        print(f'{grand_id:>4} discarded for lack of records:\\t{duration:.0f} days')\n",
    "        continue\n",
    "        \n",
    "    # bias between inflow and outflow\n",
    "    bias[grand_id] = ts.outflow.mean() / ts[inflow_var].mean()\n",
    "    if (1 - cfg.TOL_BIAS) <= bias[grand_id] <= (1 + cfg.TOL_BIAS):\n",
    "        # save periods\n",
    "        periods[grand_id] = {\n",
    "            'start': start,\n",
    "            'end': end\n",
    "        }\n",
    "    else:\n",
    "        print(f'{grand_id:>4} discarded for excesive bias:\\t{bias[grand_id]:.2f}')\n",
    "    \n",
    "print(f'\\n{len(periods)} reservoirs selected')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219fb1c-1968-4ac0-a1de-ceb5f8ea3b7d",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23409f11-7fd9-47da-abe7-c545f1300f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export list of selected reservoirs\n",
    "with open(PATH_OUT / 'reservoirs.txt', 'w') as f:\n",
    "    for grand_id in periods.keys():\n",
    "        f.write(f'{grand_id}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2333bb16-7bbe-4d9c-a9a2-dfc72b62f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export selected study period\n",
    "with open(PATH_OUT / 'periods.pkl', 'wb') as f:\n",
    "    pickle.dump(periods, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
