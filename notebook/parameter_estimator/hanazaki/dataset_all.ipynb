{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa329f0d-f937-4df3-8457-aa446dcd17be",
   "metadata": {},
   "source": [
    "# Parameter estimation: all\n",
    "***\n",
    "\n",
    "**Date**: 25-11-2024<br>\n",
    "\n",
    "* [x] Add filter by degree of regulation\n",
    "* [ ] Analyse parameter sensitivity in the model\n",
    "* [x] Simulate the model with the estimated parameters\n",
    "* [ ] MLP in `scikitlearn`\n",
    "* [ ] Increase range in the calibration of $\\delta$\n",
    "* [ ] Use `XGBoost` instead of `scikit-learn` to be able to use the GPU\n",
    "* [ ] Give more attention to the use attributes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ecdbdb9-280d-4849-a402-44beedef3e57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import geopandas as gpd\n",
    "import xarray as xr\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "# from shapely.geometry import Point\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ffc9b9b-d897-4b0e-a909-81af59346f62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'root_mean_squared_error' from 'sklearn.metrics' (C:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\sklearn\\metrics\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m root_mean_squared_error\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# from sklearn.linear_model import LinearRegression\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'root_mean_squared_error' from 'sklearn.metrics' (C:\\DEV\\Anaconda3\\envs\\xr\\lib\\site-packages\\sklearn\\metrics\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e7a488-ecfb-4f28-a7eb-1be0ae771dae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lisfloodreservoirs import read_attributes#, read_timeseries\n",
    "from lisfloodreservoirs.models import get_model\n",
    "from lisfloodreservoirs.utils.metrics import compute_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef1205c-2ff9-4cb6-93d0-4095ae4b85ac",
   "metadata": {},
   "source": [
    "## 1 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0399eb-c107-49c2-b64b-35ad15671911",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_version = {\n",
    "    'US': 'v2.0',\n",
    "    'ES': 'v3.0',\n",
    "    'MX': 'v1.0'\n",
    "}\n",
    "\n",
    "reservoir_model = 'hanazaki_2pars'\n",
    "\n",
    "data_dir = Path('Z:/nahaUsers/casadje/datasets/reservoirs/')\n",
    "results_dir = Path('./results/all')\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# paths_runs = {\n",
    "#     'default': data_dir / 'results' / reservoir_model / 'default',\n",
    "#     'storage': data_dir / 'results' / reservoir_model / 'calibration' / 'storage',\n",
    "#     'outflow': data_dir / 'results' / reservoir_model / 'calibration' / 'outflow',\n",
    "#     'bivariate': data_dir / 'results' / reservoir_model / 'calibration' / 'bivariate'\n",
    "# }\n",
    "\n",
    "par_range ={\n",
    "    'alpha': (0.2, 0.99),\n",
    "    'beta': (0.001, 0.999), \n",
    "    'gamma': (0.001, 0.999),\n",
    "    'delta': (0.1, 0.5),\n",
    "    'epsilon': (0.001, 0.999),\n",
    "}\n",
    "\n",
    "metric = 'KGE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ee84b5-c48b-4aec-aa7e-f3bb912ec55f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336b53c4-dfe3-49c5-ab1a-77acff736804",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d4424f-0985-4405-a06c-e723beae6813",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rename_attrs = {\n",
    "    'use_elec': 'hydropower',\n",
    "    'use_fcon': 'flood',\n",
    "    'use_fish': 'fish',\n",
    "    'use_irri': 'irrigation',\n",
    "    'use_live': 'livestock',\n",
    "    'use_navi': 'navigation',\n",
    "    'use_othr': 'other_use',\n",
    "    'use_pcon': 'pollution',\n",
    "    'use_recr': 'recreation',\n",
    "    'use_supp': 'supply',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4953da7-0fcd-4e2d-baa5-d3e064a9ed54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attributes = pd.DataFrame(dtype=float)\n",
    "for country, version in data_version.items():\n",
    "\n",
    "    # load attributes\n",
    "    path = data_dir / f'ResOps{country}' / version\n",
    "    attrs = read_attributes(\n",
    "        path=path / 'attributes',\n",
    "        reservoirs=pd.read_csv(path / 'selection' / 'reservoirs.txt', header=None).squeeze().tolist()\n",
    "    )\n",
    "    attrs.columns = attrs.columns.str.lower()\n",
    "    attrs.rename(columns=rename_attrs, inplace=True, errors='ignore')\n",
    "    attributes = pd.concat((attributes, attrs), axis=0)\n",
    "    \n",
    "    # # convert into geopandas\n",
    "    # attributes = gpd.GeoDataFrame(\n",
    "    #     attributes,\n",
    "    #     geometry=[Point(xy) for xy in zip(attributes['lon'], attributes['lat'])],\n",
    "    #     crs='epsg:4326'\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77d47d2-deb8-4b60-81a8-543b0bac349e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30e1002-54c8-49cf-95e4-4f1d2b9e665d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='face', facecolor='tan'), alpha=.5, zorder=0)\n",
    "sct = ax.scatter(\n",
    "    attributes.lon,\n",
    "    attributes.lat,\n",
    "    s=attributes.cap_mcm**.66,\n",
    "    c=np.log10(attributes.dor_pc),\n",
    "    cmap='viridis',\n",
    "    edgecolor='w',\n",
    "    lw=.75)\n",
    "cbar = plt.colorbar(sct, orientation='horizontal', pad=.05, shrink=.5)\n",
    "cbar.set_label('DOR (%)')\n",
    "xticks = [2, 3, 4]\n",
    "cbar.set_ticks(xticks)\n",
    "cbar.set_ticklabels(np.power(10, xticks))\n",
    "ax.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d532570d-df14-44fe-86b3-b943604275a2",
   "metadata": {},
   "source": [
    "### Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fb5e2b-59ec-4807-9f57-18f938d75e4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read periods\n",
    "with open(data_dir / version / 'selection' / 'periods.pkl', 'rb') as file:\n",
    "    periods = pickle.load(file)\n",
    "\n",
    "# read time series\n",
    "timeseries = {}\n",
    "for file in (data_dir / version / 'time_series').glob('*.nc'):\n",
    "    ID = file.stem\n",
    "    if ID in periods:\n",
    "        ds = xr.open_dataset(file)[['storage', 'inflow', 'outflow']]\n",
    "        start, end = [periods[ID][f'{x}_dates'][0] for x in ['start', 'end']]\n",
    "        df = ds.sel(date=slice(start, end)).to_pandas()\n",
    "        df.storage *= 1e6\n",
    "        timeseries[int(ID)] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e7fdd0-58a6-43cf-96f9-33dbc3053102",
   "metadata": {},
   "source": [
    "### Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51193ae-25c2-4788-a745-cef786b71ac6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for run, path in paths_runs.items():\n",
    "    # optimal parameters\n",
    "    parameters = pd.DataFrame(dtype=float)\n",
    "    if run == 'default':\n",
    "        # default reservoir limits\n",
    "        limits_def = pd.DataFrame(dtype=float)\n",
    "        for file in path.glob('*parameters.yml'):\n",
    "            # reservoir ID\n",
    "            ID = int(file.stem.split('_')[0])\n",
    "            # extract alpha\n",
    "            with open(file, 'r') as f:\n",
    "                lims = yaml.safe_load(f)\n",
    "            limits_def = pd.concat((limits_def, pd.DataFrame({ID: lims}).transpose()), axis=0)\n",
    "            parameters.loc[ID, 'alpha'] = lims['Vf'] / lims['Vtot']\n",
    "            if reservoir_model.endswith('5pars'):\n",
    "                parameters.loc[ID, 'beta'] = (lims['Vtot'] - lims['Ve']) / (lims['Vtot'] - lims['Vf'])\n",
    "                parameters.loc[ID, 'gamma'] = lims['Vmin'] / lims['Vf'] \n",
    "                parameters.loc[ID, 'epsilon'] = lims['Qn'] / lims['Qf']\n",
    "        parameters['delta'] = 0.30\n",
    "    else:\n",
    "        for file in path.glob('*samples.csv'):\n",
    "            # reservoir ID\n",
    "            ID = int(file.stem.split('_')[0])\n",
    "            # extract best sample from the calibration\n",
    "            samples = pd.read_csv(file)\n",
    "            mask_cols = samples.columns.str.startswith('par')\n",
    "            parvalues = samples.loc[[samples.like1.idxmin()], mask_cols]\n",
    "            parvalues.index = [ID]\n",
    "            parvalues.index.name = 'ID'\n",
    "            parvalues.rename(columns={col: col[3:] for col in parvalues.columns if col.startswith('par')}, inplace=True)\n",
    "            parameters = pd.concat((parameters, parvalues), axis=0)\n",
    "    parameters.index.name = 'ID'\n",
    "    \n",
    "    # performance\n",
    "    performance = pd.DataFrame(dtype=float)\n",
    "    for file in path.glob('*performance.csv'):\n",
    "        # reservoir ID\n",
    "        ID = int(file.stem.split('_')[0])\n",
    "        # extract best sample from the calibration\n",
    "        perf = pd.read_csv(file, index_col='metric')\n",
    "        perf = perf.loc[[metric], ['storage', 'outflow']]\n",
    "        perf.index = [ID]\n",
    "        perf.index.name = 'ID'\n",
    "        perf.columns = [f'{metric}_{col}' for col in perf.columns]\n",
    "        performance = pd.concat((performance, perf), axis=0)\n",
    "\n",
    "    # concat all results\n",
    "    results.append(xr.Dataset(pd.concat((parameters, performance), axis=1)).expand_dims(dim={'run': [run]}))\n",
    "\n",
    "# merge in a single Dataset\n",
    "results = xr.merge(results)\n",
    "results = results.reindex(run=['default', 'storage', 'outflow', 'bivariate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4e6f7a-b57b-47d4-9781-fc427a4813e0",
   "metadata": {},
   "source": [
    "## 3 Analyse runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e47fb7-2974-433f-aac3-f8a821f6b567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_analysis = paths_runs['default'].parent / 'plots'\n",
    "path_analysis.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f88326-497f-4577-92b8-748aa44ddc3c",
   "metadata": {},
   "source": [
    "### Correlation & distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b72d75-8c8a-4862-958d-acde3aae0d08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for par, da in results.items():\n",
    "    pairplot = sns.pairplot(da.to_pandas().transpose(), corner=True)\n",
    "    pairplot.fig.suptitle(' '.join(par.split('_')))\n",
    "    if par.startswith('KGE'):\n",
    "        vlim = (-1.02, 1.02)\n",
    "    else:\n",
    "        vlim = [v + e * .02 for v, e in zip(par_range[par], [-1, 1])]\n",
    "    axes = pairplot.axes\n",
    "    for i in range(1, axes.shape[0]):\n",
    "        for j in range(0, axes.shape[1]):\n",
    "            if j >= i:\n",
    "                continue\n",
    "            axes[i,j].plot(vlim, vlim, lw=.5, c='k', zorder=0)\n",
    "    pairplot.set(\n",
    "        xlim=vlim,\n",
    "        ylim=vlim,\n",
    "    )\n",
    "    plt.savefig(path_analysis / f'{par}_pairplot.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3fbee7-436e-4c61-bfa7-0d0be98a38a8",
   "metadata": {},
   "source": [
    "### Geographical distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2cc4ca-c397-4a6d-8905-b78809b4556d",
   "metadata": {},
   "source": [
    "#### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa5c140-0e74-4ee1-a2c7-c7ef7a537891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for run in results.run.data: \n",
    "    attributes.drop(['alpha', 'delta', 'KGE_storage', 'KGE_outflow'], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "    df = results.sel(run=run).to_pandas().drop('run', axis=1)\n",
    "    df.index.name = 'GRAND_ID'\n",
    "    attributes = pd.concat((attributes, df), axis=1)\n",
    "\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=(8, 2.5), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "    if run == 'default':\n",
    "        fig.suptitle(run)\n",
    "    else:\n",
    "        fig.suptitle(f'calibration {run}')\n",
    "    for ax, var in zip(axes, ['storage', 'outflow']):\n",
    "        ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='face', facecolor='tan'), alpha=.5, zorder=0)\n",
    "        sct = ax.scatter(\n",
    "            attributes.lon,\n",
    "            attributes.lat,\n",
    "            s=attributes.cap_mcm**.5,\n",
    "            c=attributes[f'KGE_{var}'],\n",
    "            edgecolor='w',\n",
    "            lw=.75,\n",
    "            cmap='coolwarm_r',\n",
    "            norm=mcolors.Normalize(vmin=-1, vmax=1)\n",
    "        )\n",
    "        cbar = plt.colorbar(sct, orientation='horizontal', pad=.05, shrink=.5)#, ax=ax)\n",
    "        cbar.set_label(f'KGE {var}')\n",
    "        ax.axis('off');\n",
    "    plt.savefig(path_analysis / f'performance_maps_{run}.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f37224-78d2-4992-9156-cd9df2f5307d",
   "metadata": {},
   "source": [
    "#### Parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2af511-fccd-4445-856d-05b6b41918b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for run in results.run.data: \n",
    "    attributes.drop(['alpha', 'delta', 'KGE_storage', 'KGE_outflow'], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "    df = results.sel(run=run).to_pandas().drop('run', axis=1)\n",
    "    df.index.name = 'GRAND_ID'\n",
    "    attributes = pd.concat((attributes, df), axis=1)\n",
    "\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=(8, 2.5), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "    fig.suptitle(run)\n",
    "    for ax, par in zip(axes, ['alpha', 'delta']):\n",
    "        ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='face', facecolor='tan'), alpha=.5, zorder=0)\n",
    "        sct = ax.scatter(\n",
    "            attributes.lon,\n",
    "            attributes.lat,\n",
    "            s=np.sqrt(attributes.cap_mcm),\n",
    "            c=attributes[par],\n",
    "            edgecolor='w',\n",
    "            lw=.75,\n",
    "            cmap='viridis',\n",
    "            norm=mcolors.Normalize(*par_range[par])\n",
    "        )\n",
    "        cbar = plt.colorbar(sct, orientation='horizontal', pad=.05, shrink=.5)#, ax=ax)\n",
    "        cbar.set_label(par)\n",
    "        ax.axis('off');\n",
    "    plt.savefig(path_analysis / f'parameter_maps_{run}.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04f5a03-3c96-4cd2-a9e5-89c3bf12648a",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4487a457-4706-47e6-bc46-db650a9a6a53",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e58d9e-209c-430d-9f8c-acadc62feb6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thr = 0.25\n",
    "mask_storage = attributes.KGE_storage >= thr\n",
    "mask_outflow = attributes.KGE_outflow >= thr\n",
    "mask_dor = (attributes.dor_pc >= 8)\n",
    "mask_storage.sum(), mask_outflow.sum(), mask_dor.sum(), (mask_storage & mask_outflow & mask_dor).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296e915d-a817-4e5e-9c4a-02b1e9b98597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = attributes[mask_storage & mask_outflow].copy()\n",
    "features = ['temp_mean', 'pet_mean', 'precip_mean', 'snow_mean', 'aridity', 'frac_snow',\n",
    "           'moisture_index', 'seasonality', 'high_precip_freq', 'high_precip_dur', 'low_precip_freq', 'low_precip_dur',\n",
    "           'area_skm', 'cap_mcm', 'catch_skm', 'dam_hgt_m', 'dam_len_m', 'depth_m', 'dis_avg_ls', 'dor_pc', 'elev_masl',\n",
    "            'hydropower', 'flood', 'fish', 'irrigation', 'livestock', 'navigation', 'other_use', 'pollution', 'recreation','supply',\n",
    "            #'use_elec', 'use_fcon', 'use_fish', 'use_irri', 'use_live', 'use_navi', 'use_othr', 'use_pcon', 'use_recr', 'use_supp',\n",
    "           'lat', 'lon',]\n",
    "targets  = ['alpha', 'delta']\n",
    "\n",
    "X, y = dataset[features], dataset[targets]\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e5fa04-e1c3-4dea-849d-07f7a6dbdf92",
   "metadata": {},
   "source": [
    "### Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0fc4b9-0da3-4d81-ade3-dc9af514f35f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_pred = np.median(y_train, axis=0) * len(y_test)\n",
    "# print('RMSE = {0:.3f}'.format(root_mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd5bd95-9532-49c5-9bf3-f6253099d2a9",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2b278e-6de8-43bb-9b1c-36559dd8e2ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lr = LinearRegression().fit(X_train, y_train)\n",
    "# y_pred = lr.predict(X_test)\n",
    "# print('RMSE = {0:.3f}'.format(root_mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719339d1-9308-4547-8af9-8a6e3d4665b5",
   "metadata": {},
   "source": [
    "### Random forest univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead46a3-47f9-40ca-ad32-0b36d1f24daa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_rf1 = results_dir / 'random_forest_1'\n",
    "path_rf1.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7febbe52-0ea9-4774-a2bf-4ff024f20cbe",
   "metadata": {},
   "source": [
    "#### Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe5eded-bf7c-4304-992d-4ec8503790ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10, 100, 1000],\n",
    "    'max_depth': [None, 1, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 6]\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    # verbose=2\n",
    ")\n",
    "rf1 = {}\n",
    "for par in y_train.columns:\n",
    "    grid_search.fit(X_train, y_train[par])\n",
    "    model = grid_search.best_estimator_\n",
    "    print(grid_search.best_params_)\n",
    "    y_pred = pd.Series(model.predict(X_test), index=X_test.index, name=par)\n",
    "    rmse = root_mean_squared_error(y_test[par], y_pred)\n",
    "    print(f'RMSE ({par}) = {rmse:.3f}')\n",
    "    rf1[par] = model\n",
    "    # export\n",
    "    with open(path_rf1 / f'random_forest_{par}.pkl', 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "y_rf1 = pd.DataFrame({par: pd.Series(model.predict(X), index=X.index) for par, model in rf1.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ce29c0-d314-40cf-b9d7-1604fb3c43f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ncols = len(targets)\n",
    "fig, axes = plt.subplots(ncols=ncols, figsize=(3 * ncols, 3))\n",
    "for ax, par in zip(axes, targets):\n",
    "    ax.scatter(\n",
    "        y_train[par],\n",
    "        y_rf1.loc[X_train.index, par],\n",
    "        c='C0',\n",
    "        s=16,\n",
    "        alpha=.5,\n",
    "        label='train'\n",
    "    )\n",
    "    ax.scatter(\n",
    "        y_test[par],\n",
    "        y_rf1.loc[X_test.index, par],\n",
    "        c='C1',\n",
    "        s=16,\n",
    "        alpha=.5,\n",
    "        label='test'\n",
    "    )\n",
    "    vlim = [x + e for x, e in zip(par_range[par], [-.02, .02])]\n",
    "    ax.plot(vlim, vlim, lw=.5, c='k', zorder=0)\n",
    "    ax.set(\n",
    "        xlim=vlim,\n",
    "        xlabel='calibration',\n",
    "        ylim=vlim,\n",
    "        title=par\n",
    "    )\n",
    "    if ax == axes[0]:\n",
    "        ax.set_ylabel('random forest')\n",
    "        \n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, frameon=False, bbox_to_anchor=[.95, .3, .1, .3]);\n",
    "\n",
    "plt.savefig(path_rf1 / 'parameter_scatter.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321c43c9-1f5d-4f51-b86d-54525ae54a4a",
   "metadata": {},
   "source": [
    "The correlation is almost inexistent!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db7f408-5bf4-4937-a2b7-3cc2dfdeeb17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importance_rf1 = pd.DataFrame({par: pd.Series(model.feature_importances_, index=model.feature_names_in_) for par, model in rf1.items()})\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(8, 6), sharex=True)\n",
    "for ax, par in zip(axes, targets):\n",
    "    imp = importance_rf1[par].sort_values(ascending=False)\n",
    "    ax.barh(imp.index, imp)\n",
    "    ax.set(\n",
    "        xlabel='importance',\n",
    "        title=par\n",
    "    )\n",
    "    ax.tick_params(axis='y', length=0)\n",
    "    ax.spines[['left', 'top', 'right']].set_visible(False)\n",
    "    \n",
    "plt.savefig(path_rf1 / 'importance_bar.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1e63a7-c82e-4aa2-b981-907150c882d8",
   "metadata": {},
   "source": [
    "#### Simulate reservoirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebffef5f-ebd9-40db-aa42-b5b5bc02e4f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adapt limits based on the estimation\n",
    "limits_rf1 = limits_def.loc[X.index].copy()\n",
    "limits_rf1.Vf = limits_rf1.Vtot * y_rf1['alpha']\n",
    "limits_rf1.Vmin = limits_rf1.Vf * .5\n",
    "limits_rf1.Ve = limits_rf1.Vtot - .2 * (limits_rf1.Vtot - limits_rf1.Vf)\n",
    "limits_rf1.Qf *= y_rf1['delta'] / 0.3\n",
    "\n",
    "performance_rf1 = pd.DataFrame(columns=['storage', 'outflow'])\n",
    "for ID, row in limits_rf1.iterrows():\n",
    "    \n",
    "    # declare reservoir\n",
    "    attrs = {attr: row[attr] for attr in ['Vmin', 'Vf', 'Ve', 'Vtot', 'Qn', 'Qf']}\n",
    "    attrs.update({'A': attributes.loc[ID, 'catch_skm'] * 1e6})\n",
    "    res = get_model('Hanazaki', **attrs)\n",
    "\n",
    "    # simulate\n",
    "    obs = timeseries[ID]\n",
    "    sim = res.simulate(\n",
    "        inflow=obs.inflow,\n",
    "        Vo=obs.storage.iloc[0],\n",
    "    )\n",
    "\n",
    "    # analyse performance\n",
    "    perf = compute_performance(timeseries[ID], sim)\n",
    "    performance_rf1.loc[ID, :] = perf.loc[metric, performance_rf1.columns].values\n",
    "\n",
    "# performance_rf1.index.name = 'ID'\n",
    "performance_rf1.columns = [f'{metric}_{var}' for var in performance_rf1.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1963ab5-65cc-40bc-892c-5da324d59e11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add to the calibration results\n",
    "results_rf1 = pd.concat((y_rf1, performance_rf1), axis=1)\n",
    "results_rf1.index.name = 'ID'\n",
    "results = xr.concat((results, xr.Dataset({col: results_rf1[col] for col in results_rf1.columns}).expand_dims({'run': ['random_forest_1']})), dim='run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6705a-964c-4492-aed6-420131b6abea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# performance of the best calibration\n",
    "run = 'bivariate'\n",
    "performance_cal = results.sel(ID=X.index, run=run)[['KGE_storage', 'KGE_outflow']].to_pandas().drop('run', axis=1)\n",
    "# performance_cal.rename(columns={col: col.split('_')[-1] for col in performance_cal.columns}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5c7897-09d0-4fe0-aff4-5398a9714e9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# performance of the default parameters\n",
    "run = 'default'\n",
    "performance_def = results.sel(ID=X.index, run=run)[['KGE_storage', 'KGE_outflow']].to_pandas().drop('run', axis=1)\n",
    "# performance_def.rename(columns={col: col.split('_')[-1] for col in performance_def.columns}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0bb21f-26db-4999-a40c-0bfa34169e3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(6, 6), sharex=True, sharey=True)\n",
    "vlim = (-1.02, 1.02)\n",
    "ax[0, 0].set(\n",
    "    xlim=vlim,\n",
    "    ylim=vlim,\n",
    ")\n",
    "for j, var in enumerate(['storage', 'outflow']):\n",
    "    col = f'{metric}_{var}'\n",
    "    ax[0, j].scatter(performance_rf1.loc[X_train.index, col], performance_def.loc[X_train.index, col], c='C0', s=16, alpha=.5, label='train')\n",
    "    ax[0, j].scatter(performance_rf1.loc[X_test.index, col], performance_def.loc[X_test.index, col], c='C1', s=16, alpha=.5, label='test')\n",
    "    ax[0, j].plot(vlim, vlim, c='k', lw=.5, zorder=0)\n",
    "    ax[0, j].set_title(var)\n",
    "    \n",
    "    ax[1, j].scatter(performance_rf1.loc[X_train.index, col], performance_cal.loc[X_train.index, col], c='C0', s=16, alpha=.5, label='train')\n",
    "    ax[1, j].scatter(performance_rf1.loc[X_test.index, col], performance_cal.loc[X_test.index, col], c='C1', s=16, alpha=.5, label='test')\n",
    "    ax[1, j].plot(vlim, vlim, c='k', lw=.5, zorder=0)\n",
    "    ax[1, j].set_xlabel('KGE (-)\\nrandom forest')\n",
    "    \n",
    "    if j == 0:\n",
    "        ax[0,j].set_ylabel('default\\nKGE (-)')\n",
    "        ax[1,j].set_ylabel('calibration\\nKGE (-)')\n",
    "        \n",
    "handles, labels = ax[0, 0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, frameon=False, bbox_to_anchor=[.95, .25, .1, .3]);\n",
    "\n",
    "plt.savefig(path_rf1 / 'performance_scatter.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb4667e-255f-4d2a-810e-0afdea209d8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(8, 2.5), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "fig.suptitle('random forest 1')\n",
    "for ax, var in zip(axes, ['storage', 'outflow']):\n",
    "    col = f'{metric}_{var}'\n",
    "    ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='face', facecolor='tan'), alpha=.5, zorder=0)\n",
    "    sct = ax.scatter(\n",
    "        attributes.loc[y.index, 'lon'],\n",
    "        attributes.loc[y.index, 'lat'],\n",
    "        s=np.sqrt(attributes.loc[y.index, 'cap_mcm']),\n",
    "        c=performance_rf1[col],\n",
    "        edgecolor='w',\n",
    "        lw=.75,\n",
    "        cmap='coolwarm_r',\n",
    "        norm=mcolors.Normalize(vmin=-1, vmax=1)\n",
    "    )\n",
    "    cbar = plt.colorbar(sct, orientation='horizontal', pad=.05, shrink=.5)#, ax=ax)\n",
    "    cbar.set_label(f'{metric} {var}')\n",
    "    ax.axis('off');\n",
    "plt.savefig(path_rf1 / 'performance_maps.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8a95c5-22e5-42ee-a458-c2948c32783b",
   "metadata": {},
   "source": [
    "### Random forest bivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b35cef8-d849-48ca-b7a8-d26f0f8d68dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_rf2 = results_dir / 'random_forest_2'\n",
    "path_rf2.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d8af70-9030-4e14-8458-e5fe63038cee",
   "metadata": {},
   "source": [
    "#### Fit model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6381ad89-e6f5-48a5-a5f2-53a449a489bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'n_estimators': [10, 100, 1000],\n",
    "#     'max_depth': [None, 1, 5, 10],\n",
    "#     'min_samples_split': [2, 5, 10, 20],\n",
    "#     'min_samples_leaf': [1, 2, 4, 6]\n",
    "# }\n",
    "# grid_search = GridSearchCV(\n",
    "#     RandomForestRegressor(random_state=42),\n",
    "#     param_grid,\n",
    "#     scoring='neg_mean_squared_error',\n",
    "#     cv=5,\n",
    "#     n_jobs=-1,\n",
    "#     # verbose=2\n",
    "# )\n",
    "\n",
    "# fit a model that predicts both parameters with the same settings\n",
    "grid_search.fit(X_train, y_train)\n",
    "rf2 = grid_search.best_estimator_\n",
    "print(grid_search.best_params_)\n",
    "with open(path_rf2 / f'random_forest_2par.pkl', 'wb') as file:\n",
    "        pickle.dump(rf2, file)\n",
    "\n",
    "# error\n",
    "y_pred = pd.DataFrame(rf2.predict(X_test), index=X_test.index, columns=targets)\n",
    "rmse = {var: root_mean_squared_error(y_test[var], y_pred[var]) for var in y_pred.columns}\n",
    "for key, value in rmse.items():\n",
    "    print(f'RMSE ({key}) = {value:.3f}')\n",
    "# prediction for all samples\n",
    "y_rf2 = pd.DataFrame(rf2.predict(X), index=X.index, columns=y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569a195-9b16-4df6-be66-6d5e3c97590a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ncols = len(targets)\n",
    "fig, axes = plt.subplots(ncols=ncols, nrows=2, figsize=(3 * ncols, 6))\n",
    "for i, (label, df) in enumerate({'calibration': y, 'random forest 1': y_rf1}.items()):\n",
    "    for j, par in enumerate(targets):\n",
    "        axes[i,j].scatter(\n",
    "            df.loc[X_train.index, par],\n",
    "            y_rf2.loc[X_train.index, par],\n",
    "            c='C0',\n",
    "            s=16,\n",
    "            alpha=.5,\n",
    "            label='train'\n",
    "        )\n",
    "        axes[i,j].scatter(\n",
    "            df.loc[X_test.index, par],\n",
    "            y_rf2.loc[X_test.index, par],\n",
    "            c='C1',\n",
    "            s=16,\n",
    "            alpha=.5,\n",
    "            label='test'\n",
    "        )\n",
    "        vlim = [x + e for x, e in zip(par_range[par], [-.02, .02])]\n",
    "        axes[i,j].plot(vlim, vlim, lw=.5, c='k', zorder=0)\n",
    "        axes[i,j].set(\n",
    "            xlim=vlim,\n",
    "            ylim=vlim,\n",
    "        )\n",
    "        if i == 0:\n",
    "            axes[0,j].set_title(par)\n",
    "            axes[0,j].set_xticklabels([])\n",
    "        elif i == 1:\n",
    "            axes[1,j].set_xlabel(label)\n",
    "        if j == 0:\n",
    "            axes[i,0].set_ylabel('random forest 2')\n",
    "        else:\n",
    "            axes[i,j].set_yticklabels([])\n",
    "        \n",
    "handles, labels = axes[0,0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, frameon=False, bbox_to_anchor=[.95, .25, .1, .3]);\n",
    "\n",
    "plt.savefig(path_rf2 / 'parameter_scatter.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507452a4-cca3-414e-9c0d-6a41b65de0eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importance_rf2 = pd.Series(rf2.feature_importances_, index=rf2.feature_names_in_).sort_values(ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, figsize=(4, 6), sharex=True)\n",
    "ax.barh(importance_rf2.index, importance_rf2)\n",
    "ax.set_xlabel('importance')\n",
    "ax.tick_params(axis='y', length=0)\n",
    "ax.spines[['left', 'top', 'right']].set_visible(False)\n",
    "\n",
    "plt.savefig(path_rf2 / 'importance_bar.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c08ec-a285-4b6f-acbb-dd5d304e311d",
   "metadata": {},
   "source": [
    "#### Simulate reservoirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5eafe6-d55f-4db8-9045-4095e745261e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adapt limits based on the estimation\n",
    "limits_rf2 = limits_def.loc[X.index].copy()\n",
    "limits_rf2.Vf = limits_rf2.Vtot * y_rf2['alpha']\n",
    "limits_rf2.Vmin = limits_rf2.Vf * .5\n",
    "limits_rf2.Ve = limits_rf2.Vtot - .2 * (limits_rf2.Vtot - limits_rf2.Vf)\n",
    "limits_rf2.Qf *= y_rf2['delta'] / 0.3\n",
    "\n",
    "performance_rf2 = pd.DataFrame(columns=['storage', 'outflow'])\n",
    "for ID, row in limits_rf2.iterrows():\n",
    "    \n",
    "    # declare reservoir\n",
    "    attrs = {attr: row[attr] for attr in ['Vmin', 'Vf', 'Ve', 'Vtot', 'Qn', 'Qf']}\n",
    "    attrs.update({'A': attributes.loc[ID, 'catch_skm'] * 1e6})\n",
    "    res = get_model('Hanazaki', **attrs)\n",
    "\n",
    "    # simulate\n",
    "    obs = timeseries[ID]\n",
    "    sim = res.simulate(\n",
    "        inflow=obs.inflow,\n",
    "        Vo=obs.storage.iloc[0],\n",
    "    )\n",
    "\n",
    "    # analyse performance\n",
    "    perf = compute_performance(timeseries[ID], sim)\n",
    "    performance_rf2.loc[ID, :] = perf.loc[metric, performance_rf2.columns].values\n",
    "performance_rf2.columns = [f'{metric}_{var}' for var in performance_rf2.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db60e6db-a556-4667-80ee-7812467eed8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add to the calibration results\n",
    "results_rf2 = pd.concat((y_rf2, performance_rf2), axis=1)\n",
    "results_rf2.index.name = 'ID'\n",
    "results = xr.concat((results, xr.Dataset({col: results_rf2[col] for col in results_rf2.columns}).expand_dims({'run': ['random_forest_2']})), dim='run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7365353c-8578-4abc-8432-ff855b8f649d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# performance_cal = results.sel(ID=X.index, run='bivariate')[['KGE_storage', 'KGE_outflow']].to_pandas().drop('run', axis=1)\n",
    "# performance_cal.rename(columns={col: col.split('_')[-1] for col in performance_cal.columns}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87345d-34f3-40a4-9c5d-f5f369605414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# performance_def = results.sel(ID=X.index, run='default')[['KGE_storage', 'KGE_outflow']].to_pandas().drop('run', axis=1)\n",
    "# performance_def.rename(columns={col: col.split('_')[-1] for col in performance_def.columns}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a92cc6-b855-40ec-8a2f-e99513234718",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=3, figsize=(6, 9), sharex=True, sharey=True)\n",
    "vlim = (-1.02, 1.02)\n",
    "ax[0, 0].set(\n",
    "    xlim=vlim,\n",
    "    ylim=vlim,\n",
    ")\n",
    "for j, var in enumerate(['storage', 'outflow']):\n",
    "    col = f'{metric}_{var}'\n",
    "    ax[0, j].scatter(performance_rf2.loc[X_train.index, col], performance_def.loc[X_train.index, col], c='C0', s=16, alpha=.5, label='train')\n",
    "    ax[0, j].scatter(performance_rf2.loc[X_test.index, col], performance_def.loc[X_test.index, col], c='C1', s=16, alpha=.5, label='test')\n",
    "    ax[0, j].plot(vlim, vlim, c='k', lw=.5, zorder=0)\n",
    "    ax[0, j].set_title(var)\n",
    "    \n",
    "    ax[1, j].scatter(performance_rf2.loc[X_train.index, col], performance_cal.loc[X_train.index, col], c='C0', s=16, alpha=.5, label='train')\n",
    "    ax[1, j].scatter(performance_rf2.loc[X_test.index, col], performance_cal.loc[X_test.index, col], c='C1', s=16, alpha=.5, label='test')\n",
    "    ax[1, j].plot(vlim, vlim, c='k', lw=.5, zorder=0)\n",
    "    # ax[1, j].set_xlabel('KGE (-)\\nrandom forest')\n",
    "    \n",
    "    ax[2, j].scatter(performance_rf2.loc[X_train.index, col], performance_rf1.loc[X_train.index, col], c='C0', s=16, alpha=.5, label='train')\n",
    "    ax[2, j].scatter(performance_rf2.loc[X_test.index, col], performance_rf1.loc[X_test.index, col], c='C1', s=16, alpha=.5, label='test')\n",
    "    ax[2, j].plot(vlim, vlim, c='k', lw=.5, zorder=0)\n",
    "    ax[2, j].set_xlabel('KGE (-)\\nrandom forest 2')\n",
    "    \n",
    "    if j == 0:\n",
    "        ax[0,j].set_ylabel('default\\nKGE (-)')\n",
    "        ax[1,j].set_ylabel('calibration\\nKGE (-)')\n",
    "        ax[2,j].set_ylabel('random forest 1\\nKGE (-)')\n",
    "        \n",
    "handles, labels = ax[0, 0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, frameon=False, bbox_to_anchor=[.95, .25, .1, .3]);\n",
    "\n",
    "plt.savefig(path_rf2 / 'performance_scatter.jpg', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a1ad40-a8c9-4fe8-9e29-5d1fb8756618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
