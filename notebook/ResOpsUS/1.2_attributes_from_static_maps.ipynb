{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "455af9d0-e8c9-4935-a28a-53e7320ecba8",
   "metadata": {},
   "source": [
    "# GloFAS - Attributes from static maps and model parameters\n",
    "***\n",
    "\n",
    "**_Autor:_** Chus Casado Rodríguez<br>\n",
    "**_Fecha:_** 06-05-2025<br>\n",
    "\n",
    "**Introduction:**<br>\n",
    "This notebook creates the static attributes related to GloFAS static maps and model parameters.\n",
    "\n",
    "**Ideas:**<br>\n",
    "* [ ] Reservoir attributes using GRanD or GDW, instead of GloFAS. Find the reservoirs in those datasets within the catchment, count them, and sum the total storage.\n",
    "* [ ] Lake attributes from HydroLakes, instead of GloFAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81d35226-0ade-42b9-8e74-1a086b0b4b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from lisfloodreservoirs.utils import DatasetConfig\n",
    "from lisfloodreservoirs.utils.plots import plot_attributes\n",
    "from lisfloodreservoirs.catchstats import catchment_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29654c04-471a-4957-98ad-206bc79abef1",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76bdaced-32e8-4f66-868b-dd0bff96534c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute tables will be saved in Z:\\nahaUsers\\casadje\\datasets\\reservoirs\\ResOpsUS\\v2.1\\attributes\n"
     ]
    }
   ],
   "source": [
    "cfg = DatasetConfig('config_ResOpsUS_v21.yml')\n",
    "\n",
    "# `cutmaps`\n",
    "PATH_CUTMAPS = cfg.PATH_RESOPS / 'ancillary' / 'cutmaps'\n",
    "OUTLETS = PATH_CUTMAPS / 'points_123.txt'\n",
    "MASK_FILE = 'my_mask.nc'\n",
    "\n",
    "# output\n",
    "PATH_PLOTS = cfg.PATH_ATTRS / 'plots'\n",
    "PATH_PLOTS.mkdir(parents=False, exist_ok=True)\n",
    "print(f'Attribute tables will be saved in {cfg.PATH_ATTRS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3affc9-7c12-4217-8da4-8a7b22fc6c1e",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "### Reservoirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a657e2-5f8b-4178-a5c9-0cb7d735cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load TXT used as input for `cutmaps`\n",
    "reservoirs = pd.read_csv(OUTLETS, sep='\\t', header=None)\n",
    "reservoirs.columns = ['lon_orig', 'lat_orig', 'ID']\n",
    "reservoirs.set_index('ID', drop=True, inplace=True)\n",
    "reservoirs[['LON', 'LAT', 'CATCH_SKM']] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1ecdab-005a-459a-b5f7-73caf0b1b327",
   "metadata": {},
   "source": [
    "###  Masks\n",
    "\n",
    "The coordinates of the _my_mask.nc_ maps and those of the GloFAS static maps do not match at the nth decimal, so I have to recreate the maps from the _upArea.nc_ static map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c6e3f1f-b7fe-4da4-97f6-1c58d78bf7db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1971cf7d02434b84be0b28c97240a769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading masks:   0%|          | 0/123 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the upstream area map\n",
    "upArea = xr.open_mfdataset(f'{cfg.PATH_LISFLOOD}/static_maps/upArea*.nc')['Band1'].compute()\n",
    "\n",
    "# load the pixel area map\n",
    "pixarea = xr.open_mfdataset(f'{cfg.PATH_LISFLOOD}/static_maps/pixarea*.nc')['Band1'].compute()\n",
    "\n",
    "# recreate masks and find outlet and catchment area\n",
    "masks = {}\n",
    "directories = [entry for entry in PATH_CUTMAPS.iterdir() if entry.is_dir()]\n",
    "for directory in tqdm(directories, desc='loading masks'):\n",
    "    try:\n",
    "        # ID\n",
    "        ID = int(directory.stem)\n",
    "        if ID not in reservoirs.index:\n",
    "            print(f'{ID} not in the original list')\n",
    "            continue\n",
    "\n",
    "        # load original mask\n",
    "        # mask = xr.open_dataset(directory / MASK_FILE)['Band1']\n",
    "        mask = xr.open_dataarray(directory / MASK_FILE)\n",
    "        mask = mask.rename({'x': 'lon', 'y': 'lat'})\n",
    "        # mask.name = str(ID)\n",
    "\n",
    "        # cut upArea map to the mask   \n",
    "        upArea_masked = upArea.sel(lon=mask.lon, lat=mask.lat, method='nearest', tolerance=1e-3)\n",
    "        mask['lon'] = upArea_masked.lon\n",
    "        mask['lat'] = upArea_masked.lat\n",
    "        upArea_masked = upArea_masked.where(mask == 1)        \n",
    "\n",
    "        # find outlet and catchment area\n",
    "        outlet = upArea_masked.isel(upArea_masked.argmax(dim=('lat', 'lon')))\n",
    "        reservoirs.loc[ID, ['LAT', 'LON', 'CATCH_SKM']] = outlet.lat.item(), outlet.lon.item(), outlet.item()\n",
    "\n",
    "        # create and save a mask out of the upArea map\n",
    "        mask = xr.where(upArea_masked.notnull(), 1, upArea_masked)\n",
    "        mask.name = str(ID)\n",
    "        masks[ID] = mask\n",
    "\n",
    "    except Exception as e: \n",
    "        print(directory, e)\n",
    "        continue\n",
    "        \n",
    "# series of catchment area in km²\n",
    "reservoirs.CATCH_SKM /= 1e6\n",
    "\n",
    "# create point geodataframe\n",
    "reservoirs = gpd.GeoDataFrame(\n",
    "    reservoirs, \n",
    "    geometry=gpd.points_from_xy(reservoirs.LON, reservoirs.LAT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d99ea9e2-c8ea-4938-904c-9039483d2a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extent\n",
    "lon_min, lon_max, lat_min, lat_max = reservoirs.LON.min(), reservoirs.LON.max(), reservoirs.LAT.min(), reservoirs.LAT.max()\n",
    "for ID, mask in masks.items():\n",
    "    lon_min = (np.min([lon_min, mask.lon.min()]))\n",
    "    lon_max = np.max([lon_max, mask.lon.max()])\n",
    "    lat_min = np.min([lat_min, mask.lat.min()])\n",
    "    lat_max = np.max([lat_max, mask.lat.max()])\n",
    "r = 5\n",
    "lon_min = float(np.floor(lon_min / r) * r)\n",
    "lon_max = float(np.ceil(lon_max / r) * r)\n",
    "lat_min = float(np.floor(lat_min / r) * r)\n",
    "lat_max = float(np.ceil(lat_max / r) * r)\n",
    "# used in plots\n",
    "extent = [lon_min, lon_max, lat_min, lat_max]\n",
    "# used in cutting maps\n",
    "extent_dct = {\n",
    "    'lon': slice(lon_min, lon_max),\n",
    "    'lat': slice(lat_max, lat_min)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8f361d-ce0d-40c2-bb4b-70bb7aa56467",
   "metadata": {},
   "source": [
    "## LISFLOOD static maps\n",
    "\n",
    "In this section I will compute catchment statistics of the LISFLOOD static maps that will be in the end exported as _glofas_static_maps.csv_. As ancillary maps, I have loaded first the pixel area and upstream area maps, that will be needed in the subsequent calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e647767e-50c1-4402-ae91-4ad8606371d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list where attributes will be appended\n",
    "attributes = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be878c30-80a7-4df7-a93c-2d415cdb7ecb",
   "metadata": {},
   "source": [
    "### Geomorphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7658627-9a03-44e6-b07a-052fab72dc70",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (637713411.py, line 27)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31msave=save=PATH_PLOTS / 'maps_geomorphology.jpg',\u001b[39m\n             ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "func = {'elv': ['mean', 'std', 'min', 'max'],\n",
    "        'gradient': ['mean', 'std'],\n",
    "        'upArea': ['max'],\n",
    "        # 'pixarea': ['sum']\n",
    "       }\n",
    "\n",
    "# load maps\n",
    "geomorphology = xr.Dataset({var: xr.open_mfdataset(f'{cfg.PATH_LISFLOOD}/static_maps/{var}_*.nc')['Band1'].compute() for var in func})\n",
    "geomorphology = geomorphology.sel(extent_dct)\n",
    "\n",
    "# compute statistics\n",
    "statistic = list(np.unique([stat for stats in func.values() for stat in stats]))\n",
    "attr_geomorphology = catchment_statistics(\n",
    "    geomorphology, \n",
    "    masks, \n",
    "    statistic=statistic, \n",
    "    weight=pixarea\n",
    ").to_pandas()\n",
    "cols = [f'{var}_{stat}' for var, stats in func.items() for stat in stats]\n",
    "attr_geomorphology = attr_geomorphology[cols]\n",
    "\n",
    "# plot attributes\n",
    "plot_attributes(\n",
    "    attr_geomorphology, \n",
    "    reservoirs.geometry.x, \n",
    "    reservoirs.geometry.y, \n",
    "    save=save=PATH_PLOTS / 'maps_geomorphology.jpg',\n",
    "    ncols=4, \n",
    "    extent=extent\n",
    ")\n",
    "\n",
    "# save\n",
    "attributes.append(attr_geomorphology)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911cbc6b-70cf-4121-bf54-6827dd9ff19c",
   "metadata": {},
   "source": [
    "### Land use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d0826b-42a3-4f8d-9750-8030a419c996",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['fracforest', 'fracirrigated', 'fracother', 'fracrice', 'fracwater', 'fracsealed']\n",
    "variables.sort()\n",
    "\n",
    "# load maps\n",
    "land_use = xr.Dataset({var: xr.open_mfdataset(f'{cfg.PATH_LISFLOOD}/static_maps/{var}_*.nc')['Band1'].compute() for var in variables})\n",
    "land_use = land_use.rename({var: var[4:] for var in list(land_use)})\n",
    "land_use = land_use.sel(extent_dct)\n",
    "\n",
    "# compute statistics\n",
    "attr_landuse = catchment_statistics(\n",
    "    land_use, \n",
    "    masks, \n",
    "    statistic=['mean'], \n",
    "    weight=pixarea\n",
    ").to_pandas()\n",
    "attr_landuse.sort_index(axis=1, inplace=True)\n",
    "\n",
    "# compute main land use\n",
    "lu_classes = {col: i for i, col in enumerate(attr_landuse.columns, start=1)}\n",
    "attr_landuse['land_use_main'] = attr_landuse.idxmax(axis=1).map(lu_classes)\n",
    "\n",
    "# rename attributes\n",
    "attr_landuse.rename(columns={col: col.split('_')[0] if 'mean' in col else col for col in attr_landuse}, inplace=True)\n",
    "attr_landuse.rename(columns={col: 'frac' + col.split('_')[0] if 'mean' in col else col for col in attr_landuse}, inplace=True)\n",
    "\n",
    "# plot attributes\n",
    "plot_attributes(\n",
    "    attr_landuse, \n",
    "    reservoirs.geometry.x, \n",
    "    reservoirs.geometry.y, \n",
    "    save=save=PATH_PLOTS / 'maps_landuse.jpg',\n",
    "    ncols=4,\n",
    "    extent=extent\n",
    ")\n",
    "\n",
    "# save\n",
    "attributes.append(attr_landuse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d73efe-2dbc-4314-b6a4-2206ea21f39d",
   "metadata": {},
   "source": [
    "### Crop coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab180f-54cc-45e7-94b8-7a526cd56461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping land use acronym and name\n",
    "mapping_landuse = {'f': 'forest', 'i': 'irrigated', 'o': 'other'}\n",
    "variables = ['cropcoef_f', 'cropcoef_i', 'cropcoef_o']\n",
    "\n",
    "# load maps\n",
    "crops = xr.Dataset({var: xr.open_mfdataset(f'{cfg.PATH_LISFLOOD}/static_maps/{var}_*.nc')['Band1'].compute() for var in variables})\n",
    "crops = crops.rename({var: mapping_landuse[var.split('_')[1]] for var in list(crops)})\n",
    "crops = crops.sel(extent_dct)\n",
    "\n",
    "# mean weighted by the fraction of pixel covered by each land use\n",
    "crops = crops.to_array('land_use').weighted(land_use.to_array('land_use').fillna(0)).sum('land_use', skipna=True) \n",
    "crops = crops.where(~upArea.isnull())\n",
    "crops.name = 'cropcoef'\n",
    "\n",
    "# compute statistics\n",
    "attr_crops = catchment_statistics(\n",
    "    crops,\n",
    "    masks, \n",
    "    statistic=['mean', 'std'], \n",
    "    weight=pixarea\n",
    ").to_pandas()\n",
    "\n",
    "# plot attributes\n",
    "plot_attributes(\n",
    "    attr_crops, \n",
    "    reservoirs.geometry.x, \n",
    "    reservoirs.geometry.y, \n",
    "    save=save=PATH_PLOTS / 'maps_crops.jpg',\n",
    "    ncols=2,\n",
    "    extent=extent\n",
    ")\n",
    "\n",
    "# save\n",
    "attributes.append(attr_crops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20374d3-4761-4cd0-8f11-120803b157c8",
   "metadata": {},
   "source": [
    "### Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c0c9d0-3abc-451f-b6d5-4e5813f0454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = {\n",
    "    'chanbnkf': ['mean'],\n",
    "    'chanbw': ['mean'],\n",
    "    'changrad': ['mean'],\n",
    "    'chanlength': ['sum'],\n",
    "    'chanflpn': ['mean'],\n",
    "    'chanman': ['mean'],\n",
    "    'chans': ['mean'],\n",
    "}\n",
    "\n",
    "# load maps\n",
    "streams = {var: xr.open_mfdataset(f'{cfg.PATH_LISFLOOD}/static_maps/{var}_*.nc')['Band1'].compute() for var in func}\n",
    "streams = {var: da.rename(var) for var, da in streams.items()}\n",
    "streams = {var : da.drop_vars([coord for coord in list(da.coords) if coord not in ['lon', 'lat']]) for var, da in streams.items()}\n",
    "streams = xr.Dataset({var: xr.DataArray(da.data, coords=upArea.coords, name=var) for var, da in streams.items()})\n",
    "streams = streams.sel(extent_dct)\n",
    "\n",
    "# mask streams (pixels with depth larger than 1 m)\n",
    "rivers = streams['chanbnkf'] > 1\n",
    "# rivers.plot(cmap='Blues')\n",
    "streams = streams.where(rivers)\n",
    "\n",
    "# calcular estadístico\n",
    "statistic = list(np.unique([stat for stats in func.values() for stat in stats]))\n",
    "attr_streams = catchment_statistics(\n",
    "    streams, \n",
    "    masks, \n",
    "    statistic, \n",
    "    weight=pixarea\n",
    ").to_pandas()\n",
    "cols = [f'{var}_{stat}' for var, stats in func.items() for stat in stats]\n",
    "attr_streams = attr_streams[cols]\n",
    "\n",
    "# plot attributes\n",
    "plot_attributes(\n",
    "    attr_streams,\n",
    "    reservoirs.geometry.x, \n",
    "    reservoirs.geometry.y, \n",
    "    save=save=PATH_PLOTS / 'maps_streams.jpg',\n",
    "    ncols=4,\n",
    "    extent=extent\n",
    ")\n",
    "\n",
    "# save\n",
    "attributes.append(attr_streams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32c116d-87c7-480f-b32e-a0be98344329",
   "metadata": {},
   "source": [
    "### Soil properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa6660c-4682-4541-9ec4-59bc9baf314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['ksat', 'lambda', 'genua', 'soildepth', 'thetas', 'thetar']\n",
    "layers = [1, 2, 3]\n",
    "maps = [f'{var}{layer}' for var in variables for layer in layers]\n",
    "\n",
    "# load maps\n",
    "soils = {}\n",
    "for var in tqdm(maps, desc='loading maps'):\n",
    "    files = list((cfg.PATH_LISFLOOD / 'static_maps').glob(f'{var}_*.nc'))\n",
    "    if len(files) > 1:\n",
    "        ds = {}\n",
    "        for file in files:\n",
    "            # type of land use\n",
    "            cover = mapping_landuse[file.stem.split('_')[1]]\n",
    "            # import map\n",
    "            ds[cover] = xr.open_dataset(file)['Band1']\n",
    "        ds = xr.Dataset(ds)\n",
    "        da = ds.to_array('land_use').weighted(land_use.to_array('land_use').fillna(0)).sum('land_use', skipna=True)\n",
    "        soils[var] = da.where(~upArea.isnull())\n",
    "    elif len(files) == 1:\n",
    "        soils[var] = xr.open_dataset(files[0])['Band1']\n",
    "soils = xr.Dataset(soils)\n",
    "soils = soils.sortby('lat', ascending=False)\n",
    "soils = soils.sel(extent_dct)\n",
    "\n",
    "# compute statistics\n",
    "attr_soils = catchment_statistics(\n",
    "    soils, \n",
    "    masks, \n",
    "    statistic=['mean'], \n",
    "    weight=pixarea\n",
    ").to_pandas()\n",
    "\n",
    "# rename attributes\n",
    "attr_soils.rename(columns={col: col.split('_')[0] for col in attr_soils if 'mean' in col}, inplace=True)\n",
    "\n",
    "# plot attributes\n",
    "plot_attributes(\n",
    "    attr_soils, \n",
    "    reservoirs.geometry.x, \n",
    "    reservoirs.geometry.y, \n",
    "    save=save=PATH_PLOTS / 'maps_soils.jpg',\n",
    "    ncols=3,\n",
    "    extent=extent\n",
    ")\n",
    "\n",
    "# save\n",
    "attributes.append(attr_soils)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6f8a5a-6ff9-4ce1-b690-7731fe55af55",
   "metadata": {},
   "source": [
    "### LAI\n",
    "\n",
    "I convert the timeseries of 10-daily timesteps into annual and monthly averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a03c9b-ee57-48dd-9ecf-b88cfefa3dc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maps = ['laif', 'laii', 'laio']\n",
    "\n",
    "# load maps\n",
    "lai = xr.Dataset({var: xr.open_mfdataset(f'{cfg.PATH_LISFLOOD}/static_maps/{var}*.nc')['Band1'] for var in maps})\n",
    "lai = lai.rename({var: mapping_landuse[var[3]] for var in list(lai)})\n",
    "lai = lai.sel(extent_dct).compute()\n",
    "\n",
    "# mean weighted by the portion of pixel covered by each land use\n",
    "lai = lai.to_array('land_use').weighted(land_use.to_array('land_use').fillna(0)).sum('land_use', skipna=True) \n",
    "lai = lai.where(~upArea.isnull())\n",
    "lai.name = 'lai'\n",
    "lai['time'] = pd.date_range('2021-01-05', periods=len(lai.time), freq='10D')\n",
    "\n",
    "# monthly resampling\n",
    "lai_m = lai.resample(time='MS').mean()\n",
    "lai_m['time'] = [f'{i:02}' for i in range(1, 13)]\n",
    "lai_agg = xr.Dataset({f'lai{month}': lai_m.sel(time=month).drop_vars('time') for month in lai_m.time.data})\n",
    "\n",
    "# annual statistics\n",
    "lai_agg['laiyrmean'] = lai.mean('time')\n",
    "lai_agg['laiyrmax'] = lai.max('time')\n",
    "lai_agg['laiyrmin'] = lai.min('time')\n",
    "\n",
    "# compute statistics\n",
    "attr_lai = catchment_statistics(\n",
    "    lai_agg,\n",
    "    masks, \n",
    "    statistic=['mean'], \n",
    "    weight=pixarea.sel(extent_dct)\n",
    ").to_pandas()\n",
    "\n",
    "# rename attributes\n",
    "attr_lai.rename(columns={col: '_'.join(col.split('_')[:-1]) for col in attr_lai if 'mean' in col}, inplace=True)\n",
    "\n",
    "# plot attributes\n",
    "plot_attributes(\n",
    "    attr_lai, \n",
    "    reservoirs.geometry.x, \n",
    "    reservoirs.geometry.y, \n",
    "    save=save=PATH_PLOTS / 'maps_lai.jpg',\n",
    "    ncols=4,\n",
    "    extent=extent\n",
    ")\n",
    "\n",
    "# save\n",
    "attributes.append(attr_lai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178218f1-83e9-4ba4-8500-bfe8c0b6e79a",
   "metadata": {},
   "source": [
    "### Water demand\n",
    "\n",
    "The original demand maps are monthly time series (domestic, energy, industry, livestock) in mm/day for the period 1990-2023. \n",
    "\n",
    "I will compute annual and monthly averages and from those I will compute statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f9a348-34db-4fb6-a989-dacb82bb3370",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = ['dom', 'ene', 'ind', 'liv']\n",
    "\n",
    "# load maps\n",
    "# demand = xr.Dataset({var: xr.open_mfdataset(f'{PATH_LISFLOOD}/iberia/maps/{var}_*.nc')[var].compute() for var in maps})\n",
    "\n",
    "# load maps\n",
    "demand = {}\n",
    "start, end = pd.to_datetime(cfg.START), pd.to_datetime('2023-12-31')\n",
    "dates = pd.date_range(start, end, freq='D')\n",
    "for use in tqdm(maps):\n",
    "    \n",
    "    # load dataset of demand\n",
    "    da = xr.open_mfdataset(f'{cfg.PATH_LISFLOOD}/static_maps/{use}*.nc')\n",
    "    da['time'] = da['time'] - pd.Timedelta(days=1)\n",
    "    da = da.sel(extent_dct).compute()\n",
    "    \n",
    "    # compute cachtment statistic\n",
    "    df = catchment_statistics(\n",
    "        da, \n",
    "        masks, \n",
    "        statistic=['mean'], \n",
    "        weight=pixarea\n",
    "    )[f'{use}_mean'].to_pandas()\n",
    "\n",
    "    # convert dataframe to daily resolution\n",
    "    daily_df = df.reindex(index=dates).ffill()\n",
    "    daily_df.index.name = 'time'\n",
    "\n",
    "    # convert to DataArray\n",
    "    demand[use] = xr.Dataset.from_dataframe(daily_df).to_array(dim='id', name=use)\n",
    "\n",
    "# combine all demands in one Dataset\n",
    "demand = xr.Dataset(demand)\n",
    "\n",
    "# monthly means\n",
    "demand_m = demand.groupby('time.month').mean('time')\n",
    "\n",
    "# annual mean\n",
    "demand_y = demand.groupby('time.year').mean('time').mean('year')\n",
    "# demand_y = demand.mean('time')\n",
    "\n",
    "# combine in a single dataset\n",
    "demand_agg = xr.Dataset()\n",
    "for key, da in demand_m.items():\n",
    "    for month in da.month.data:\n",
    "        demand_agg[f'{key}_{month:02}'] = da.sel(month=month).drop_vars('month')\n",
    "    demand_agg[f'{key}_yr'] = demand_y[key]\n",
    "\n",
    "# convert to volume\n",
    "# demand_agg = demand_agg * 1e-3 * pixarea\n",
    "\n",
    "# # compute statistics\n",
    "# attr_demand = catchment_statistics(demand_agg, masks, statistic=['sum'], weight=pixarea).to_pandas()\n",
    "\n",
    "# # rename attributes\n",
    "# attr_demand.rename(columns={col: '_'.join(col.split('_')[:-1]) for col in attr_demand if 'sum' in col}, inplace=True)\n",
    "\n",
    "attr_demand = demand_agg.to_pandas()\n",
    "\n",
    "# plot attributes\n",
    "plot_attributes(\n",
    "    attr_demand[['dom_yr', 'ene_yr', 'ind_yr', 'liv_yr']],\n",
    "    reservoirs.geometry.x,\n",
    "    reservoirs.geometry.y,\n",
    "    save=save=PATH_PLOTS / 'maps_demand.jpg',\n",
    "    ncols=4,\n",
    "    extent=extent\n",
    ")\n",
    "\n",
    "# save\n",
    "attributes.append(attr_demand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f8a11f-f24e-4f75-b94d-7a7341f06c77",
   "metadata": {},
   "source": [
    "### Reservoirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a11f4d-1b1b-474c-bf3c-fb76ce7623d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load map or reservoir ID\n",
    "# var = 'reservoirs'\n",
    "# res_xr = xr.open_mfdataset(f'{cfg.PATH_LISFLOOD}/static_maps/*_{var}_*.nc')['res']\n",
    "# res_xr = res_xr.sel(extent_dct).compute()\n",
    "\n",
    "# # extract reservoir ID\n",
    "# ids = [int(ID) for ID in np.unique(res_xr) if not np.isnan(ID)]\n",
    "# print('GloFAS represents {0} reservoirs in the study area'.format(len(ids)))\n",
    "\n",
    "# # load table of total reservoir storage\n",
    "# storage_pd = pd.read_csv(next((cfg.PATH_LISFLOOD / 'tables').glob('rstor*.txt')), sep='\\t', header=None, index_col=0).squeeze().astype('int64')\n",
    "# storage_pd.index.name = 'ResID'\n",
    "# storage_pd.name = 'storage'\n",
    "\n",
    "# # create map of reservoir storage\n",
    "# storage = res_xr.copy(deep=True)\n",
    "# for ID in ids:\n",
    "#     storage = storage.where(res_xr != ID, other=storage_pd.loc[ID])\n",
    "# # storage /= 1e6\n",
    "# storage.name = 'storage'\n",
    "# storage.attrs['units'] = 'm3'\n",
    "# storage.attrs['standard_name'] = 'capacity'\n",
    "# storage.attrs['long_name'] = 'reservoir_storage_capacity'\n",
    "\n",
    "# # compute statistics\n",
    "# attr_reservoir = catchment_statistics(\n",
    "#     storage, \n",
    "#     masks, \n",
    "#     statistic=['count', 'sum']\n",
    "# ).to_pandas()\n",
    "\n",
    "# # rename attributes\n",
    "# attr_reservoir.rename(columns={'storage_count': 'no_reservoirs', 'storage_sum': 'storage_reservoirs'}, inplace=True)\n",
    "\n",
    "# # plot attributes\n",
    "# plot_attributes(\n",
    "#     attr_reservoir, \n",
    "#     reservoirs.geometry.x, \n",
    "#     reservoirs.geometry.y,\n",
    "#     save=save=PATH_PLOTS / 'maps_reservoir.jpg',\n",
    "#     extent=extent\n",
    "# )\n",
    "\n",
    "# # save\n",
    "# attributes.append(attr_reservoir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680935ac-2c9b-47c2-9840-1fbf338e28c5",
   "metadata": {},
   "source": [
    "### Lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536a813c-04bb-4ad5-a061-ccda586fe6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load map or reservoir ID\n",
    "# var = 'lakes'\n",
    "# lakes_xr = xr.open_mfdataset(f'{cfg.PATH_LISFLOOD}/static_maps/*{var}*.nc')[var]\n",
    "# lakes_xr = lakes_xr.sel(extent_dct).compute()\n",
    "\n",
    "# # extract lake ID\n",
    "# ids = [int(ID) for ID in np.unique(lakes_xr) if not np.isnan(ID)]\n",
    "# print('GloFAS represents {0} lakes in the study area'.format(len(ids)))\n",
    "\n",
    "# # load table of lake area\n",
    "# lakes_pd = pd.read_csv(next((cfg.PATH_LISFLOOD / 'tables').glob('lakearea*.txt')), sep='\\t', header=None, index_col=0).squeeze().astype('int64')\n",
    "# lakes_pd.index.name = 'LakeID'\n",
    "# lakes_pd.name = 'area'\n",
    "\n",
    "# # create map of lake area\n",
    "# lakearea = lakes_xr.copy(deep=True)\n",
    "# for ID in ids:\n",
    "#     lakearea = lakearea.where(lakes_xr != ID, other=lakes_pd.loc[ID])\n",
    "# lakearea.name = 'area'\n",
    "# lakearea.attrs['units'] = 'm2'\n",
    "# lakearea.attrs['standard_name'] = 'area'\n",
    "# lakearea.attrs['long_name'] = 'lake_surface_area'\n",
    "\n",
    "# # compute statistics\n",
    "# attr_lake = catchment_statistics(\n",
    "#     lakearea, \n",
    "#     masks, \n",
    "#     statistic=['count', 'sum']\n",
    "# ).to_pandas()\n",
    "\n",
    "# # rename attributes\n",
    "# attr_lake.rename(columns={'area_count': 'no_lakes', 'area_sum': 'area_lakes'}, inplace=True)\n",
    "\n",
    "# # plot attributes\n",
    "# plot_attributes(\n",
    "#     attr_lake, \n",
    "#     reservoirs.geometry.x, \n",
    "#     reservoirs.geometry.y,\n",
    "#     save=save=PATH_PLOTS / 'maps_lake.jpg',\n",
    "#     extent=extent\n",
    "# )\n",
    "\n",
    "# # save\n",
    "# attributes.append(attr_lake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debbf762-3b6e-47df-8ec9-c1e59da49f7f",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19233587-98f4-44b1-b218-6e72a068ee91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all attributes\n",
    "attrs = pd.concat(attributes, axis=1)\n",
    "attrs.index.name = 'GRAND_ID'\n",
    "attrs.sort_index(axis=0, inplace=True)\n",
    "\n",
    "print('{0} attributes define the characteristics of {1} catchments'.format(*attrs.shape[::-1]))\n",
    "\n",
    "# export\n",
    "attrs.to_csv(cfg.PATH_ATTRS / 'glofas_static_maps.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d213266f-4f04-4cc5-b3ea-66ade17ba370",
   "metadata": {},
   "source": [
    "## LISFLOOD parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d441c72b-03c4-4e9d-91f5-13b3a60adf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list where parameters wil be appended\n",
    "parameters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9753896-b753-4134-9c63-d50feb00c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load parameter maps\n",
    "params = xr.open_mfdataset(f'{cfg.PATH_LISFLOOD}/parameters/*.nc', decode_timedelta=False).drop_vars('wgs_1984')\n",
    "params = params.sel(extent_dct).compute()\n",
    "print(f'{len(params)} parameters were calibrated in GloFAS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284c0dd5-cf2a-48b8-a8d6-e02b38fb8e8a",
   "metadata": {},
   "source": [
    "### Reservoir parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62867ff-c56e-4c08-8fe7-bf57a994b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reservoir_parameters = ['adjustNormalFlood', 'ReservoirRnormqMult']\n",
    "\n",
    "# extract the pixel value of reservoir parameters\n",
    "reservoirs_xr = reservoirs[['LAT', 'LON']].to_xarray()\n",
    "par_reservoir = params[reservoir_parameters].sel(lat=reservoirs_xr.LAT, lon=reservoirs_xr.LON, method='nearest').compute()\n",
    "par_reservoir = par_reservoir.to_pandas()[reservoir_parameters]\n",
    "\n",
    "# plot attributes\n",
    "plot_attributes(\n",
    "    par_reservoir,\n",
    "    reservoirs.geometry.x,\n",
    "    reservoirs.geometry.y,\n",
    "    save=save=PATH_PLOTS / 'maps_parameter_reservoir.jpg',\n",
    "    ncols=4,\n",
    "    extent=extent\n",
    ")\n",
    "\n",
    "# save\n",
    "parameters.append(par_reservoir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c31467-a882-45e7-ac8b-90709db60931",
   "metadata": {},
   "source": [
    "### Catchment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729319d5-70e5-44b6-99e4-4f45c1dc58b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute catchment statistics of the other parameters\n",
    "other_parameters = list(set(list(params)).difference(reservoir_parameters))\n",
    "par_catchment = catchment_statistics(\n",
    "    params[other_parameters], \n",
    "    masks, \n",
    "    statistic=['mean'], \n",
    "    weight=pixarea\n",
    ").to_pandas()\n",
    "par_catchment.rename(columns={col: '_'.join(col.split('_')[:-1]) for col in par_catchment if 'mean' in col}, inplace=True)\n",
    "\n",
    "# plot parameters\n",
    "plot_attributes(\n",
    "    par_catchment, \n",
    "    reservoirs.geometry.x, \n",
    "    reservoirs.geometry.y, \n",
    "    save=save=PATH_PLOTS / 'maps_parameter_catchment.jpg',\n",
    "    ncols=4,\n",
    "    extent=extent\n",
    ")\n",
    "\n",
    "# save\n",
    "parameters.append(par_catchment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d0dbde-ea77-4a5f-83f6-a72ccf8aa6b1",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648b2ea8-f589-4ae0-9afe-4074bad06a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate\n",
    "pars = pd.concat(parameters, axis=1)\n",
    "pars.index.name = 'GRAND_ID'\n",
    "pars.sort_index(axis=0, inplace=True)\n",
    "\n",
    "print('{0} attributes define the model parameters of {1} catchments'.format(*pars.shape[::-1]))  \n",
    "\n",
    "# export\n",
    "pars.to_csv(cfg.PATH_ATTRS / 'glofas_model_parameters.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
