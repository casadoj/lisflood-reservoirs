{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "631e1812-9c8c-4f8e-ad1b-41578130117b",
   "metadata": {},
   "source": [
    "# Select reservoirs and study period\n",
    "***\n",
    "\n",
    "**Author:** Chus Casado Rodríguez<br>\n",
    "**Date:** 06-09-2024<br>\n",
    "\n",
    "**Introduction:**<br>\n",
    "This notebook reads all the attributes and time series in the dataset and selects the reservoirs appropriate for testing the different reservoir routines. Several conditions need to be met for a reservoir to be selected:\n",
    "\n",
    "1. It must contain observed time series of the variables `inflow`, `storage` and `outflow`.\n",
    "2. The longest period without gaps in those three time series needs to be longer than 8 years.\n",
    "3. The bias between the observed inflow and outflow timeseries needs to be between 0.7 and 1.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1940f88-25de-47e5-88ec-2ba55e079da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from lisfloodreservoirs.utils import DatasetConfig\n",
    "from lisfloodreservoirs import read_attributes, read_timeseries\n",
    "from lisfloodreservoirs.utils.timeseries import define_period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d503d3-dd70-4b64-b148-ff7f86e0b789",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "436b7df9-9647-462b-bbfa-21472b4c18d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected reservoirs and periods will be saved in:\n",
      "\tZ:\\nahaUsers\\casadje\\datasets\\reservoirs\\ResOpsUS\\v2.0\\selection\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = DatasetConfig('config_dataset.yml')\n",
    "\n",
    "PATH_OUT = cfg.PATH_RESOPS / cfg.VERSION / 'selection'\n",
    "PATH_OUT.mkdir(parents=True, exist_ok=True)\n",
    "print(f'Selected reservoirs and periods will be saved in:\\n\\t{PATH_OUT}\\n')\n",
    "\n",
    "variables = ['inflow', 'storage', 'outflow']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da057a63-1f1b-412b-9188-3b984c86a637",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ab25ee-79ef-423a-aaf5-eb3c10fc6d6a",
   "metadata": {},
   "source": [
    "### Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e28a0d05-6a52-45b3-80e1-3ca6f3c4963a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528 reservoirs in the attribute tables\n",
      "231 reservoirs include observed time series for all variables: inflow, storage, outflow\n"
     ]
    }
   ],
   "source": [
    "# import all tables of attributes\n",
    "attributes = read_attributes(cfg.PATH_ATTRS, reservoirs=None)\n",
    "print(f'{attributes.shape[0]} reservoirs in the attribute tables')\n",
    "\n",
    "# keep only reservoirs with all observed variables\n",
    "mask = pd.concat([attributes[var.upper()] == 1 for var in variables], axis=1).all(axis=1)\n",
    "attributes = attributes[mask]\n",
    "attributes.sort_index(axis=0, inplace=True)\n",
    "print('{0} reservoirs include observed time series for all variables: {1}'.format(attributes.shape[0],\n",
    "                                                                                ', '.join(variables)))\n",
    "\n",
    "# NOTE!! The checks below (area and volume) were alreday done in notebook 1\n",
    "\n",
    "# # keep reservoirs that comply with the catchment area and total storage conditions\n",
    "# if cfg.MIN_AREA is not None:\n",
    "#     mask_area = attributes.CATCH_SKM >= cfg.MIN_AREA\n",
    "#     attributes = attributes[mask_area]\n",
    "#     print('{0} reservoirs comply with the minimum catchment area: {1} km²'.format(attributes.shape[0],\n",
    "#                                                                                            cfg.MIN_AREA))\n",
    "# if cfg.MIN_VOL is not None:\n",
    "#     mask_volume = attributes.CAP_MCM >= cfg.MIN_VOL\n",
    "#     attributes = attributes[mask_volume]\n",
    "#     print('{0} reservoirs comply with the minimum storage capacity: {1} hm3'.format(attributes.shape[0],\n",
    "#                                                                                 cfg.MIN_VOL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d8a35d2-a460-452a-bbcd-5985d0b95c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReservoirRnormqMult    2\n",
       "adjustNormalFlood      2\n",
       "DAM_NAME               1\n",
       "DIS_AVG_LS             1\n",
       "DOR_PC                 1\n",
       "                      ..\n",
       "soildepth2             1\n",
       "lambda1                1\n",
       "soildepth3             1\n",
       "lambda3                1\n",
       "TIME_SERIES_START      1\n",
       "Length: 150, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes.columns.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeee3a9-740a-4091-88ef-7226be8a1267",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a07a7af-b676-4a54-b2f9-d7f62acf74ae",
   "metadata": {},
   "source": [
    "#### Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f3ce9d6-350a-41ad-8345-1097aed7f18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231 reservoirs with timeseries\n",
      "\n",
      "217 reservoirs comply with the minimum degre of regulation: 0.08\n"
     ]
    }
   ],
   "source": [
    "# read time series\n",
    "timeseries = read_timeseries(cfg.PATH_TS / 'csv',\n",
    "                             attributes.index)\n",
    "print(f'{len(timeseries)} reservoirs with timeseries\\n')\n",
    "\n",
    "# remove reservoirs with excessively low degree of regulation\n",
    "if cfg.MIN_DOR is not None:\n",
    "    dor = pd.Series({grand_id: attributes.loc[grand_id, 'CAP_MCM'] * 1e6 / (ts.inflow.mean() * 365 * 24 * 3600) for grand_id, ts in timeseries.items()},\n",
    "                    name='DOR')\n",
    "    mask_dor = dor > cfg.MIN_DOR\n",
    "    attributes = attributes[mask_dor]\n",
    "    timeseries = {grand_id: ts for grand_id, ts in timeseries.items() if mask_dor[grand_id]}\n",
    "    print('{0} reservoirs comply with the minimum degre of regulation: {1}'.format(attributes.shape[0],\n",
    "                                                                                       cfg.MIN_DOR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d691a230-50d0-42e8-b1c9-a3fb6bef772f",
   "metadata": {},
   "source": [
    "## Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f53d31c9-1d85-47d9-8dfa-fadefe9ff162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a9c3a7000045fdae1951ac3cc2dcd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "select reservoirs:   0%|          | 0/217 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 135 discarded for lack of records:\t0 days\n",
      " 138 discarded for lack of records:\t1 days\n",
      " 144 discarded for lack of records:\t444 days\n",
      " 148 discarded for lack of records:\t602 days\n",
      " 158 discarded for lack of records:\t958 days\n",
      " 169 discarded for lack of records:\t1003 days\n",
      " 173 discarded for lack of records:\t206 days\n",
      " 180 discarded for lack of records:\t604 days\n",
      " 185 discarded for excesive bias:\t0.68\n",
      " 190 discarded for lack of records:\t302 days\n",
      " 191 discarded for lack of records:\t594 days\n",
      " 193 discarded for lack of records:\t503 days\n",
      " 203 discarded for lack of records:\t89 days\n",
      " 210 discarded for excesive bias:\t0.49\n",
      " 214 discarded for lack of records:\t594 days\n",
      " 223 discarded for lack of records:\t606 days\n",
      " 299 discarded for lack of records\n",
      " 320 discarded for lack of records:\t1163 days\n",
      " 338 discarded for lack of records:\t512 days\n",
      " 347 discarded for lack of records:\t3 days\n",
      " 374 discarded for lack of records:\t1444 days\n",
      " 382 discarded for lack of records:\t354 days\n",
      " 385 discarded for lack of records:\t827 days\n",
      " 386 discarded for excesive bias:\t0.34\n",
      " 470 discarded for excesive bias:\t0.58\n",
      " 487 discarded for lack of records:\t213 days\n",
      " 491 discarded for lack of records:\t849 days\n",
      " 492 discarded for excesive bias:\t2.18\n",
      " 493 discarded for excesive bias:\t0.16\n",
      " 509 discarded for excesive bias:\t0.70\n",
      " 557 discarded for lack of records:\t21 days\n",
      " 567 discarded for excesive bias:\t0.41\n",
      " 585 discarded for lack of records:\t503 days\n",
      " 592 discarded for lack of records:\t604 days\n",
      " 600 discarded for lack of records:\t503 days\n",
      " 605 discarded for lack of records:\t604 days\n",
      " 609 discarded for lack of records:\t475 days\n",
      " 612 discarded for lack of records:\t503 days\n",
      " 613 discarded for lack of records:\t7 days\n",
      " 620 discarded for lack of records:\t827 days\n",
      " 664 discarded for lack of records:\t1247 days\n",
      " 758 discarded for excesive bias:\t0.69\n",
      " 777 discarded for lack of records:\t1223 days\n",
      " 784 discarded for lack of records:\t1055 days\n",
      " 798 discarded for excesive bias:\t0.66\n",
      " 827 discarded for lack of records:\t574 days\n",
      " 836 discarded for excesive bias:\t0.54\n",
      " 837 discarded for lack of records:\t1423 days\n",
      " 854 discarded for lack of records:\t797 days\n",
      " 872 discarded for lack of records:\t694 days\n",
      " 884 discarded for lack of records:\t726 days\n",
      " 936 discarded for lack of records:\t1443 days\n",
      " 939 discarded for excesive bias:\t0.68\n",
      " 947 discarded for lack of records:\t359 days\n",
      " 948 discarded for lack of records:\t1260 days\n",
      " 953 discarded for lack of records:\t686 days\n",
      " 958 discarded for lack of records:\t700 days\n",
      " 962 discarded for lack of records:\t690 days\n",
      " 963 discarded for lack of records:\t633 days\n",
      " 976 discarded for lack of records:\t416 days\n",
      "1001 discarded for excesive bias:\t0.70\n",
      "1003 discarded for lack of records:\t563 days\n",
      "1007 discarded for lack of records:\t1044 days\n",
      "1017 discarded for lack of records:\t701 days\n",
      "1021 discarded for lack of records:\t1301 days\n",
      "1084 discarded for lack of records:\t791 days\n",
      "1092 discarded for lack of records:\t830 days\n",
      "1093 discarded for lack of records:\t1032 days\n",
      "1095 discarded for lack of records:\t700 days\n",
      "1101 discarded for lack of records:\t1424 days\n",
      "1109 discarded for lack of records:\t1165 days\n",
      "1120 discarded for excesive bias:\t0.67\n",
      "1122 discarded for lack of records:\t593 days\n",
      "1151 discarded for excesive bias:\t0.53\n",
      "1170 discarded for excesive bias:\t0.48\n",
      "1197 discarded for excesive bias:\t0.58\n",
      "1237 discarded for excesive bias:\t0.69\n",
      "1600 discarded for lack of records:\t529 days\n",
      "1615 discarded for lack of records:\t821 days\n",
      "1631 discarded for lack of records:\t252 days\n",
      "1691 discarded for lack of records:\t263 days\n",
      "1699 discarded for lack of records:\t415 days\n",
      "1707 discarded for lack of records:\t444 days\n",
      "1709 discarded for lack of records:\t976 days\n",
      "1712 discarded for lack of records:\t703 days\n",
      "1713 discarded for lack of records:\t1365 days\n",
      "1726 discarded for lack of records:\t610 days\n",
      "1733 discarded for lack of records:\t451 days\n",
      "1735 discarded for lack of records:\t752 days\n",
      "1762 discarded for lack of records:\t1046 days\n",
      "1883 discarded for lack of records:\t587 days\n",
      "1916 discarded for excesive bias:\t400.21\n",
      "2158 discarded for lack of records:\t153 days\n",
      "7311 discarded for lack of records:\t905 days\n",
      "\n",
      "123 reservoirs selected\n"
     ]
    }
   ],
   "source": [
    "bias = {}\n",
    "periods = {}\n",
    "for grand_id, ts in tqdm(timeseries.items(), desc='select reservoirs', total=len(timeseries)):\n",
    "    \n",
    "    # select study period\n",
    "    start, end = define_period(ts[variables])\n",
    "    if np.isnan(start) or np.isnan(end):\n",
    "        print(f'{grand_id:>4} discarded for lack of records')\n",
    "        continue\n",
    "    duration = (end - start) / np.timedelta64(1, 'D')\n",
    "    if duration >= cfg.MIN_YEARS * 365:\n",
    "        ts = ts.loc[start:end]\n",
    "    else:\n",
    "        print(f'{grand_id:>4} discarded for lack of records:\\t{duration:.0f} days')\n",
    "        continue\n",
    "        \n",
    "    # bias between inflow and outflow\n",
    "    bias[grand_id] = ts.outflow.mean() / ts.inflow.mean()\n",
    "    if (1 - cfg.TOL_BIAS) <= bias[grand_id] <= (1 + cfg.TOL_BIAS):\n",
    "        # save periods\n",
    "        periods[str(grand_id)] = {\n",
    "            'start_dates': [pd.Timestamp(start)],\n",
    "            'end_dates': [pd.Timestamp(end)]\n",
    "        }\n",
    "    else:\n",
    "        print(f'{grand_id:>4} discarded for excesive bias:\\t{bias[grand_id]:.2f}')\n",
    "    \n",
    "print(f'\\n{len(periods)} reservoirs selected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d502a68-c5f5-4ed3-912d-0dfb9abcd5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CAP',\n",
       " 'CAP_GLWD',\n",
       " 'GLOFAS_ID',\n",
       " 'GLWD_ID',\n",
       " 'LAT_LISFLOOD',\n",
       " 'LON_LISFLOOD',\n",
       " 'Qf',\n",
       " 'Qmin',\n",
       " 'Qn',\n",
       " 'Qn_adj',\n",
       " 'ReservoirRnormqMult',\n",
       " 'Vf',\n",
       " 'Vmin',\n",
       " 'Vn',\n",
       " 'Vn_adj',\n",
       " 'adjustNormalFlood',\n",
       " 'ADMIN_UNIT',\n",
       " 'ALT_HGT_M',\n",
       " 'ALT_LEN_M',\n",
       " 'ALT_NAME',\n",
       " 'ALT_RIVER',\n",
       " 'ALT_YEAR',\n",
       " 'AREA_SKM',\n",
       " 'CAP_MCM',\n",
       " 'CATCH_SKM',\n",
       " 'COMMENTS',\n",
       " 'COUNTRY',\n",
       " 'DAM_HGT_M',\n",
       " 'DAM_LEN_M',\n",
       " 'DAM_NAME',\n",
       " 'DEPTH_M',\n",
       " 'DIS_AVG_LS',\n",
       " 'DOR_PC',\n",
       " 'ELEV_MASL',\n",
       " 'LAKE_CTRL',\n",
       " 'LAT',\n",
       " 'LON',\n",
       " 'MAIN_BASIN',\n",
       " 'MAIN_ELEC',\n",
       " 'MAIN_FCON',\n",
       " 'MAIN_FISH',\n",
       " 'MAIN_IRRI',\n",
       " 'MAIN_NAVI',\n",
       " 'MAIN_OTHR',\n",
       " 'MAIN_RECR',\n",
       " 'MAIN_SUPP',\n",
       " 'MULTI_DAMS',\n",
       " 'NEAR_CITY',\n",
       " 'QUALITY',\n",
       " 'RES_NAME',\n",
       " 'RIVER',\n",
       " 'SEC_ADMIN',\n",
       " 'SINGLE_USE',\n",
       " 'USE_ELEC',\n",
       " 'USE_FCON',\n",
       " 'USE_FISH',\n",
       " 'USE_IRRI',\n",
       " 'USE_LIVE',\n",
       " 'USE_NAVI',\n",
       " 'USE_OTHR',\n",
       " 'USE_PCON',\n",
       " 'USE_RECR',\n",
       " 'USE_SUPP',\n",
       " 'YEAR',\n",
       " 'CAP_RESOPS',\n",
       " 'ELEVATION',\n",
       " 'ELEVATION_END',\n",
       " 'ELEVATION_START',\n",
       " 'EVAPORATION',\n",
       " 'EVAPORATION_END',\n",
       " 'EVAPORATION_START',\n",
       " 'INCONSISTENCIES_NOTED',\n",
       " 'INFLOW',\n",
       " 'INFLOW_END',\n",
       " 'INFLOW_START',\n",
       " 'OUTFLOW',\n",
       " 'OUTFLOW_END',\n",
       " 'OUTFLOW_START',\n",
       " 'STATE',\n",
       " 'STORAGE',\n",
       " 'STORAGE_END',\n",
       " 'STORAGE_START',\n",
       " 'TIME_SERIES_END',\n",
       " 'TIME_SERIES_START']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d25bed8-39f7-47cd-9b88-cd97ddeee7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_cols = {\n",
    "    'CATCH_SKM': 'area',\n",
    "    'LAT': 'lat',\n",
    "    'LON': 'lon'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18bcd04e-7e3a-4e29-832c-0964bcd229d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv = attributes.loc[[int(ID) for ID in periods], list(rename_cols)].copy()\n",
    "csv.index.name = 'ID'\n",
    "csv.rename(columns=rename_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db5ce4ab-d142-4bdb-a069-dd6e40b04852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2599</td>\n",
       "      <td>48.732466</td>\n",
       "      <td>-121.067305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>485</td>\n",
       "      <td>46.654792</td>\n",
       "      <td>-121.128322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1789</td>\n",
       "      <td>40.802949</td>\n",
       "      <td>-122.760687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>19018</td>\n",
       "      <td>40.720459</td>\n",
       "      <td>-122.422031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>514</td>\n",
       "      <td>40.599432</td>\n",
       "      <td>-122.540564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      area        lat         lon\n",
       "ID                               \n",
       "41    2599  48.732466 -121.067305\n",
       "63     485  46.654792 -121.128322\n",
       "131   1789  40.802949 -122.760687\n",
       "132  19018  40.720459 -122.422031\n",
       "133    514  40.599432 -122.540564"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75882b4e-c7ca-42b7-b89c-5a74e85095bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f02b5192-98fb-483a-b538-60a3cc23325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.to_csv(PATH_OUT / 'points_lfcoords.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219fb1c-1968-4ac0-a1de-ceb5f8ea3b7d",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23409f11-7fd9-47da-abe7-c545f1300f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export list of selected reservoirs\n",
    "with open(PATH_OUT / 'reservoirs.txt', 'w') as f:\n",
    "    for grand_id in periods.keys():\n",
    "        f.write(f'{grand_id}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2333bb16-7bbe-4d9c-a9a2-dfc72b62f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export selected study period\n",
    "with open(PATH_OUT / 'periods.pkl', 'wb') as f:\n",
    "    pickle.dump(periods, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04b83f0-3c68-45a2-9075-d353a23b158b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
