{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "974af1d2-5532-4168-ae69-6aee6a8f7477",
   "metadata": {},
   "source": [
    "# Reservoir Operations US\n",
    "***\n",
    "\n",
    "**Author:** Chus Casado Rodr√≠guez<br>\n",
    "**Date:** 13-09-2023<br>\n",
    "\n",
    "**Introduction:**<br>\n",
    "This notebook expores the dataset ResOpsUS, which contains reservoir operations for dams in the US. The data for reservoirs simulated in GloFAS4.0 are extracted and compared against GloFAS parameters.\n",
    "\n",
    "**To do:**<br>\n",
    "* [ ] Compare maximum reservoir storage between GRanD, GloFAS and ResOpsUS.\n",
    "* [ ] Add GloFAS reservoir limits to the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eb96988-9245-4b13-b455-21fc6b3855af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../src/')\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "from shapely import Point\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "from tqdm.notebook import tqdm\n",
    "import yaml\n",
    "\n",
    "from lisfloodreservoirs.utils.plots import plot_resops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d207e77-0580-43de-a3a9-262d0a0a11e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_datasets = Path('Z:/nahaUsers/casadje/datasets/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73caed1-ea11-42b4-85ef-d3eb19ce794a",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79013d62-36f7-47e7-8928-b001d15b15e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config_extraction.yml', 'r', encoding='utf8') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "197912de-a9e4-4255-bb46-2534d11bdc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "PATH_GLOFAS = Path(cfg['paths']['GloFAS'])\n",
    "PATH_RESOPS = Path(cfg['paths']['ResOpsUS'])\n",
    "PATH_GRAND = Path(cfg['paths']['GRanD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c7868e-dd05-497d-bd62-fec30a020c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b53355f-c749-46c8-8795-d45a2b440744",
   "metadata": {},
   "source": [
    "## Reservoirs\n",
    "\n",
    "### ResOpsUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72296b99-1948-4b2f-998a-20cd6c6d25b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load reservoir attributes\n",
    "attributes = pd.read_csv(PATH_RESOPS / 'raw' / 'attributes' / 'reservoir_attributes.csv', index_col='DAM_ID')\n",
    "\n",
    "# load time series recorded for each reservoir\n",
    "inventory = pd.read_csv(PATH_RESOPS / 'raw' / 'attributes' / 'time_series_inventory.csv', index_col='DAM_ID')\n",
    "\n",
    "# merge attributes and inventory and convert into geopandas\n",
    "resops = pd.merge(attributes, inventory, left_index=True, right_index=True)\n",
    "resops = gpd.GeoDataFrame(resops,\n",
    "                          geometry=[Point(xy) for xy in zip(resops.LONG, resops.LAT)])\n",
    "resops.crs = 'EPSG:4326'\n",
    "\n",
    "# remove duplicated index\n",
    "resops = resops[~resops.index.duplicated(keep='first')]\n",
    "\n",
    "# simplify column names\n",
    "resops.rename(columns={'AGENCY_CODE': 'AGENCY_COD',\n",
    "         'TIME_SERIES_START': 'TS_START',\n",
    "         'TIME_SERIES_END': 'TS_END',\n",
    "         'INCONSISTENCIES_NOTED': 'NOTES',\n",
    "         'STORAGE_START': 'STO_START',\n",
    "         'STORAGE_END': 'STO_END',\n",
    "         'DATA_SOURCE': 'STO_SOURCE',\n",
    "         'INFLOW_START': 'IN_START',\n",
    "         'INFLOW_END': 'IN_END',\n",
    "         'DATA_SOURCE.1': 'IN_SOURCE',\n",
    "         'OUTFLOW_START': 'OUT_START',\n",
    "         'OUTFLOW_END': 'OUT_END',\n",
    "         'DATA_SOURCE.2': 'OUT_SOURCE', \n",
    "         'ELEVATION_START': 'ELE_START', \n",
    "         'ELEVATION_END': 'ELE_END',\n",
    "         'DATA_SOURCE.3': 'ELE_SOURCE',\n",
    "         'EVAPORATION': 'EVAPORA',\n",
    "         'EVAPORATION_START': 'EVA_START', \n",
    "         'EVAPORATION_END': 'EVA_END',\n",
    "         'DATA_SOURCE.4': 'EVA_SOURCE'},\n",
    "                 inplace=True)\n",
    "\n",
    "# export as shapefile\n",
    "path_GIS = PATH_RESOPS / 'GIS'\n",
    "if path_GIS.exists() is False:\n",
    "    path_GIS.mkdir()\n",
    "resops.to_file(path_GIS / 'reservoirs.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a06bba4-43cb-4645-b0dd-349e36e71bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ResOpsUS contains {0} reservoirs.'.format(resops.shape[0]))\n",
    "variables = ['STORAGE', 'INFLOW', 'OUTFLOW']\n",
    "for var in variables:\n",
    "    print('{0} of those have {1} time series.'.format((resops[var] == 1).sum(),\n",
    "                                                      var.lower()))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 5), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '110m', edgecolor='face', facecolor='lightgray'), alpha=.5, zorder=0)\n",
    "ax.scatter(resops.geometry.x, resops.geometry.y, alpha=.5)\n",
    "ax.text(.5, 1.05, 'ResOpsUS reservoirs', horizontalalignment='center', verticalalignment='bottom', transform=ax.transAxes, fontsize=12)\n",
    "ax.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58df05d3-0094-4449-a61e-d7822fb8659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "((resops[variables] == 1).all(axis=1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e581d2fe-159e-4053-a421-0872517cd27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resops.STO_END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f04b5d-a1cb-48e1-a29e-a8f471d27aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2d35db-6166-4415-8a6a-385dfa1e82d8",
   "metadata": {},
   "source": [
    "### GRanD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e831549-ab93-4486-996d-1aa7afae9a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data set\n",
    "grand = gpd.read_file(PATH_GRAND / 'grand_dams_v1_3.shp')\n",
    "grand.set_index('GRAND_ID', drop=True, inplace=True)\n",
    "grand = grand.replace(-99, np.nan)\n",
    "\n",
    "# keep only reservoirs in ResOpsUS\n",
    "mask = resops.index.intersection(grand.index)\n",
    "grand = grand.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3038cdf-5936-450d-b8c4-9638855de26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GRanD contains {0} out of {1} reservoirs in ResOpsUS.'.format(grand.shape[0], resops.shape[0]))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 5), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '110m', edgecolor='face', facecolor='lightgray'), alpha=.5, zorder=0)\n",
    "ax.scatter(grand.geometry.x, grand.geometry.y, s=grand.CAP_MCM**.5, cmap='coolwarm', c='steelblue', alpha=.5)\n",
    "ax.text(.5, 1.05, 'GRanD reservoirs in ResOpsUS', horizontalalignment='center', verticalalignment='bottom', transform=ax.transAxes, fontsize=12)\n",
    "ax.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d79afd-b51b-4077-98d0-f78fa75ec749",
   "metadata": {},
   "source": [
    "## GloFAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88a2040-b84e-49a0-9262-6d3a64d79ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load GloFAS reservoirs\n",
    "# path_GloFAS = Path('../data/reservoirs/GloFAS')\n",
    "glofas = gpd.read_file(path_GloFAS / 'tables' / 'GloFAS_reservoirs.shp')\n",
    "glofas.GRAND_ID = glofas.GRAND_ID.astype(pd.Int64Dtype())\n",
    "glofas.GLWD_ID = glofas.GLWD_ID.astype(pd.Int64Dtype())\n",
    "glofas.set_index('GRAND_ID', inplace=True)\n",
    "\n",
    "# keep only reservoirs in ResOpsUS\n",
    "mask = glofas.index.intersection(resops.index)\n",
    "glofas = glofas.loc[mask]\n",
    "\n",
    "# remove duplicates\n",
    "glofas = glofas[~glofas.index.duplicated(keep='first')]\n",
    "\n",
    "glofas.sort_index(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d4e245-7adb-4576-9ad7-9ab3716e3f45",
   "metadata": {},
   "source": [
    "There are two reservoirs that are duplicated in GloFAS:\n",
    "* The reservoir with GRanD_ID 993 (Lake of the Ozarks) has both ResID 361 and 362.\n",
    "* The reservoir with GranD_ID 1752 (Kentucky Lake) has both ResID 385 and 386.\n",
    "\n",
    "In both cases, the attributes are all the same but the LISFLOOD outflow paramters: _minq_, _ndq_, _normq_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24646e2e-c3f6-42d0-9e82-423a13f34377",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GloFAS contains {0} out of {1} reservoirs in ResOpsUS.'.format(glofas.shape[0], resops.shape[0]))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 5), subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "ax.add_feature(cfeature.NaturalEarthFeature('physical', 'land', '110m', edgecolor='face', facecolor='lightgray'), alpha=.5, zorder=0)\n",
    "ax.scatter(glofas.geometry.x, glofas.geometry.y, s=glofas.stor**.5, cmap='coolwarm', c='steelblue', alpha=.5)\n",
    "ax.text(.5, 1.05, 'GloFAS reservoirs in ResOpsUS', horizontalalignment='center', verticalalignment='bottom', transform=ax.transAxes, fontsize=12)\n",
    "ax.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5417b5-f499-4bf8-a4d9-82bd0e11e234",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2bb184-b3f9-4962-86db-b194bcff990d",
   "metadata": {},
   "source": [
    "**Compare the reservoir capacity in GloFAS and GRanD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ffc9a-bee6-4115-b43f-b1cb75137208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame of reservoir capacity in both datasets\n",
    "capacity = pd.concat((glofas.stor, grand.CAP_MCM), axis=1, join='inner')\n",
    "capacity.columns = ['GloFAS', 'GRanD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e74708-d527-46bc-a12d-2fdcb2caec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "r = 1e4\n",
    "cmin = np.floor(capacity.min().min() / r) * r\n",
    "cmax = np.ceil(capacity.max().max() / r) * r\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.scatter(capacity.GloFAS, capacity.GRanD, s=5, alpha=.5)\n",
    "ax.plot([cmin, cmax], [cmin, cmax], lw=.5, c='k', zorder=0)\n",
    "ax.set(xlim=(cmin, cmax),\n",
    "       xlabel='GloFAS',\n",
    "       ylim=(cmin, cmax),\n",
    "       ylabel='GRanD',\n",
    "       title='maximum storage (hm3)');\n",
    "# ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c1f273-b770-4126-b121-bb8e02cf16e9",
   "metadata": {},
   "source": [
    "Surprisingly, there's considerable dispersion between the reservoir capacity in both datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f2b13-52df-4ccf-8d17-8baacdd13408",
   "metadata": {},
   "source": [
    "## Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d49aa-f4fb-43b9-8767-6355b29bd81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = {}\n",
    "for ID in tqdm(glofas.index):\n",
    "    # load timeseries\n",
    "    series_id = pd.read_csv(PATH_RESOPS / 'time_series_all' / f'ResOpsUS_{ID}.csv', parse_dates=True, index_col='date')\n",
    "    series_id.columns.name = 'variable'\n",
    "    # remove empty time series\n",
    "    # series_id.dropna(axis=1, how='all', inplace=True)\n",
    "    # remove duplicated index\n",
    "    series_id = series_id[~series_id.index.duplicated(keep='first')]\n",
    "    # organize in a DataFrame by variable\n",
    "    series[ID] = series_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b86ef59-ca14-44f3-81c8-cc1a59f1d873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_out = Path('./ResOps')\n",
    "path_out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for ID, df in series.items():\n",
    "    title = '{0} - {1} ({2})'.format(ID, *resops.loc[ID, ['DAM_NAME', 'STATE']])\n",
    "    plot_resops(df.storage, df.elevation, df.inflow, df.outflow, capacity=capacity.loc[ID].to_list(),\n",
    "                xlim=(datetime(1979, 1, 1), None), title=title, save=path_out / f'{ID:04}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96d8ff7-1fd2-4b40-909a-77ba13dcb63e",
   "metadata": {},
   "source": [
    "Hoover, Glen Canyon, Fort Peck, Toledo Bend, Structure 193, Wesley E. Seale, Coolidge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3c4082-280f-4fed-9f57-d512a38c2ee3",
   "metadata": {},
   "source": [
    "The inspection of the previous plots shows that the maximum storage capacity in neither GloFAS nor GRanD are fully reliable. In some cases there are big difference between the capacity reported by GRanD and GloFAS, and depending on the reservoir, the incorrect value is one of these datasets or the other. I consider erroneous the capacity value when there's a clear offset compared with the storage time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d81686-de29-44f4-b736-58913eb46330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reservoirs selected in Otta et al. (2023)\n",
    "dams = ['Hoover', 'Glen Canyon', 'Fort Peck Dam', 'Toledo Bend', 'Structure 193', 'Wesley E. Seale Dam', 'Coolidge']\n",
    "mask_dams = grand.DAM_NAME.isin(dams)\n",
    "grand_IDs = grand.loc[mask_dams].index.to_list()\n",
    "\n",
    "grand_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414e73f9-c18a-4485-b239-ac0aef73bc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity.loc[[307, 597, 610, 656, 1269, 1317]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49617f3f-3836-466b-8eff-dc5a60ca6823",
   "metadata": {},
   "source": [
    "The reservoir named Structure 193 (GRanD ID 1957) is not modelled in GloFAS. From the other 6 reservoirs:\n",
    "\n",
    "* 307 - Fort Deck. The GloFAS capacity (19,000 hm3) is slightly below the peaks in the storage time series. The capacity in GRanD (23,560 hm3) seems correct.\n",
    "* 597 - Glen Canyon. The GloFAS capacity (33,300 hm3) seems accurate. The GRanD value (25,070 hm3) might be an error in the units (Wikipedia says that the capacity is 25000 acre¬∑ft or 31,000 hm3).\n",
    "* 610 - Hoover. Both values are similar and could be correct.\n",
    "* 656 - Coolidge. Similar values, but both are well above the time series.\n",
    "* 1269 - Toledo Bend. The GloFAS capacity (5,520 hm3) is below the storage time series. The GRanD value (6287.7 hm3) seems correct.\n",
    "* 1317 - Wesley E. Seale. The GloFAS value (1240 hm3) is double as that of GRanD (655 hm3), and both are well above the storage time series. According to a website from the Texas Government, the volume of the reservoir is 314.2 hm3, which can be closer to the storage time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc64f99-2497-470f-979e-e882ad91e806",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ID, df in series.items():\n",
    "    cap_glofas, cap_grand = capacity.loc[ID]\n",
    "    if cap_glofas < df.storage.max():\n",
    "        print('{0} - Glofas: {1:.1f} hm3\\tseries: {2:.1f} hm3'.format(ID, cap_glofas, df.storage.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db966158-2220-4ec7-9353-8ec6fa1aea9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
